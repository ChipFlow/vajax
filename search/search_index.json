{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"VAJAX: GPU-Accelerated Analog Circuit Simulator","text":"<p>A proof-of-concept GPU-accelerated analog circuit simulator built on JAX, demonstrating:</p> <ul> <li>Automatic differentiation for computing device Jacobians without explicit derivatives</li> <li>GPU acceleration for large circuits using JAX's JIT compilation</li> <li>Verilog-A model integration via OpenVAF/OSDI bindings for PDK compatibility</li> <li>SAX-inspired functional device model API</li> </ul>"},{"location":"#current-status","title":"Current Status","text":"<p>VAJAX is in active development as a proof-of-concept. All VACASK benchmark circuits are passing.</p> <p>CI test results and benchmarks</p>"},{"location":"#validation-three-way-comparison","title":"Validation: Three-Way Comparison","text":"<p>VAJAX results are validated against VACASK (reference simulator) and ngspice. All simulators use identical netlists and device models (PSP103 MOSFETs via OSDI).</p>"},{"location":"#rc-low-pass-filter","title":"RC Low-Pass Filter","text":"<p>Simple RC circuit demonstrating basic transient behavior. VAJAX matches VACASK and ngspice exactly.</p> <p></p>"},{"location":"#psp103-ring-oscillator","title":"PSP103 Ring Oscillator","text":"<p>7-stage ring oscillator with production PSP103 MOSFET models. Shows excellent agreement in oscillation frequency and waveform shape.</p> <p></p>"},{"location":"#c6288-16-bit-multiplier","title":"C6288 16-bit Multiplier","text":"<p>Large-scale benchmark with ~86,000 nodes. Uses sparse solver for memory efficiency. Demonstrates VAJAX scaling to production-sized circuits.</p> <p></p>"},{"location":"#performance","title":"Performance","text":"<p>VAJAX is designed for GPU acceleration of large circuits. The table below shows per-step timing against VACASK (C++ reference simulator) on CI runners.</p>"},{"location":"#cpu-performance-vs-vacask","title":"CPU Performance (vs VACASK)","text":"Benchmark Nodes Steps JAX (ms/step) VACASK (ms/step) Ratio RMS Error rc 4 1M 0.012 0.002 6.6x 0.00% graetz 6 1M 0.020 0.004 5.4x 0.00% mul 8 500k 0.041 0.004 10.9x 0.00% ring 47 20k 0.511 0.109 4.7x - c6288 ~5000 1k 88.060 76.390 1.2x 2.01%"},{"location":"#gpu-performance","title":"GPU Performance","text":"Benchmark Nodes JAX GPU (ms/step) JAX CPU (ms/step) GPU Speedup vs VACASK CPU c6288 ~5000 19.81 88.06 4.4x 2.9x faster ring 47 1.49 0.51 0.3x below threshold rc 4 0.24 0.01 0.05x below threshold <p>See Performance Analysis for the full overhead breakdown.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install with uv (recommended)\nuv sync\n\n# Run tests\nuv sync --extra test\nJAX_PLATFORMS=cpu uv run pytest tests/ -v\n\n# Run a benchmark\nJAX_PLATFORMS=cpu uv run vajax benchmark ring\n</code></pre>"},{"location":"#installation-options","title":"Installation Options","text":"<pre><code># CPU only (default)\nuv sync\n\n# With CUDA 12 support (Linux)\nuv sync --extra cuda12\n\n# With SAX integration\nuv sync --extra sax\n</code></pre>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>vajax/\n\u251c\u2500\u2500 analysis/             # Circuit solvers and analysis engines\n\u2502   \u251c\u2500\u2500 engine.py        # CircuitEngine - main simulation API\n\u2502   \u251c\u2500\u2500 solver.py        # Newton-Raphson with lax.while_loop\n\u2502   \u251c\u2500\u2500 transient/       # Transient analysis (scan/loop strategies)\n\u2502   \u251c\u2500\u2500 ac.py            # AC small-signal analysis\n\u2502   \u251c\u2500\u2500 noise.py         # Noise analysis\n\u2502   \u251c\u2500\u2500 hb.py            # Harmonic balance\n\u2502   \u251c\u2500\u2500 xfer.py          # Transfer function (DCINC, DCXF, ACXF)\n\u2502   \u251c\u2500\u2500 corners.py       # PVT corner analysis\n\u2502   \u251c\u2500\u2500 homotopy.py      # Convergence aids (GMIN, source stepping)\n\u2502   \u2514\u2500\u2500 sparse.py        # JAX sparse matrix operations (BCOO/BCSR)\n\u2502\n\u251c\u2500\u2500 devices/              # Device models\n\u2502   \u251c\u2500\u2500 vsource.py       # Voltage/current source waveforms\n\u2502   \u2514\u2500\u2500 verilog_a.py     # OpenVAF Verilog-A wrapper\n\u2502\n\u251c\u2500\u2500 netlist/              # Circuit representation\n\u2502   \u251c\u2500\u2500 parser.py        # VACASK netlist parser\n\u2502   \u2514\u2500\u2500 circuit.py       # Circuit data structures\n\u2502\n\u2514\u2500\u2500 benchmarks/           # Benchmark infrastructure\n    \u251c\u2500\u2500 registry.py      # Auto-discovery of benchmarks\n    \u2514\u2500\u2500 runner.py        # VACASK benchmark runner\n</code></pre> <p>See Architecture Overview for the full design documentation.</p>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#user-guide","title":"User Guide","text":"<ul> <li>API Reference - CircuitEngine, result types, I/O</li> <li>CLI Reference - Command-line interface</li> <li>Transient Options - Transient analysis configuration</li> <li>Performance Analysis - Overhead breakdown</li> <li>VACASK Sim Format - Circuit file format</li> </ul>"},{"location":"#developer-guide","title":"Developer Guide","text":"<ul> <li>Architecture Overview - System design</li> <li>GPU Solver Architecture - Solver internals</li> <li>GPU Solver Jacobian - Jacobian computation</li> <li>Debug Tools - Debugging utilities</li> <li>OSDI Inputs - OpenVAF integration</li> </ul>"},{"location":"OPENVAF_API_PLAN/","title":"OpenVAF API Clarity Plan","text":""},{"location":"OPENVAF_API_PLAN/#executive-summary","title":"Executive Summary","text":"<p>The current data flow from Verilog-A source through <code>openvaf_py</code> to VAJAX has several naming convention issues that make the code difficult to understand and debug. This document proposes a clear, well-documented data flow with unambiguous naming conventions.</p>"},{"location":"OPENVAF_API_PLAN/#current-issues","title":"Current Issues","text":""},{"location":"OPENVAF_API_PLAN/#1-sim_node-synthetic-naming","title":"1. <code>sim_node{}</code> Synthetic Naming","text":"<p>In <code>openvaf_py/src/lib.rs</code>, the <code>get_dae_system()</code> function uses synthetic <code>sim_node{i}</code> names:</p> <pre><code>// Current problematic code (lib.rs:692-717)\nfor (i, node) in self.nodes.iter().enumerate() {\n    unknowns.set_item(format!(\"sim_node{}\", i), node.clone()).unwrap();\n}\n// ...\nfor i in 0..self.num_residuals {\n    residuals.set_item(format!(\"sim_node{}\", i), res).unwrap();\n}\n</code></pre> <p>Problems: - Creates synthetic names that must be decoded (<code>sim_node3</code> \u2192 what actual node?) - Assumes 1:1 mapping between unknowns/residuals/jacobians by index - Consumer code in <code>engine.py</code> must strip <code>sim_</code> prefix and do lookups - Different representations for same concept (node name vs <code>sim_node{i}</code>)</p>"},{"location":"OPENVAF_API_PLAN/#2-v-variable-name-clashes","title":"2. <code>v{}</code> Variable Name Clashes","text":"<p>MIR variables are named with <code>v{}</code> prefix (e.g., <code>v123</code>, <code>v456</code>):</p> <pre><code>constants.set_item(format!(\"v{}\", u32::from(val)), float_val).unwrap();\n// ...\nresiduals[\"resist\"] = \"v{index}\"  // e.g., \"v1234\"\n</code></pre> <p>Problems: - <code>v{}</code> could clash with voltage-related naming conventions - Not immediately clear if <code>v123</code> refers to MIR value 123 or something else - Same prefix used for constants, params, residuals, jacobians</p>"},{"location":"OPENVAF_API_PLAN/#3-multiple-representations-of-same-data","title":"3. Multiple Representations of Same Data","text":"<p>The DAE system has: - <code>unknowns</code>: Maps <code>sim_node{i}</code> \u2192 actual node name (e.g., <code>KirchoffLaw(d)</code>) - <code>residuals</code>: Maps <code>sim_node{i}</code> \u2192 <code>{resist: v{idx}, react: v{idx}}</code> - <code>jacobian</code>: List of <code>{row: sim_node{i}, col: sim_node{j}, resist: v{idx}, react: v{idx}}</code> - <code>nodes</code>: List of raw node names from OpenVAF (e.g., <code>KirchoffLaw(NodeId(0))</code>)</p> <p>Consumer code must constantly translate between these representations.</p>"},{"location":"OPENVAF_API_PLAN/#proposed-solution","title":"Proposed Solution","text":""},{"location":"OPENVAF_API_PLAN/#phase-1-clarify-data-structure-non-breaking","title":"Phase 1: Clarify Data Structure (Non-Breaking)","text":"<p>Add a new <code>get_dae_system_v2()</code> method with clearer naming:</p> <pre><code>{\n    # Node information (indexed by node_idx 0..N-1)\n    \"nodes\": [\n        {\"idx\": 0, \"name\": \"d\", \"kind\": \"KirchoffLaw\", \"is_internal\": False},\n        {\"idx\": 1, \"name\": \"g\", \"kind\": \"KirchoffLaw\", \"is_internal\": False},\n        ...\n    ],\n\n    # Residual equations (indexed by equation_idx)\n    \"residuals\": [\n        {\n            \"equation_idx\": 0,\n            \"node_idx\": 0,  # Which node this residual stamps into\n            \"node_name\": \"d\",\n            \"resist_var\": \"mir_1234\",  # MIR variable for resistive part\n            \"react_var\": \"mir_5678\",   # MIR variable for reactive part\n        },\n        ...\n    ],\n\n    # Jacobian entries\n    \"jacobian\": [\n        {\n            \"entry_idx\": 0,\n            \"row_node_idx\": 0,\n            \"row_node_name\": \"d\",\n            \"col_node_idx\": 1,\n            \"col_node_name\": \"g\",\n            \"resist_var\": \"mir_2345\",\n            \"react_var\": \"mir_6789\",\n            \"has_resist\": True,\n            \"has_react\": True,\n        },\n        ...\n    ],\n\n    # Terminal nodes (external ports)\n    \"terminals\": [\"d\", \"g\", \"s\", \"b\"],\n    \"num_terminals\": 4,\n\n    # Internal nodes\n    \"internal_nodes\": [\"di\", \"gi\", \"si\", \"bi\", \"noi\"],\n    \"num_internal\": 5,\n}\n</code></pre>"},{"location":"OPENVAF_API_PLAN/#phase-2-rename-mir-variables-non-breaking","title":"Phase 2: Rename MIR Variables (Non-Breaking)","text":"<p>Change <code>v{}</code> prefix to <code>mir_{}</code> to clearly indicate these are MIR intermediate values:</p> <pre><code># Before: \"v1234\"\n# After:  \"mir_1234\"\n</code></pre> <p>This makes it unambiguous that these refer to OpenVAF MIR SSA values.</p>"},{"location":"OPENVAF_API_PLAN/#phase-3-document-data-flow","title":"Phase 3: Document Data Flow","text":"<p>Create clear documentation showing data flow:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        VERILOG-A SOURCE                                  \u2502\n\u2502  module psp103(d, g, s, b);                                             \u2502\n\u2502    inout d, g, s, b;                                                    \u2502\n\u2502    electrical d, g, s, b, di, gi, si, bi;                               \u2502\n\u2502    I(d, di) &lt;+ gds * V(d, di);                                          \u2502\n\u2502    ...                                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         OPENVAF COMPILER                                 \u2502\n\u2502  Parses VA \u2192 HIR \u2192 MIR (SSA form)                                       \u2502\n\u2502  - Parameters: param_names[], param_kinds[]                             \u2502\n\u2502  - Nodes: node_names[] with terminal + internal                         \u2502\n\u2502  - DAE System: residuals[], jacobian[]                                  \u2502\n\u2502  - Init function: computes cache values                                 \u2502\n\u2502  - Eval function: computes I, dI/dV at operating point                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         OPENVAF-PY (Rust)                                \u2502\n\u2502  lib.rs: VaModule struct with:                                          \u2502\n\u2502  - param_names: [\"TYPE\", \"W\", \"L\", ...]                                 \u2502\n\u2502  - param_kinds: [\"param\", \"param\", \"param\", ...]                        \u2502\n\u2502  - nodes: [\"KirchoffLaw(d)\", \"KirchoffLaw(g)\", ...]                     \u2502\n\u2502  - residual_resist_indices: [mir_idx for each residual]                 \u2502\n\u2502  - jacobian_rows/cols: [node_idx for each jac entry]                    \u2502\n\u2502                                                                          \u2502\n\u2502  get_dae_system() \u2192 Python dict with:                                   \u2502\n\u2502    unknowns: {sim_node0: \"d\", sim_node1: \"g\", ...}  \u2190 CONFUSING         \u2502\n\u2502    residuals: {sim_node0: {resist: v123, react: v456}, ...}             \u2502\n\u2502    jacobian: [{row: sim_node0, col: sim_node1, resist: v789}, ...]      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       OPENVAF_JAX.PY (Python)                            \u2502\n\u2502  OpenVAFToJAX class:                                                     \u2502\n\u2502  - Translates MIR instructions \u2192 JAX code                               \u2502\n\u2502  - Uses dae_data to map outputs:                                        \u2502\n\u2502      for node, res in dae_data['residuals'].items():                    \u2502\n\u2502          # node is \"sim_node{i}\" - must decode!                         \u2502\n\u2502          resist_val = res['resist']  # \"v{idx}\" - MIR variable          \u2502\n\u2502                                                                          \u2502\n\u2502  Generated functions:                                                    \u2502\n\u2502  - init_fn(params) \u2192 cache[N_cache]                                     \u2502\n\u2502  - eval_fn(params, cache) \u2192 (residuals, jacobian)                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       ENGINE.PY (VAJAX)                              \u2502\n\u2502  CircuitEngine._prepare_openvaf_batched_inputs():                        \u2502\n\u2502  - Builds node_map: {model_node_name \u2192 circuit_node_idx}                \u2502\n\u2502  - ALSO adds sim_node{i} entries for DAE residual mapping               \u2502\n\u2502                                                                          \u2502\n\u2502  _build_stamp_indices():                                                 \u2502\n\u2502  - Uses metadata['node_names'] which are \"sim_node{i}\" strings          \u2502\n\u2502  - Must strip \"sim_\" prefix to get actual model node                    \u2502\n\u2502                                                                          \u2502\n\u2502  _stamp_batched_results():                                               \u2502\n\u2502  - Maps \"sim_node{i}\" \u2192 model_node \u2192 circuit_node_idx                   \u2502\n\u2502  - Stamps into global f[], J[][] matrices                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"OPENVAF_API_PLAN/#phase-4-refactor-enginepy-node-mapping","title":"Phase 4: Refactor Engine.py Node Mapping","text":"<p>Current code in <code>engine.py:987-990</code>: <pre><code># Also map sim_node{i} names (DAE residuals use sequential indices)\nfor i, model_node in enumerate(model_nodes):\n    node_map[f'sim_node{i}'] = node_map.get(model_node, ground)\n</code></pre></p> <p>Proposed: Use the new v2 API to get direct node indices without synthetic names:</p> <pre><code># With v2 API - no synthetic names needed\nfor residual in dae_v2['residuals']:\n    node_name = residual['node_name']  # Direct node name: \"d\", \"g\", etc.\n    node_idx = residual['node_idx']    # Index within model\n    global_idx = circuit_node_map.get(node_name, ground)\n</code></pre>"},{"location":"OPENVAF_API_PLAN/#implementation-plan","title":"Implementation Plan","text":""},{"location":"OPENVAF_API_PLAN/#step-1-add-get_dae_system_v2-in-librs","title":"Step 1: Add <code>get_dae_system_v2()</code> in lib.rs","text":"<p>Add new method that returns cleaner data structure alongside existing method (backward compatible).</p>"},{"location":"OPENVAF_API_PLAN/#step-2-update-openvaf_jaxpy","title":"Step 2: Update <code>openvaf_jax.py</code>","text":"<p>Modify to use v2 API internally while maintaining external interface.</p>"},{"location":"OPENVAF_API_PLAN/#step-3-update-enginepy","title":"Step 3: Update <code>engine.py</code>","text":"<p>Remove <code>sim_node{}</code> workarounds once v2 API is used.</p>"},{"location":"OPENVAF_API_PLAN/#step-4-deprecate-get_dae_system","title":"Step 4: Deprecate <code>get_dae_system()</code>","text":"<p>Mark original method as deprecated, remove in future version.</p>"},{"location":"OPENVAF_API_PLAN/#naming-convention-reference","title":"Naming Convention Reference","text":"Concept Old Convention New Convention MIR SSA value <code>v123</code> <code>mir_123</code> Node reference in DAE <code>sim_node{i}</code> <code>node_idx: i, node_name: \"d\"</code> Residual equation <code>sim_node{i}</code> key <code>equation_idx: i, node_idx: j</code> Jacobian entry <code>row: sim_node{i}</code> <code>row_node_idx: i, row_node_name: \"d\"</code>"},{"location":"OPENVAF_API_PLAN/#testing-strategy","title":"Testing Strategy","text":"<ol> <li>Add unit tests for <code>get_dae_system_v2()</code> output format</li> <li>Add integration tests comparing v1 and v2 outputs for known models</li> <li>Test with ring oscillator benchmark to verify currents are non-zero</li> <li>Compare VAJAX vs VACASK results</li> </ol>"},{"location":"OPENVAF_API_PLAN/#files-to-modify","title":"Files to Modify","text":"<ol> <li><code>openvaf-py/src/lib.rs</code> - Add <code>get_dae_system_v2()</code> method</li> <li><code>openvaf-py/openvaf_jax.py</code> - Use v2 API, update code generation</li> <li><code>vajax/analysis/engine.py</code> - Remove <code>sim_node{}</code> workarounds</li> <li>Tests for all above</li> </ol>"},{"location":"OPENVAF_API_PLAN/#success-criteria","title":"Success Criteria","text":"<ol> <li>No more <code>sim_node{}</code> synthetic names in API</li> <li>MIR variables clearly identified with <code>mir_</code> prefix</li> <li>Data flow is documented and follows naming conventions</li> <li>Ring oscillator produces non-zero currents and oscillates correctly</li> <li>VACASK benchmark alignment improves</li> </ol>"},{"location":"OPENVAF_API_PLAN/#timeline","title":"Timeline","text":"<p>This is a medium-sized refactoring effort. The key insight is that the current confusion around <code>sim_node{}</code> naming is making it very hard to debug why currents are zero - we can't easily trace which model node maps to which circuit node.</p>"},{"location":"VACASK-ANALYSIS/","title":"Ring Benchmark Analysis","text":""},{"location":"VACASK-ANALYSIS/#circuit-overview","title":"Circuit Overview","text":"<p>The ring benchmark is a 9-stage ring oscillator using CMOS inverters built with PSP103 compact transistor models.</p>"},{"location":"VACASK-ANALYSIS/#circuit-topology","title":"Circuit Topology","text":"<pre><code>                  +------------------------------------------------------+\n                  |                                                      |\n                  v                                                      |\nNode 1 -&gt; [INV u1] -&gt; Node 2 -&gt; [INV u2] -&gt; Node 3 -&gt; ... -&gt; [INV u9] -&gt; Node 9\n    ^\n    |\n[ISOURCE i0] - Pulse to trigger oscillation\n    |\n    v\n   GND\n</code></pre> <p>Feedback: Output of u9 (node 9) feeds back to input of u1 (node 1), closing the ring.</p>"},{"location":"VACASK-ANALYSIS/#hierarchy-structure","title":"Hierarchy Structure","text":"<p>Each inverter has this hierarchical structure: <pre><code>inverter (subcircuit)\n  +-- mp (pmos subcircuit)\n  |     +-- m (psp103p OSDI instance) - PMOS transistor\n  +-- mn (nmos subcircuit)\n        +-- m (psp103n OSDI instance) - NMOS transistor\n</code></pre></p> <p>Total instances: - 20 low-level (leaf) instances: 18 PSP transistors + 1 isource + 1 vsource - 28 subcircuit instances: 9 inverters x 3 (inverter + pmos + nmos)</p>"},{"location":"VACASK-ANALYSIS/#device-parameters","title":"Device Parameters","text":""},{"location":"VACASK-ANALYSIS/#inverter-parameters-from-netlist","title":"Inverter Parameters (from netlist)","text":"Parameter Value Description w 10u Transistor width l 1u Gate length pfact 2 PMOS width factor (PMOS is 2x wider than NMOS)"},{"location":"VACASK-ANALYSIS/#pmos-transistor-u1mpm","title":"PMOS Transistor (u1:mp:m)","text":"Parameter Value w 20um (10u x pfact) l 1um as 10e-12 (source area) ad 10e-12 (drain area) ps 41um (source perimeter) pd 41um (drain perimeter) Terminals D-&gt;node 2, G-&gt;node 1, S-&gt;vdd, B-&gt;vdd"},{"location":"VACASK-ANALYSIS/#nmos-transistor-u1mnm","title":"NMOS Transistor (u1:mn:m)","text":"Parameter Value w 10um l 1um as 5e-12 (source area) ad 5e-12 (drain area) ps 21um (source perimeter) pd 21um (drain perimeter) Terminals D-&gt;node 2, G-&gt;node 1, S-&gt;GND, B-&gt;GND"},{"location":"VACASK-ANALYSIS/#node-collapsing","title":"Node Collapsing","text":"<p>Each PSP transistor has internal nodes that are collapsed: - G -&gt; GP (gate to gate-poly) - S -&gt; SI (source to internal source) - D -&gt; DI (drain to internal drain) - B -&gt; BI, BP -&gt; BI, BS -&gt; BI, BD -&gt; BI (bulk nodes consolidated)</p>"},{"location":"VACASK-ANALYSIS/#system-size","title":"System Size","text":"Metric Value Total nodes 174 Unknowns (after collapsing) 47 Matrix non-zeros 220 Sparsity ratio 0.0996 <p>The 47 unknowns include: - 10 external nodes (0-9, vdd) - 18 internal noise flow nodes (2 per transistor) - 18 internal noise nodes (2 per transistor) - 1 voltage source branch current</p>"},{"location":"VACASK-ANALYSIS/#calculation-order","title":"Calculation Order","text":"<p>The evaluation proceeds in this order (see <code>lib/circuit.cpp:1358</code> and <code>lib/osdidevice.cpp:373</code>):</p>"},{"location":"VACASK-ANALYSIS/#1-device-iteration","title":"1. Device Iteration","text":"<p>Devices are processed sequentially: <pre><code>__hierarchical__ (skipped - wrapper for subcircuits)\nvsource\nisource\nvccs, vcvs, cccs, ccvs, mutual (builtin, unused)\npsp103va (OSDI device - contains all transistors)\n</code></pre></p>"},{"location":"VACASK-ANALYSIS/#2-model-iteration","title":"2. Model Iteration","text":"<p>For each device, models are processed: - For psp103va: psp103n first, then psp103p</p>"},{"location":"VACASK-ANALYSIS/#3-instance-iteration","title":"3. Instance Iteration","text":"<p>For each model, instances are evaluated sequentially: - Under psp103n: u1:mn:m, u2:mn:m, u3:mn:m, ... u9:mn:m - Under psp103p: u1:mp:m, u2:mp:m, u3:mp:m, ... u9:mp:m</p>"},{"location":"VACASK-ANALYSIS/#4-per-instance-operations","title":"4. Per-Instance Operations","text":"<p>In <code>evalAndLoad</code>: 1. <code>evalCore()</code> - Evaluate device equations, compute currents and Jacobians 2. <code>loadCore()</code> - Load values into system matrix</p>"},{"location":"VACASK-ANALYSIS/#simulation-parameters","title":"Simulation Parameters","text":"<pre><code>Transient analysis:\n- Method: Trapezoidal (trap)\n- Step: 0.05ns\n- Stop: 1us\n- Max step: 0.05ns\n</code></pre>"},{"location":"VACASK-ANALYSIS/#performance-statistics-from-run","title":"Performance Statistics (from run)","text":"Metric Value Eval/load calls 84,686 NR iterations 84,685 Accepted timepoints 24,769 Rejected timepoints 0 Bypass opportunities 445,824 Bypassed evaluations 445,824 (100% bypass rate) <p>The high bypass rate indicates that the simulator efficiently skips re-evaluating devices when their terminal voltages haven't changed significantly.</p>"},{"location":"VACASK-ANALYSIS/#sparsity-pattern","title":"Sparsity Pattern","text":"<p>The Jacobian matrix has entries at the following (row, column) positions. The pattern shows coupling between: - Adjacent ring nodes (1-2, 2-3, ..., 8-9, 9-1) - Supply node (vdd = node 12) to all inverter outputs - Internal noise nodes to their corresponding external nodes</p> <p>Key sparsity characteristics: - Diagonal dominance (all diagonal entries present) - Banded structure for ring connectivity - Dense column for vdd supply (couples to all stages)</p>"},{"location":"VACASK-ANALYSIS/#psp103-model-parameters","title":"PSP103 Model Parameters","text":"<p>The PSP103 model uses extensive parameterization for accurate MOSFET modeling. Key parameter categories:</p>"},{"location":"VACASK-ANALYSIS/#geometry-parameters","title":"Geometry Parameters","text":"<ul> <li><code>lvaro</code>, <code>wvaro</code> - Length/width variation</li> <li><code>lap</code>, <code>dlq</code>, <code>dwq</code> - Overlap and delta parameters</li> </ul>"},{"location":"VACASK-ANALYSIS/#threshold-voltage","title":"Threshold Voltage","text":"<ul> <li><code>vfbo</code> = -1.1V - Flatband voltage</li> <li><code>toxo</code> = 1.5nm - Gate oxide thickness</li> <li><code>nsubo</code> = 3e23 - Substrate doping</li> </ul>"},{"location":"VACASK-ANALYSIS/#mobility","title":"Mobility","text":"<ul> <li><code>uo</code> = 0.035 - Low-field mobility</li> <li><code>mueo</code> = 0.6 - Mobility degradation</li> <li><code>themuo</code> = 2.75 - Temperature coefficient</li> </ul>"},{"location":"VACASK-ANALYSIS/#saturation","title":"Saturation","text":"<ul> <li><code>thesato</code> = 1e-6 - Saturation velocity parameter</li> <li><code>axo</code> = 20 - CLM parameter</li> </ul>"},{"location":"VACASK-ANALYSIS/#junction-parameters","title":"Junction Parameters","text":"<ul> <li><code>cjorbot</code> = 1e-3 - Bottom junction capacitance</li> <li><code>vbirbot</code> = 0.75V - Built-in potential</li> <li><code>idsatrbot</code> = 5e-9 - Saturation current</li> </ul> <p>The full model contains 270+ parameters for comprehensive MOSFET behavior modeling.</p>"},{"location":"VACASK-ANALYSIS/#detailed-analysis-evalcore-and-loadcore","title":"Detailed Analysis: evalCore and loadCore","text":"<p>The core evaluation loop for OSDI devices consists of two main functions that are called for each instance during simulation. These functions are defined in <code>lib/osdiinstance.cpp</code>.</p>"},{"location":"VACASK-ANALYSIS/#evalcore-device-evaluation","title":"evalCore() - Device Evaluation","text":"<p>Location: <code>lib/osdiinstance.cpp:1104-1342</code></p> <p>Purpose: Evaluates the device model equations to compute currents, charges, and Jacobian matrices.</p>"},{"location":"VACASK-ANALYSIS/#input-data-structures","title":"Input Data Structures","text":"<p>EvalSetup (defined in <code>include/elsetup.h</code>): <pre><code>struct EvalSetup {\n    // State and solution vectors\n    VectorRepository&lt;double&gt;* solution;    // Solution history\n    VectorRepository&lt;double&gt;* states;      // State variable history\n    double* deviceStates;                  // For bypass checking\n\n    // Analysis mode flags\n    bool staticAnalysis, dcAnalysis, acAnalysis, tranAnalysis, noiseAnalysis;\n\n    // Limiting control\n    bool enableLimiting, initializeLimiting;\n\n    // Evaluation control flags\n    bool evaluateResistiveJacobian;\n    bool evaluateReactiveJacobian;\n    bool evaluateResistiveResidual;\n    bool evaluateReactiveResidual;\n\n    // Bypass control\n    bool forceBypass, allowBypass, requestHighPrecision;\n\n    // Integration coefficients for transient\n    IntegratorCoeffs* integCoeffs;\n\n    // Output: bound step, breakpoints, etc.\n    double boundStep, nextBreakPoint, maxFreq;\n    double time;\n};\n</code></pre></p>"},{"location":"VACASK-ANALYSIS/#execution-flow","title":"Execution Flow","text":"<ol> <li> <p>Bypass Check (lines 1144-1195):    <pre><code>IF device is bypassable AND high precision not requested:\n  IF output is converged AND inputs haven't changed significantly:\n    SET bypass = true\n    SKIP device evaluation\n</code></pre></p> </li> <li> <p>Core Evaluation (lines 1197-1250):    <pre><code>IF NOT bypass:\n  CALL descriptor-&gt;eval(handle, instance_core, model_core, simInfo)\n\n  PROCESS eval flags:\n    - EVAL_RET_FLAG_LIM: Limiting was applied\n    - EVAL_RET_FLAG_FATAL: Fatal error, abort simulation\n    - EVAL_RET_FLAG_FINISH: $finish called\n    - EVAL_RET_FLAG_STOP: $stop called\n</code></pre></p> </li> <li> <p>Reactive State Storage (lines 1256-1286):    <pre><code>FOR each nonzero reactive residual node:\n  GET reactive residual contribution from instance core\n  IF limiting applied:\n    SUBTRACT linearized residual component\n  STORE in states vector\n  IF integCoeffs provided:\n    DIFFERENTIATE to get flow (dq/dt)\n    STORE flow in states vector\n</code></pre></p> </li> <li> <p>Bound Step Processing (lines 1317-1321):    <pre><code>IF computeBoundStep enabled:\n  GET bound_step from instance core\n  UPDATE global bound step (minimum)\n</code></pre></p> </li> <li> <p>Output Convergence Check (lines 1323-1339):    <pre><code>IF nr_bypass enabled AND device is bypassable:\n  CHECK if outputs have converged\n  UPDATE convergence flags for next iteration\n</code></pre></p> </li> </ol>"},{"location":"VACASK-ANALYSIS/#key-osdi-api-calls","title":"Key OSDI API Calls","text":"<pre><code>// Main device evaluation\nevalFlags = descriptor-&gt;eval(&amp;handle, core(), model()-&gt;core(), &amp;simInfo);\n</code></pre> <p>The <code>eval()</code> function is generated by OpenVAF from the Verilog-A model and: - Computes all branch currents - Computes all charges - Computes Jacobian derivatives (partial derivatives of currents/charges w.r.t. voltages) - Handles limiting functions for convergence - Sets internal states for integration</p>"},{"location":"VACASK-ANALYSIS/#loadcore-matrix-loading","title":"loadCore() - Matrix Loading","text":"<p>Location: <code>lib/osdiinstance.cpp:1344-1500</code></p> <p>Purpose: Loads the computed values from evalCore into the system matrix and RHS vector.</p>"},{"location":"VACASK-ANALYSIS/#input-data-structures_1","title":"Input Data Structures","text":"<p>LoadSetup (defined in <code>include/elsetup.h</code>): <pre><code>struct LoadSetup {\n    VectorRepository&lt;double&gt;* states;\n\n    // Jacobian loading control\n    bool loadResistiveJacobian;\n    bool loadReactiveJacobian;\n    double reactiveJacobianFactor;\n    bool loadTransientJacobian;\n    IntegratorCoeffs* integCoeffs;\n    MatrixEntryIndex jacobianLoadOffset;\n\n    // Residual loading destinations\n    double* resistiveResidual;\n    double* reactiveResidual;\n    double* linearizedResistiveRhsResidual;\n    double* linearizedReactiveRhsResidual;\n    double* reactiveResidualDerivative;\n\n    // Max contribution tracking\n    double* maxResistiveResidualContribution;\n    double* maxReactiveResidualContribution;\n    double* maxReactiveResidualDerivativeContribution;\n};\n</code></pre></p>"},{"location":"VACASK-ANALYSIS/#execution-flow_1","title":"Execution Flow","text":"<ol> <li> <p>Jacobian Loading (lines 1376-1398):    <pre><code>IF loadResistiveJacobian:\n  CALL descriptor-&gt;load_jacobian_resist(instance, model)\n  // Adds dI/dV contributions to matrix\n\nIF loadReactiveJacobian:\n  CALL descriptor-&gt;load_jacobian_react(instance, model, factor)\n  // Adds dQ/dV contributions scaled by factor\n\nIF loadTransientJacobian:\n  CALL descriptor-&gt;load_jacobian_tran(instance, model, alpha)\n  // Adds dI/dV + alpha*dQ/dV where alpha = integCoeffs-&gt;leadingCoeff()\n</code></pre></p> </li> <li> <p>Residual Loading (lines 1414-1430):    <pre><code>IF resistiveResidual provided:\n  CALL descriptor-&gt;load_residual_resist(instance, model, resistiveResidual)\n  // Loads I(V) contributions into RHS vector\n\nIF reactiveResidual provided:\n  CALL descriptor-&gt;load_residual_react(instance, model, reactiveResidual)\n  // Loads Q(V) contributions into RHS vector\n\nIF limiting was applied:\n  CALL descriptor-&gt;load_limit_rhs_resist/react(...)\n  // Subtracts linearized residual correction\n</code></pre></p> </li> <li> <p>Max Contribution Tracking (lines 1433-1497):    <pre><code>FOR each nonzero resistive residual:\n  GET contribution from instance core\n  IF limiting: SUBTRACT linearized component\n  UPDATE max contribution for that unknown\n\nFOR each nonzero reactive residual:\n  GET charge and flow from states vector\n  UPDATE max charge contribution\n  UPDATE max flow contribution\n  IF reactiveResidualDerivative provided:\n    ADD flow to RHS\n</code></pre></p> </li> </ol>"},{"location":"VACASK-ANALYSIS/#key-osdi-api-calls_1","title":"Key OSDI API Calls","text":"<pre><code>// Jacobian loading\ndescriptor-&gt;load_jacobian_resist(core(), model()-&gt;core());\ndescriptor-&gt;load_jacobian_react(core(), model()-&gt;core(), factor);\ndescriptor-&gt;load_jacobian_tran(core(), model()-&gt;core(), alpha);\n\n// Residual loading\ndescriptor-&gt;load_residual_resist(core(), model()-&gt;core(), rhs);\ndescriptor-&gt;load_residual_react(core(), model()-&gt;core(), rhs);\n\n// Limiting corrections\ndescriptor-&gt;load_limit_rhs_resist(core(), model()-&gt;core(), rhs);\ndescriptor-&gt;load_limit_rhs_react(core(), model()-&gt;core(), rhs);\n</code></pre>"},{"location":"VACASK-ANALYSIS/#data-flow-diagram","title":"Data Flow Diagram","text":"<pre><code>                    +------------------+\n                    |   OsdiDevice::   |\n                    |   evalAndLoad()  |\n                    +--------+---------+\n                             |\n             +---------------+---------------+\n             |                               |\n             v                               v\n    +--------+--------+             +--------+--------+\n    | FOR each model  |             | FOR each model  |\n    +--------+--------+             +--------+--------+\n             |                               |\n             v                               v\n    +--------+--------+             +--------+--------+\n    | FOR each inst   |             | FOR each inst   |\n    +--------+--------+             +--------+--------+\n             |                               |\n             v                               v\n    +--------+--------+             +--------+--------+\n    |    evalCore()   |             |    loadCore()   |\n    +--------+--------+             +--------+--------+\n             |                               |\n             v                               v\n    +--------+--------+             +--------+--------+\n    | descriptor-&gt;    |             | descriptor-&gt;    |\n    |   eval()        |             | load_jacobian_* |\n    +-----------------+             | load_residual_* |\n                                    +-----------------+\n             |                               |\n             v                               v\n    +--------+--------+             +--------+--------+\n    | Instance Core   |             | System Matrix   |\n    | - currents      | ----------&gt; | - Jacobian      |\n    | - charges       |             | - RHS vector    |\n    | - Jacobians     |             +-----------------+\n    +-----------------+\n</code></pre>"},{"location":"VACASK-ANALYSIS/#instance-core-memory-layout","title":"Instance Core Memory Layout","text":"<p>Each OSDI instance has a <code>core_</code> pointer to a memory block containing:</p> <pre><code>+---------------------------+\n| Node mapping array        |  &lt;- nodeMappingArray()\n+---------------------------+\n| Collapsed nodes pattern   |  &lt;- collapsedNodesPattern()\n+---------------------------+\n| Jacobian pointers (resist)|  &lt;- resistiveJacobianPointers()\n+---------------------------+\n| Jacobian pointers (react) |  &lt;- reactiveJacobianPointer(i)\n+---------------------------+\n| State index table         |  &lt;- stateIndexTable()\n+---------------------------+\n| Node residuals (resist)   |  &lt;- nodes[i].resist_residual_off\n+---------------------------+\n| Node residuals (react)    |  &lt;- nodes[i].react_residual_off\n+---------------------------+\n| Limiting RHS (resist)     |  &lt;- nodes[i].resist_limit_rhs_off\n+---------------------------+\n| Limiting RHS (react)      |  &lt;- nodes[i].react_limit_rhs_off\n+---------------------------+\n| Model-specific data       |  (parameters, internal vars)\n+---------------------------+\n</code></pre>"},{"location":"VACASK-ANALYSIS/#bypass-optimization","title":"Bypass Optimization","text":"<p>The bypass mechanism significantly improves performance by skipping device evaluation when:</p> <ol> <li>Input Bypass Check (<code>inputBypassCheckCore</code>):</li> <li>Compares current input voltages to stored values</li> <li> <p>If change &lt; tolerance * bypasstol, bypass is allowed</p> </li> <li> <p>Output Bypass Check (<code>outputBypassCheckCore</code>):</p> </li> <li>Compares current residuals to stored values</li> <li>If change &lt; tolerance * convtol, outputs are converged</li> <li>Stores history for next iteration</li> </ol> <p>In the ring benchmark, 100% of bypass opportunities were taken (445,824 evaluations skipped), demonstrating the effectiveness of this optimization for steady-state operation.</p>"},{"location":"api_reference/","title":"VAJAX API Reference","text":""},{"location":"api_reference/#core-classes","title":"Core Classes","text":""},{"location":"api_reference/#circuitengine","title":"CircuitEngine","text":"<p>The main class for circuit simulation. Parses VACASK/SPICE netlists and runs various analyses.</p> <pre><code>from vajax import CircuitEngine\n\nengine = CircuitEngine(\"circuit.sim\")\nengine.parse()\nengine.prepare(t_stop=1e-6, dt=1e-9)\nresult = engine.run_transient()\n</code></pre>"},{"location":"api_reference/#constructor","title":"Constructor","text":"<pre><code>CircuitEngine(sim_path: Path | str)\n</code></pre> <p>Parameters: - <code>sim_path</code>: Path to circuit file (<code>.sim</code> VACASK format; use <code>vajax convert</code> for SPICE netlists)</p>"},{"location":"api_reference/#methods","title":"Methods","text":""},{"location":"api_reference/#parse","title":"parse()","text":"<p>Parse the circuit file and compile device models.</p> <pre><code>engine.parse()\n</code></pre> <p>Loads the netlist, compiles Verilog-A models via OpenVAF, and prepares the circuit for simulation.</p>"},{"location":"api_reference/#prepare","title":"prepare()","text":"<p>Prepare for transient analysis by configuring all parameters. Call this once before <code>run_transient()</code>. If <code>run_transient()</code> is called without <code>prepare()</code>, it will auto-prepare from netlist defaults.</p> <pre><code>engine.prepare(\n    *,\n    t_stop: float = None,              # Stop time (seconds)\n    dt: float = None,                  # Time step / initial timestep (seconds)\n    use_sparse: bool = None,           # Force sparse (True) or dense (False) solver\n    backend: str = None,               # 'gpu', 'cpu', or None (auto-select)\n    temperature: float = 300.15,       # Simulation temperature (Kelvin)\n    adaptive_config: AdaptiveConfig = None,  # Adaptive timestep configuration\n    checkpoint_interval: int = None,   # GPU memory checkpointing interval\n)\n</code></pre> <p>Parameters: - <code>t_stop</code>: Simulation stop time. If None, uses value from netlist analysis params - <code>dt</code>: Time step. If None, uses value from netlist. For adaptive mode, this is the initial timestep - <code>use_sparse</code>: Use sparse matrix solver (recommended for &gt;1000 nodes). Defaults to False (dense) - <code>backend</code>: Force GPU or CPU backend. If None, auto-selects based on circuit size - <code>temperature</code>: Simulation temperature in Kelvin (default: 300.15K) - <code>adaptive_config</code>: Override adaptive timestep settings (LTE ratio, tolerances, etc.) - <code>checkpoint_interval</code>: If set, use GPU memory checkpointing with this many steps per buffer</p>"},{"location":"api_reference/#run_transient","title":"run_transient()","text":"<p>Run transient (time-domain) simulation. Requires <code>prepare()</code> to have been called first (or will auto-prepare from netlist defaults).</p> <pre><code>result = engine.run_transient() -&gt; TransientResult\n</code></pre> <p>Returns: <code>TransientResult</code></p>"},{"location":"api_reference/#run_ac","title":"run_ac()","text":"<p>Run AC (small-signal frequency response) analysis.</p> <pre><code>result = engine.run_ac(\n    freq_start: float = 1.0,      # Start frequency (Hz)\n    freq_stop: float = 1e6,       # Stop frequency (Hz)\n    mode: str = 'dec',            # 'dec', 'lin', 'oct', or 'list'\n    points: int = 10,             # Points per decade/octave\n    step: float = None,           # Frequency step for 'lin' mode\n    values: List[float] = None,   # Explicit frequency list for 'list' mode\n) -&gt; ACResult\n</code></pre> <p>Parameters: - <code>freq_start</code>: Start frequency in Hz - <code>freq_stop</code>: Stop frequency in Hz - <code>mode</code>: Sweep mode - <code>'dec'</code> (decade), <code>'lin'</code> (linear), <code>'oct'</code> (octave), or <code>'list'</code> - <code>points</code>: Points per decade/octave (for <code>'dec'</code>/<code>'oct'</code> modes) - <code>step</code>: Frequency step for <code>'lin'</code> mode - <code>values</code>: Explicit frequency list for <code>'list'</code> mode</p> <p>Returns: <code>ACResult</code></p>"},{"location":"api_reference/#run_noise","title":"run_noise()","text":"<p>Run noise analysis.</p> <pre><code>result = engine.run_noise(\n    out: str | int = 1,          # Output node (name or index)\n    input_source: str = \"\",      # Name of input source (e.g., \"vin\")\n    freq_start: float = 1.0,    # Start frequency (Hz)\n    freq_stop: float = 1e6,     # Stop frequency (Hz)\n    mode: str = 'dec',          # 'dec', 'lin', 'oct', or 'list'\n    points: int = 10,           # Points per decade/octave\n    temperature: float = 300.15, # Temperature (Kelvin)\n) -&gt; NoiseResult\n</code></pre> <p>Returns: <code>NoiseResult</code></p>"},{"location":"api_reference/#run_corners","title":"run_corners()","text":"<p>Run PVT (Process-Voltage-Temperature) corner analysis.</p> <pre><code>from vajax.analysis.corners import create_pvt_corners\n\ncorners = create_pvt_corners(\n    processes=['FF', 'TT', 'SS'],\n    voltages=[0.9, 1.0, 1.1],\n    temperatures=['cold', 'room', 'hot'],\n)\n\nengine.prepare(t_stop=1e-6, dt=1e-9)\nresults = engine.run_corners(corners)\n</code></pre> <p>Returns: <code>CornerSweepResult</code> containing results for all corners.</p>"},{"location":"api_reference/#run_dcinc","title":"run_dcinc()","text":"<p>Run DC incremental (small-signal gain) analysis.</p> <pre><code>result = engine.run_dcinc() -&gt; DCIncResult\n</code></pre> <p>Returns: <code>DCIncResult</code> with DC operating point and incremental gains.</p>"},{"location":"api_reference/#run_dcxf","title":"run_dcxf()","text":"<p>Run DC transfer function analysis.</p> <pre><code>result = engine.run_dcxf(\n    out: str | int = 1,  # Output node (name or index)\n) -&gt; DCXFResult\n</code></pre> <p>Returns: <code>DCXFResult</code> with transfer function magnitude and phase.</p>"},{"location":"api_reference/#run_acxf","title":"run_acxf()","text":"<p>Run AC transfer function analysis.</p> <pre><code>result = engine.run_acxf(\n    out: str | int = 1,              # Output node (name or index)\n    freq_start: float = 1.0,        # Start frequency (Hz)\n    freq_stop: float = 1e6,         # Stop frequency (Hz)\n    mode: str = 'dec',              # 'dec', 'lin', 'oct', or 'list'\n    points: int = 10,               # Points per decade/octave\n    step: float = None,             # Frequency step for 'lin' mode\n    values: List[float] = None,     # Explicit frequency list for 'list' mode\n) -&gt; ACXFResult\n</code></pre> <p>Returns: <code>ACXFResult</code> with frequency-dependent transfer function.</p>"},{"location":"api_reference/#properties","title":"Properties","text":""},{"location":"api_reference/#node_names","title":"node_names","text":"<p>Dict mapping node name strings to integer indices.</p> <pre><code>engine.node_names  # {'0': 0, 'vdd': 1, 'out': 2, ...}\n</code></pre>"},{"location":"api_reference/#devices","title":"devices","text":"<p>List of device information dicts.</p> <pre><code>engine.devices  # [{'name': 'R1', 'model': 'resistor', ...}, ...]\n</code></pre>"},{"location":"api_reference/#result-types","title":"Result Types","text":""},{"location":"api_reference/#transientresult","title":"TransientResult","text":"<p>Result of transient simulation.</p> <pre><code>@dataclass\nclass TransientResult:\n    times: Array                    # Time points array\n    voltages: Dict[str, Array]      # Node voltages over time\n    currents: Dict[str, Array]      # Source currents over time\n    stats: Dict[str, Any]           # Simulation statistics\n</code></pre> <p>Properties: - <code>num_steps</code>: Number of time steps - <code>node_names</code>: List of node names - <code>source_names</code>: List of voltage source names with current data</p> <p>Methods: - <code>voltage(node: str) -&gt; Array</code>: Get voltage waveform at a specific node - <code>current(source: str) -&gt; Array</code>: Get current waveform through a voltage source</p> <p>Example: <pre><code>engine.prepare(t_stop=1e-6, dt=1e-9)\nresult = engine.run_transient()\n\n# Access results\nprint(f\"Simulated {result.num_steps} time points\")\nprint(f\"Nodes: {result.node_names}\")\n\n# Get specific node voltage\nvout = result.voltage(\"out\")\nprint(f\"Final output: {vout[-1]:.3f}V\")\n\n# Iterate over all nodes\nfor name, voltages in result.voltages.items():\n    print(f\"  {name}: {voltages[-1]:.3f}V\")\n</code></pre></p>"},{"location":"api_reference/#acresult","title":"ACResult","text":"<p>Result of AC analysis.</p> <pre><code>@dataclass\nclass ACResult:\n    frequencies: Array           # Frequency points (Hz)\n    voltages: Dict[str, Array]   # Complex voltages at each frequency\n    currents: Dict[str, Array]   # Complex currents at each frequency\n</code></pre> <p>Example: <pre><code>result = engine.run_ac(freq_start=1e3, freq_stop=1e9, points=100)\n\n# Get transfer function magnitude\nvout = result.voltages[\"out\"]\nmagnitude_db = 20 * jnp.log10(jnp.abs(vout))\nphase_deg = jnp.angle(vout) * 180 / jnp.pi\n</code></pre></p>"},{"location":"api_reference/#noiseresult","title":"NoiseResult","text":"<p>Result of noise analysis.</p> <pre><code>@dataclass\nclass NoiseResult:\n    frequencies: Array                          # Frequency points (Hz)\n    output_noise: Array                         # Output noise spectral density\n    power_gain: Array                           # Power gain from input to output\n    contributions: Dict[str, Array]             # Per-device noise contributions\n    detailed_contributions: Dict[Tuple[str, str], Array]  # Per-device per-node contributions\n    dc_voltages: Optional[Array]                # DC operating point voltages\n</code></pre>"},{"location":"api_reference/#cornerresult","title":"CornerResult","text":"<p>Result of a single PVT corner simulation.</p> <pre><code>@dataclass\nclass CornerResult:\n    corner: CornerConfig         # Corner configuration used\n    result: Any                  # Simulation result (TransientResult, etc.) or None if failed\n    converged: bool              # Whether simulation converged successfully\n    stats: Dict[str, Any]        # Additional statistics and metadata\n</code></pre>"},{"location":"api_reference/#utility-functions","title":"Utility Functions","text":""},{"location":"api_reference/#create_pvt_corners","title":"create_pvt_corners()","text":"<p>Create PVT corner combinations for corner analysis.</p> <pre><code>from vajax.analysis.corners import create_pvt_corners\n\ncorners = create_pvt_corners(\n    processes=['FF', 'TT', 'SS'],          # Process corners\n    voltages=[0.9, 1.0, 1.1],             # VDD scale factors\n    temperatures=['cold', 'room', 'hot'],  # Temperature corners\n)\n</code></pre> <p>Returns: List of <code>CornerConfig</code> objects for all combinations (default: 27 = 3x3x3).</p>"},{"location":"api_reference/#configure_precision","title":"configure_precision()","text":"<p>Configure JAX floating-point precision.</p> <pre><code>from vajax import configure_precision\n\nconfigure_precision(force_x64=True)   # Force float64\nconfigure_precision(force_x64=False)  # Force float32\nconfigure_precision()                  # Auto-detect based on backend\n</code></pre>"},{"location":"api_reference/#get_precision_info","title":"get_precision_info()","text":"<p>Get current precision configuration.</p> <pre><code>from vajax import get_precision_info\n\ninfo = get_precision_info()\nprint(f\"Backend: {info['backend']}\")\nprint(f\"Float64 enabled: {info['x64_enabled']}\")\n</code></pre>"},{"location":"api_reference/#io-functions","title":"I/O Functions","text":""},{"location":"api_reference/#write_rawfile","title":"write_rawfile()","text":"<p>Write results to ngspice-compatible raw file.</p> <pre><code>from vajax.io import write_rawfile\n\nwrite_rawfile(result, \"output.raw\", binary=True)\n</code></pre> <p>Parameters: - <code>result</code>: TransientResult or ACResult - <code>output_path</code>: Path to output file - <code>binary</code>: If True, write binary format (more compact)</p>"},{"location":"api_reference/#write_csv","title":"write_csv()","text":"<p>Write results to CSV file.</p> <pre><code>from vajax.io import write_csv\n\nwrite_csv(result, \"output.csv\", precision=9)\n</code></pre> <p>Parameters: - <code>result</code>: Simulation result - <code>output_path</code>: Path to output file - <code>precision</code>: Decimal places for scientific notation</p>"},{"location":"api_reference/#read_csv","title":"read_csv()","text":"<p>Read simulation results from CSV file.</p> <pre><code>from vajax.io import read_csv\n\ndata = read_csv(\"output.csv\")\ntimes = data['times']\nvoltages = data['voltages']\n</code></pre>"},{"location":"api_reference/#sparse-solver-functions","title":"Sparse Solver Functions","text":"<p>For large circuits (&gt;1000 nodes), use sparse matrix solvers:</p> <pre><code>from vajax.analysis.sparse import (\n    build_csr_arrays,    # COO to CSR conversion\n    sparse_solve_csr,    # Sparse linear solve\n)\n</code></pre> <p>See <code>vajax/analysis/sparse.py</code> for details.</p>"},{"location":"api_reference/#example-complete-workflow","title":"Example: Complete Workflow","text":"<pre><code>from vajax import CircuitEngine, configure_precision\nfrom vajax.io import write_rawfile\n\n# Configure precision\nconfigure_precision(force_x64=True)\n\n# Load and parse circuit\nengine = CircuitEngine(\"ring_oscillator.sim\")\nengine.parse()\n\n# Run transient analysis\nengine.prepare(t_stop=100e-9, dt=1e-9, use_sparse=True)\ntran = engine.run_transient()\nprint(f\"Transient: {tran.num_steps} steps, final Vout={tran.voltage('out')[-1]:.3f}V\")\n\n# Run AC analysis\nac = engine.run_ac(freq_start=1e3, freq_stop=1e9, points=100)\nprint(f\"AC: {len(ac.frequencies)} frequency points\")\n\n# Run noise analysis\nnoise = engine.run_noise(freq_start=1e3, freq_stop=1e9, input_source=\"vin\", out=\"vout\")\n\n# Save results\nwrite_rawfile(tran, \"transient.raw\")\n</code></pre>"},{"location":"api_reference/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Command-line interface</li> <li>Architecture Overview - System design</li> <li>GPU Solver Architecture - Performance optimization</li> </ul>"},{"location":"architecture_overview/","title":"VAJAX Architecture Overview","text":"<p>This document provides a high-level overview of VAJAX's architecture for developers new to the codebase.</p>"},{"location":"architecture_overview/#design-philosophy","title":"Design Philosophy","text":"<p>VAJAX is built on three core principles:</p> <ol> <li>Functional Device Models: Devices are pure JAX functions compiled from Verilog-A</li> <li>Automatic Differentiation: Jacobians computed via JAX autodiff, no explicit derivatives</li> <li>Vectorization: Same-type devices evaluated in parallel via <code>jax.vmap</code></li> </ol>"},{"location":"architecture_overview/#system-architecture","title":"System Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           User Code                                  \u2502\n\u2502   from vajax import CircuitEngine                               \u2502\n\u2502   engine = CircuitEngine(\"circuit.sim\")                             \u2502\n\u2502   engine.parse()                                                     \u2502\n\u2502   result = engine.run_transient()                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    CircuitEngine (analysis/engine.py)                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 run_transient\u2502 \u2502     run_ac       \u2502  \u2502    run_noise         \u2502  \u2502\n\u2502  \u2502 (lax.scan)  \u2502  \u2502 (AC analysis)    \u2502  \u2502  (noise analysis)    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 run_corners \u2502  \u2502   run_dcinc      \u2502  \u2502  run_dcxf/run_acxf   \u2502  \u2502\n\u2502  \u2502 (PVT sweep) \u2502  \u2502 (transfer funcs) \u2502  \u2502 (transfer functions)  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          Device Layer                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502              OpenVAF Compiled Verilog-A Models                \u2502  \u2502\n\u2502  \u2502    resistor.va  capacitor.va  diode.va  psp103.va  ...       \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502              Built-in Sources (vsource.py)                    \u2502  \u2502\n\u2502  \u2502    DC, Pulse, Sine, PWL voltage/current sources               \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           JAX Runtime                                \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502     \u2502     JIT      \u2502  \u2502    vmap     \u2502  \u2502   Autodiff         \u2502      \u2502\n\u2502     \u2502 Compilation  \u2502  \u2502 Batched     \u2502  \u2502 (Jacobians via     \u2502      \u2502\n\u2502     \u2502 (lax.scan)   \u2502  \u2502 Device Eval \u2502  \u2502  jacfwd/jvp)       \u2502      \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture_overview/#data-flow-circuit-parsing-and-setup","title":"Data Flow: Circuit Parsing and Setup","text":"<pre><code>1. Load Circuit File\n   \u2514\u2500\u2500 engine = CircuitEngine(\"circuit.sim\")\n       \u2514\u2500\u2500 engine.parse()\n\n2. Netlist Processing\n   \u251c\u2500\u2500 Parse VACASK .sim file or SPICE netlist\n   \u251c\u2500\u2500 Load device models (.osdi files via OpenVAF)\n   \u251c\u2500\u2500 Build node map (node name \u2192 index)\n   \u2514\u2500\u2500 Flatten hierarchical instances\n\n3. Device Compilation\n   \u251c\u2500\u2500 Compile Verilog-A models with OpenVAF\n   \u251c\u2500\u2500 Generate JAX-compatible device functions\n   \u2514\u2500\u2500 Batch devices by type for vmap evaluation\n\n4. System Builder\n   \u2514\u2500\u2500 _make_full_mna_build_system_fn()\n       \u251c\u2500\u2500 Creates JIT-compiled residual/Jacobian builder\n       \u251c\u2500\u2500 Uses full MNA with branch currents as unknowns\n       \u251c\u2500\u2500 Batches device evaluations via vmap\n       \u2514\u2500\u2500 Handles sparse vs dense matrix assembly\n</code></pre>"},{"location":"architecture_overview/#data-flow-transient-analysis","title":"Data Flow: Transient Analysis","text":"<pre><code>1. Initial Conditions\n   \u2514\u2500\u2500 Run DC operating point via Newton-Raphson\n\n2. Time Integration (lax.scan)\n   \u2502\n   \u251c\u2500\u2500 For each time step t = dt, 2*dt, ..., t_stop:\n   \u2502   \u2502\n   \u2502   \u251c\u2500\u2500 Update source waveforms (pulse, sine, PWL)\n   \u2502   \u2502\n   \u2502   \u251c\u2500\u2500 Build system (residual f, Jacobian J)\n   \u2502   \u2502   \u251c\u2500\u2500 Evaluate all devices via batched vmap\n   \u2502   \u2502   \u251c\u2500\u2500 Stamp currents \u2192 residual vector\n   \u2502   \u2502   \u2514\u2500\u2500 Stamp conductances \u2192 Jacobian matrix\n   \u2502   \u2502\n   \u2502   \u251c\u2500\u2500 Newton-Raphson iteration (lax.while_loop):\n   \u2502   \u2502   \u251c\u2500\u2500 Solve: delta_V = solve(J, -f)\n   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Dense: jax.scipy.linalg.solve()\n   \u2502   \u2502   \u2502   \u2514\u2500\u2500 Sparse: jax.experimental.sparse.linalg.spsolve()\n   \u2502   \u2502   \u251c\u2500\u2500 Update: V = V + delta_V\n   \u2502   \u2502   \u2514\u2500\u2500 Check: max(|f|) &lt; abstol?\n   \u2502   \u2502\n   \u2502   \u2514\u2500\u2500 Store solution: V[t] appended to trajectory\n   \u2502\n   \u2514\u2500\u2500 Return TransientResult(times, voltages)\n\n3. GPU Efficiency\n   \u2514\u2500\u2500 lax.scan enables full GPU execution without Python callbacks\n</code></pre>"},{"location":"architecture_overview/#key-classes","title":"Key Classes","text":""},{"location":"architecture_overview/#circuitengine-analysisenginepy","title":"CircuitEngine (<code>analysis/engine.py</code>)","text":"<p>The central class that manages circuit parsing, device compilation, and analysis.</p> <pre><code>class CircuitEngine:\n    # Core data\n    circuit_file: str                  # Path to .sim or SPICE file\n    node_map: Dict[str, int]           # Node name \u2192 index\n    models: Dict[str, CompiledModel]   # OpenVAF compiled models\n    device_data: Dict[str, DeviceInfo] # Device instances and parameters\n\n    # Parsing\n    def parse() -&gt; None                # Parse netlist, compile models\n\n    # Analysis methods\n    def prepare(t_stop, dt, ...) -&gt; None\n    def run_transient() -&gt; TransientResult\n    def run_ac(freq_start, freq_stop, ...) -&gt; ACResult\n    def run_noise(out, input_source, ...) -&gt; NoiseResult\n    def run_corners(corners) -&gt; CornerSweepResult\n    def run_dcinc() -&gt; DCIncResult\n    def run_dcxf(out) -&gt; DCXFResult\n    def run_acxf(out, freq_start, freq_stop, ...) -&gt; ACXFResult\n\n    # Internal system building\n    def _make_full_mna_build_system_fn() -&gt; Callable\n</code></pre>"},{"location":"architecture_overview/#transientresult","title":"TransientResult","text":"<p>The output of transient analysis.</p> <pre><code>@dataclass\nclass TransientResult:\n    times: Array                       # Shape: (n_steps,) time points\n    voltages: Dict[str, Array]         # node_name \u2192 voltage array\n    currents: Dict[str, Array]         # source_name \u2192 current array\n    stats: Dict[str, Any]             # Simulation statistics (wall_time, etc.)\n\n    # Properties\n    num_steps: int                     # len(times)\n    node_names: List[str]             # list(voltages.keys())\n    source_names: List[str]           # list(currents.keys())\n\n    # Methods\n    def voltage(node: str) -&gt; Array    # Case-insensitive node voltage lookup\n    def current(source: str) -&gt; Array  # Case-insensitive source current lookup\n</code></pre>"},{"location":"architecture_overview/#openvaf-device-interface","title":"OpenVAF Device Interface","text":"<p>Devices are compiled from Verilog-A and evaluated in batches:</p> <pre><code># OpenVAF compiles Verilog-A to JAX-compatible functions\nmodel = compile_va(\"resistor.va\")\n\n# Device evaluation function signature (simplified):\ndef device_fn(\n    voltages: Array,     # Terminal voltages [n_devices, n_terminals]\n    params: Array,       # Device parameters [n_devices, n_params]\n    temperature: float,  # Operating temperature\n) -&gt; Tuple[Array, Array]:\n    # Returns (currents, conductances) for MNA stamping\n    ...\n\n# Batched evaluation via vmap\ncurrents, G = jax.vmap(device_fn)(V_terminals, params_batch, temp)\n</code></pre>"},{"location":"architecture_overview/#device-model-interface","title":"Device Model Interface","text":""},{"location":"architecture_overview/#openvaf-compilation-pipeline","title":"OpenVAF Compilation Pipeline","text":"<p>All devices are compiled from Verilog-A source:</p> <pre><code>resistor.va  \u2192  OpenVAF Compiler  \u2192  MIR/OSDI  \u2192  JAX Function\n</code></pre> <p>Example Verilog-A source (<code>resistor.va</code>): <pre><code>module resistor(p, n);\n    inout p, n;\n    electrical p, n;\n    parameter real r = 1k;\n    parameter real tc1 = 0.0;\n    parameter real tc2 = 0.0;\n\n    analog begin\n        I(p, n) &lt;+ V(p, n) / r * (1 + tc1*dT + tc2*dT*dT);\n    end\nendmodule\n</code></pre></p> <p>OpenVAF compiles this to a pure JAX function that: - Takes terminal voltages and parameters as input - Returns currents and conductance matrix - Is automatically differentiable for Jacobian computation - Can be batched with <code>jax.vmap</code> for parallel evaluation</p>"},{"location":"architecture_overview/#why-verilog-a-openvaf","title":"Why Verilog-A + OpenVAF?","text":"<ol> <li>PDK Compatibility: Use production models (PSP103, BSIM4) directly</li> <li>Standardization: Industry-standard compact model format</li> <li>Validation: Models tested against commercial simulators</li> <li>Maintainability: One source for all backends (JAX, VACASK, ngspice)</li> </ol>"},{"location":"architecture_overview/#sparse-matrix-support","title":"Sparse Matrix Support","text":"<p>For large circuits (&gt;1000 nodes), VAJAX uses JAX's native sparse formats:</p> <pre><code>from jax.experimental.sparse import BCOO, BCSR\nfrom jax.experimental.sparse.linalg import spsolve\n\n# Build sparse Jacobian from COO triplets\ndef build_sparse_jacobian(rows, cols, values, shape):\n    # Use pure JAX for COO\u2192CSR conversion\n    data, indices, indptr = build_csr_arrays(rows, cols, values, shape)\n    return data, indices, indptr\n\n# Solve sparse system\n# JAX spsolve works on CPU and GPU (via cuSOLVER)\ndelta_V = spsolve(data, indices, indptr, -residual, tol=0)\n</code></pre>"},{"location":"architecture_overview/#sparse-formats","title":"Sparse Formats","text":"Format Usage Notes BCOO Matrix construction JAX native COO, efficient for building BCSR Linear solve CSR required by spsolve"},{"location":"architecture_overview/#when-sparse-is-used","title":"When Sparse is Used","text":"Circuit Size Solver Reason &lt; 1000 nodes Dense Lower overhead, <code>jax.scipy.linalg.solve()</code> \u2265 1000 nodes Sparse Memory efficiency, <code>spsolve()</code> <p>The switch is controlled by <code>use_sparse=True</code> in <code>prepare()</code>:</p> <pre><code>engine.prepare(t_stop=1e-6, dt=1e-9, use_sparse=True)\nresult = engine.run_transient()\n</code></pre>"},{"location":"architecture_overview/#openvaf-integration","title":"OpenVAF Integration","text":""},{"location":"architecture_overview/#compilation-pipeline","title":"Compilation Pipeline","text":"<pre><code>Verilog-A (.va)\n      \u2502\n      \u25bc\nOpenVAF Compiler\n      \u2502\n      \u25bc\nMIR (Mid-level IR)\n      \u2502\n      \u25bc\nopenvaf_jax Translator\n      \u2502\n      \u25bc\nJAX Function\n</code></pre>"},{"location":"architecture_overview/#verilogadevice-wrapper","title":"VerilogADevice Wrapper","text":"<pre><code>class VerilogADevice:\n    def __init__(self, compiled_model, params):\n        self.eval_fn = openvaf_jax.translate(compiled_model)\n        self.params = params\n        self.n_internal = compiled_model.n_internal_nodes\n\n    def evaluate(self, V, params, context):\n        # Call the JAX-translated function\n        outputs = self.eval_fn(V, params)\n\n        # Extract currents and conductances from outputs\n        return DeviceStamps(\n            currents=outputs.currents,\n            conductances=outputs.jacobian\n        )\n</code></pre>"},{"location":"architecture_overview/#performance-optimization","title":"Performance Optimization","text":""},{"location":"architecture_overview/#jit-compilation","title":"JIT Compilation","text":"<pre><code>@jax.jit\ndef newton_step(V, system, context):\n    residual, J = system.build_jacobian_and_residual(V, context)\n    delta_V = jnp.linalg.solve(J, -residual)\n    return V + delta_V\n</code></pre> <p>First call: ~1-5 seconds (compilation) Subsequent calls: ~1-20 ms</p>"},{"location":"architecture_overview/#vectorized-evaluation","title":"Vectorized Evaluation","text":"<pre><code># Without vectorization (slow)\ncurrents = []\nfor i in range(n_devices):\n    I = device_fn(V[nodes[i]], params[i])\n    currents.append(I)\n\n# With vectorization (fast)\ncurrents = jax.vmap(device_fn)(V[node_indices], batched_params)\n</code></pre> <p>Speedup: 10-100x depending on device count</p> <p>For a detailed walkthrough of how all these mechanisms compose for a real circuit, see Parallelism Architecture: c6288 Case Study.</p>"},{"location":"architecture_overview/#batched-parameter-arrays","title":"Batched Parameter Arrays","text":"<p>Pre-computing parameter arrays eliminates Python loops:</p> <pre><code># During build_device_groups()\nparams = {\n    \"r\": jnp.array([d.params[\"r\"] for d in resistors]),\n    \"tc1\": jnp.array([d.params.get(\"tc1\", 0) for d in resistors]),\n}\n# Now vmap can use these directly\n</code></pre>"},{"location":"architecture_overview/#convergence-strategies","title":"Convergence Strategies","text":""},{"location":"architecture_overview/#source-stepping","title":"Source Stepping","text":"<p>Gradually ramps supply voltage from 0 to target:</p> <pre><code>VDD steps: 0.0 \u2192 0.12 \u2192 0.24 \u2192 ... \u2192 1.2V\n\nAt each step:\n1. Solve DC with current VDD\n2. Use solution as initial guess for next step\n</code></pre> <p>Helps with digital circuits that have multiple stable states.</p>"},{"location":"architecture_overview/#gmin-stepping","title":"GMIN Stepping","text":"<p>Adds decreasing conductance to ground at each node:</p> <pre><code>GMIN steps: 1e-3 \u2192 1e-6 \u2192 1e-9 \u2192 1e-12 S\n\nAt each step:\n1. Add GMIN*V to residual (pulls nodes toward 0)\n2. Solve DC\n3. Reduce GMIN and repeat\n</code></pre> <p>Prevents floating nodes and improves conditioning.</p>"},{"location":"architecture_overview/#file-reference","title":"File Reference","text":"File Purpose <code>analysis/engine.py</code> CircuitEngine - main simulation API, parsing, all analyses <code>analysis/solver.py</code> Newton-Raphson solver with <code>lax.while_loop</code> <code>analysis/transient/</code> Transient analysis (scan/loop strategies) <code>analysis/ac.py</code> AC small-signal analysis <code>analysis/noise.py</code> Noise analysis <code>analysis/hb.py</code> Harmonic balance analysis <code>analysis/xfer.py</code> Transfer function (DCINC, DCXF, ACXF) <code>analysis/corners.py</code> PVT corner analysis <code>analysis/homotopy.py</code> Convergence aids (GMIN, source stepping) <code>analysis/sparse.py</code> JAX sparse utilities (BCOO/BCSR, spsolve) <code>devices/vsource.py</code> Voltage/current source waveforms <code>devices/verilog_a.py</code> OpenVAF Verilog-A device wrapper <code>netlist/parser.py</code> VACASK netlist parser <code>benchmarks/runner.py</code> VACASK benchmark runner <code>benchmarks/registry.py</code> Auto-discovery of benchmark circuits"},{"location":"architecture_overview/#common-patterns","title":"Common Patterns","text":""},{"location":"architecture_overview/#loading-and-running-a-circuit","title":"Loading and Running a Circuit","text":"<pre><code>from vajax import CircuitEngine\n\n# Load circuit from VACASK .sim file\nengine = CircuitEngine(\"vendor/VACASK/sim/ring.sim\")\nengine.parse()\n\n# Prepare and run transient analysis\nengine.prepare(t_stop=1e-6, dt=1e-9, use_sparse=True)\nresult = engine.run_transient()\n</code></pre>"},{"location":"architecture_overview/#extracting-results","title":"Extracting Results","text":"<pre><code># Get all node voltages at final time\nfor node_name, voltages in result.voltages.items():\n    print(f\"{node_name}: {voltages[-1]:.3f}V\")\n\n# Get specific node over time\nvout = result.voltages[\"out\"]  # Array of voltages\n\n# Time array\ntimes = result.times\n</code></pre>"},{"location":"architecture_overview/#running-multiple-analysis-types","title":"Running Multiple Analysis Types","text":"<pre><code># Transient\nengine.prepare(t_stop=1e-6, dt=1e-9)\ntran_result = engine.run_transient()\n\n# AC analysis\nac_result = engine.run_ac(freq_start=1e3, freq_stop=1e9, points=100)\n\n# Noise analysis\nnoise_result = engine.run_noise(\n    freq_start=1e3, freq_stop=1e9,\n    input_source=\"vin\", out=\"vout\"\n)\n\n# PVT corners\nfrom vajax.analysis.corners import create_pvt_corners\ncorners = create_pvt_corners(\n    processes=['TT', 'FF', 'SS'],\n    voltages=[0.9, 1.0, 1.1],\n    temperatures=['cold', 'room', 'hot'],\n)\ncorner_results = engine.run_corners(corners)\n</code></pre>"},{"location":"architecture_overview/#debugging-entry-points","title":"Debugging Entry Points","text":"<p>When investigating issues, start here:</p> <ol> <li>Parsing issues: Check <code>CircuitEngine.parse()</code> in <code>engine.py</code></li> <li>Device compilation: Check OpenVAF model loading in <code>_compile_openvaf_models()</code></li> <li>System building: Check <code>_make_full_mna_build_system_fn()</code> for J/f construction</li> <li>Convergence issues: Look at Newton-Raphson loop in <code>solver.py</code></li> <li>Sparse solver: Check <code>sparse.py</code> for BCOO/BCSR operations</li> <li>Source waveforms: Check <code>vsource.py</code> for pulse/sine/PWL evaluation</li> </ol>"},{"location":"ci-status/","title":"VAJAX CI Summary","text":"<p>Last updated: 2026-02-27 10:43 UTC</p> <p>Commit: af3a5fb5</p>"},{"location":"ci-status/#test-coverage","title":"Test Coverage","text":"Suite Passed Failed Errors Skipped Total Time benchmark-dense 5 0 0 2 7 350.2s benchmark-sparse 6 1 0 2 9 2349.3s benchmarks 5 0 0 0 5 358.5s ngspice 0 1 0 70 71 245.7s openvaf-py 320 0 0 92 412 1073.3s unit 72 0 0 5 77 19.5s xyce 39 0 0 1890 1929 66.5s Total 447 2 0 2061 2510 4463.0s"},{"location":"ci-status/#performance","title":"Performance","text":""},{"location":"ci-status/#cpu-benchmarks","title":"CPU Benchmarks","text":"Benchmark Steps VAJAX (ms/step) VACASK (ms/step) Ratio Startup rc 1,000,000 0.0146 0.0019 7.86x 4.4s graetz 1,000,000 0.0213 0.0038 5.57x 10.5s mul 500,000 0.0435 0.0038 11.36x 8.1s ring 19,999 0.6344 0.1086 5.84x 209.9s tb_dp 299 0.1059 N/A N/A 6.7s"},{"location":"ci-status/#gpu-benchmarks","title":"GPU Benchmarks","text":"Benchmark Steps VAJAX (ms/step) VACASK (ms/step) Ratio Startup rc 1,000,000 0.2367 0.0009 253.11x 4.1s graetz 1,000,000 0.3113 0.0019 164.72x 10.0s mul 500,000 0.4536 N/A N/A 7.7s ring 19,999 1.4995 0.0453 33.12x 190.0s c6288 1,000 20.0046 56.7875 0.35x 222.3s <p>View workflows |  Repository</p>"},{"location":"cli_reference/","title":"VAJAX CLI Reference","text":"<p>The <code>vajax</code> command-line interface provides ngspice-style access to circuit simulation.</p>"},{"location":"cli_reference/#installation","title":"Installation","text":"<p>After installing vajax, the CLI is available:</p> <pre><code># Install with uv\nuv sync\n\n# Verify installation\nvajax --version\nvajax --help\n</code></pre>"},{"location":"cli_reference/#basic-usage","title":"Basic Usage","text":"<pre><code># Run simulation on a circuit file\nvajax circuit.sim\n\n# Specify output file\nvajax circuit.sim -o results.raw\n\n# Run with specific output format\nvajax circuit.sim -o results.csv --format csv\n</code></pre>"},{"location":"cli_reference/#commands","title":"Commands","text":""},{"location":"cli_reference/#run-default","title":"<code>run</code> (default)","text":"<p>Run circuit simulation. This is the default command when a circuit file is provided.</p> <pre><code># These are equivalent:\nvajax circuit.sim\nvajax run circuit.sim\n</code></pre> <p>Options:</p> Option Description <code>-o, --output FILE</code> Output file path (default: circuit.raw) <code>-f, --format FMT</code> Output format: <code>raw</code>, <code>csv</code>, <code>json</code> (default: raw) <code>--tran DT TSTOP</code> Override transient analysis parameters <code>--ac TYPE PTS FSTART FSTOP</code> AC analysis (dec/lin/oct, points, freq range) <code>--sparse</code> Force sparse solver (for large circuits) <code>--no-scan</code> Disable lax.scan (use Python loop) <code>--gpu</code> Force GPU backend <code>--cpu</code> Force CPU backend <code>--x64</code> Force float64 precision <code>--x32</code> Force float32 precision <code>--profile</code> Enable profiling <p>Examples:</p> <pre><code># Transient analysis with custom parameters\nvajax circuit.sim --tran 1n 100u\n\n# AC analysis\nvajax circuit.sim --ac dec 100 1k 1G\n\n# Large circuit with sparse solver on GPU\nvajax large_circuit.sim --sparse --gpu\n\n# Force float64 precision on CPU\nvajax circuit.sim --cpu --x64\n</code></pre>"},{"location":"cli_reference/#benchmark","title":"<code>benchmark</code>","text":"<p>Run benchmark circuits from the VACASK test suite.</p> <pre><code># List available benchmarks\nvajax benchmark --list\n\n# Run a specific benchmark\nvajax benchmark ring\n\n# Run with profiling\nvajax benchmark ring --profile\n</code></pre> <p>Options:</p> Option Description <code>-l, --list</code> List available benchmarks <code>--sparse</code> Force sparse solver <code>--x64</code> Force float64 precision <code>--x32</code> Force float32 precision <code>--profile</code> Enable timing profiling"},{"location":"cli_reference/#convert","title":"<code>convert</code>","text":"<p>Convert SPICE netlists to VACASK format.</p> <pre><code>vajax convert input.sp output.sim\n</code></pre>"},{"location":"cli_reference/#info","title":"<code>info</code>","text":"<p>Display system information.</p> <pre><code>vajax info\n</code></pre> <p>Shows: - JAX backend (CPU, CUDA, Metal) - Float64 support status - Available devices</p>"},{"location":"cli_reference/#output-formats","title":"Output Formats","text":""},{"location":"cli_reference/#raw-ngspice-compatible","title":"Raw (ngspice-compatible)","text":"<p>Binary format compatible with ngspice tools and gwave waveform viewer.</p> <pre><code>vajax circuit.sim -o results.raw --format raw\n</code></pre> <p>Read with ngspice: <pre><code>ngspice&gt; load results.raw\nngspice&gt; plot v(out)\n</code></pre></p> <p>Read with gwave: <pre><code>gwave results.raw\n</code></pre></p>"},{"location":"cli_reference/#csv","title":"CSV","text":"<p>Comma-separated values, compatible with spreadsheets and data analysis tools.</p> <pre><code>vajax circuit.sim -o results.csv --format csv\n</code></pre> <p>Format: <pre><code>time,node1,node2,...\n0.0,0.0,1.2,...\n1e-9,0.1,1.1,...\n</code></pre></p>"},{"location":"cli_reference/#json","title":"JSON","text":"<p>JSON format for programmatic processing.</p> <pre><code>vajax circuit.sim -o results.json --format json\n</code></pre> <p>Format: <pre><code>{\n  \"times\": [0.0, 1e-9, ...],\n  \"voltages\": {\n    \"node1\": [0.0, 0.1, ...],\n    \"node2\": [1.2, 1.1, ...]\n  }\n}\n</code></pre></p>"},{"location":"cli_reference/#environment-variables","title":"Environment Variables","text":"Variable Description <code>JAX_PLATFORMS</code> Force JAX platform: <code>cpu</code>, <code>cuda</code>, <code>gpu</code> <code>JAX_ENABLE_X64</code> Enable float64: <code>1</code> or <code>0</code> <code>NGSPICE_BIN</code> Path to ngspice binary (for convert)"},{"location":"cli_reference/#examples","title":"Examples","text":""},{"location":"cli_reference/#transient-analysis","title":"Transient Analysis","text":"<pre><code># Basic transient simulation\nvajax ring_oscillator.sim --tran 1n 10u\n\n# Large circuit with sparse solver\nvajax c6288.sim --tran 1n 100n --sparse\n\n# GPU acceleration\nvajax ring_oscillator.sim --gpu --tran 1n 10u\n</code></pre>"},{"location":"cli_reference/#ac-analysis","title":"AC Analysis","text":"<pre><code># Decade sweep, 100 points per decade\nvajax amplifier.sim --ac dec 100 1k 1G\n\n# Linear sweep\nvajax filter.sim --ac lin 1000 1k 10k\n</code></pre>"},{"location":"cli_reference/#benchmarking","title":"Benchmarking","text":"<pre><code># Run ring oscillator benchmark with profiling\nvajax benchmark ring --profile\n\n# Compare sparse vs dense solver\nvajax benchmark mul --profile\nvajax benchmark mul --profile --sparse\n</code></pre>"},{"location":"cli_reference/#batch-processing","title":"Batch Processing","text":"<pre><code># Process multiple circuits\nfor f in circuits/*.sim; do\n    vajax \"$f\" -o \"results/$(basename \"$f\" .sim).raw\"\ndone\n</code></pre>"},{"location":"cli_reference/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cli_reference/#gpu-not-detected","title":"GPU Not Detected","text":"<pre><code># Check system info\nvajax info\n\n# Force CPU fallback\nvajax circuit.sim --cpu\n</code></pre>"},{"location":"cli_reference/#convergence-issues","title":"Convergence Issues","text":"<p>For difficult circuits, try: <pre><code># Use sparse solver for better conditioning\nvajax circuit.sim --sparse\n\n# Force double precision\nvajax circuit.sim --x64\n</code></pre></p>"},{"location":"cli_reference/#out-of-memory","title":"Out of Memory","text":"<p>For large circuits: <pre><code># Use sparse solver (required for &gt;1000 nodes)\nvajax large_circuit.sim --sparse\n</code></pre></p>"},{"location":"cli_reference/#see-also","title":"See Also","text":"<ul> <li>README.md - Getting started guide</li> <li>Architecture Overview - System design</li> <li>GPU Solver Architecture - Performance optimization</li> </ul>"},{"location":"debug_tools/","title":"Debug Tools Reference","text":"<p>This document describes the debugging utilities in <code>vajax.debug</code> for troubleshooting OSDI vs JAX discrepancies.</p>"},{"location":"debug_tools/#quick-start","title":"Quick Start","text":"<pre><code>from vajax.debug import quick_compare, inspect_model\n\n# Compare OSDI vs JAX at a bias point\nresult = quick_compare(\n    va_path=\"vendor/OpenVAF/integration_tests/PSP102/psp102.va\",\n    osdi_path=\"/tmp/osdi_jax_test_cache/psp102.osdi\",\n    params={'TYPE': 1, 'W': 1e-6, 'L': 1e-7},\n    voltages=[0.5, 0.6, 0.0, 0.0],\n)\nprint(result)\n\n# Inspect MIR structure\ninspect_model(\"vendor/OpenVAF/integration_tests/PSP102/psp102.va\")\n\n# Graph-based queries (requires networkx)\nfrom vajax.debug import MIRGraph\ngraph = MIRGraph.from_va_file(\"model.va\", func='eval')\ngraph.dae_residual('dt')      # Find residual variable\ngraph.param_to_value('rth')   # Map param to MIR value\n</code></pre>"},{"location":"debug_tools/#module-overview","title":"Module Overview","text":"Module Purpose <code>model_comparison</code> Compare OSDI vs JAX outputs (residuals, Jacobians, cache) <code>mir_inspector</code> Inspect MIR data (params, PHI nodes, constants) <code>mir_graph</code> Graph-based MIR queries (requires networkx) <code>jacobian</code> Format-aware Jacobian comparison (OSDI sparse vs JAX dense) <code>mir_tracer</code> Trace value flow through MIR <code>param_analyzer</code> Analyze parameter kinds and OSDI comparison <code>mir_analysis</code> CFG analysis with networkx (optional dependency) <code>transient_diagnostics</code> Runtime transient step analysis (LTE, NR, step acceptance)"},{"location":"debug_tools/#model-comparison-model_comparisonpy","title":"Model Comparison (<code>model_comparison.py</code>)","text":""},{"location":"debug_tools/#modelcomparator","title":"ModelComparator","text":"<p>Full-featured comparison between OSDI and JAX implementations.</p> <pre><code>from vajax.debug import ModelComparator\n\ncomparator = ModelComparator(\n    va_path=\"path/to/model.va\",\n    osdi_path=\"path/to/model.osdi\",\n    params={'TYPE': 1, 'W': 1e-6, 'L': 1e-7},\n    temperature=300.0,\n)\n\n# Compare at a single bias point\nresult = comparator.compare_at_bias([0.5, 0.6, 0.0, 0.0])\nprint(result)\nprint(f\"Passed: {result.passed}\")\nprint(f\"Issues: {result.issues}\")\n\n# Print side-by-side residual table\ncomparator.print_residual_table([0.5, 0.6, 0.0, 0.0])\n\n# Analyze cache for potential issues\ncache_analysis = comparator.analyze_cache()\nprint(cache_analysis)\n\n# Sweep comparison\nresults = comparator.sweep_comparison(\n    base_voltages=[0.5, 0.0, 0.0, 0.0],\n    sweep_index=1,  # Sweep Vgs\n    sweep_values=[0.0, 0.3, 0.6, 0.9, 1.2],\n)\n</code></pre>"},{"location":"debug_tools/#cacheanalysis","title":"CacheAnalysis","text":"<p>Detects potential issues in JAX cache values:</p> <ul> <li>inf/nan detection: Catches numerical instabilities</li> <li>Large values: Flags values &gt; 1e10 that might cause overflow</li> <li>Temperature-related: Finds VT values (0.025-0.030) and their implied temperatures</li> </ul> <pre><code>cache = comparator.analyze_cache()\nprint(f\"Cache size: {cache.size}\")\nprint(f\"Non-zero: {cache.nonzero_count}\")\nprint(f\"Has inf: {cache.has_inf}\")\nprint(f\"Has nan: {cache.has_nan}\")\n\n# Check temperature values\nfor idx, val, implied_t in cache.temperature_related:\n    print(f\"cache[{idx}] = {val:.6f} implies T = {implied_t:.1f}K\")\n</code></pre>"},{"location":"debug_tools/#mir-inspector-mir_inspectorpy","title":"MIR Inspector (<code>mir_inspector.py</code>)","text":""},{"location":"debug_tools/#mirinspector","title":"MIRInspector","text":"<p>Examine MIR (Mid-level IR) structure for debugging translation issues.</p> <pre><code>from vajax.debug import MIRInspector\n\ninspector = MIRInspector(\"path/to/model.va\")\n\n# Overall statistics\ninspector.print_mir_stats()\n\n# Parameter summary\ninspector.print_param_summary('eval')  # or 'init'\n\n# PHI node analysis\ninspector.print_phi_summary('eval')\n\n# Find TYPE parameter (NMOS/PMOS models)\ninspector.print_type_param_info()\n</code></pre>"},{"location":"debug_tools/#finding-specific-values","title":"Finding Specific Values","text":"<pre><code># Find constants near a value (e.g., P_CELSIUS0 = 273.15)\nconstants = inspector.find_constants_near(273.15, tolerance=0.01)\nfor name, value in constants:\n    print(f\"{name} = {value}\")\n\n# Find PHI nodes with zero operand (indicates conditional branch)\nzero_phis = inspector.find_phi_nodes_with_value('v3')  # v3 is typically 0.0\nfor phi in zero_phis[:5]:\n    print(f\"PHI {phi.result} in {phi.block}\")\n    for pred, val in phi.operands:\n        print(f\"  {pred} -&gt; {val}\")\n</code></pre>"},{"location":"debug_tools/#mir-graph-mir_graphpy","title":"MIR Graph (<code>mir_graph.py</code>)","text":"<p>Graph-based queries for MIR analysis. Requires <code>networkx</code>.</p>"},{"location":"debug_tools/#mirgraph","title":"MIRGraph","text":"<p>Build a queryable graph from a VA model:</p> <pre><code>from vajax.debug import MIRGraph\n\ngraph = MIRGraph.from_va_file(\"model.va\", func='eval', include_dae=True)\n</code></pre>"},{"location":"debug_tools/#value-tracing","title":"Value Tracing","text":"<pre><code># What instruction defines a value?\ngraph.who_defines('v273116')\n# Returns: {'opcode': 'optbarrier', 'block': 'block1458', ...}\n\n# What instructions use a value?\ngraph.who_uses('v142825')\n# Returns: [{'target': 'value:v142827', 'opcode': 'fgt', ...}, ...]\n\n# Trace dependencies backwards\ngraph.trace_back('v273116', depth=5)\n\n# Trace usage forwards\ngraph.trace_forward('v142825', depth=5)\n</code></pre>"},{"location":"debug_tools/#parameter-mapping","title":"Parameter Mapping","text":"<pre><code># Find MIR value ID for a parameter\ngraph.param_to_value('rth')  # Returns 'v142825'\n\n# Reverse lookup\ngraph.value_to_param('v142825')  # Returns 'rth'\n</code></pre>"},{"location":"debug_tools/#dae-system-queries","title":"DAE System Queries","text":"<pre><code># Get resist/react value IDs for a node\ngraph.dae_residual('dt')\n# Returns: {'resist': 'v273116', 'react': 'v273117'}\n</code></pre>"},{"location":"debug_tools/#control-flow","title":"Control Flow","text":"<pre><code># Find path from entry to a block\ngraph.path_to_block('block1451')\n# Returns: ['block0', 'block4', ..., 'block1450', 'block1451']\n\n# Get PHI nodes in a block\ngraph.phi_info('block1453')\n# Returns: [{'result': 'v252438', 'operands': [...], ...}, ...]\n\n# Get branch condition for a block\ngraph.branch_condition('block1450')\n# Returns: {'condition': 'v142827', 'true_block': 'block1451', 'false_block': 'block1453'}\n\n# Find all blocks that branch on a value\ngraph.blocks_with_condition('v142827')\n# Returns: ['block1450']\n</code></pre>"},{"location":"debug_tools/#constants","title":"Constants","text":"<pre><code># Check if a value is a constant\nis_const, value = graph.is_constant('v3')\n# Returns: (True, 0.0)\n</code></pre>"},{"location":"debug_tools/#jacobian-comparison-jacobianpy","title":"Jacobian Comparison (<code>jacobian.py</code>)","text":"<p>Format-aware comparison between OSDI (sparse, column-major) and JAX (dense, row-major).</p> <pre><code>from vajax.debug import compare_jacobians, print_jacobian_structure\n\n# Compare Jacobians\nresult = compare_jacobians(\n    osdi_jac, jax_jac, n_nodes, jacobian_keys,\n    rtol=1e-4, atol=1e-10\n)\nprint(result.report)\nprint(f\"Passed: {result.passed}\")\nprint(f\"Max abs diff: {result.max_abs_diff}\")\nprint(f\"Mismatched positions: {result.mismatched_positions}\")\n\n# Print structure\nprint_jacobian_structure(jacobian_keys, n_nodes)\n</code></pre>"},{"location":"debug_tools/#cli-tools","title":"CLI Tools","text":""},{"location":"debug_tools/#mir-cfg-analyzer","title":"MIR CFG Analyzer","text":"<p>Analyze control flow graph from command line:</p> <pre><code># Find PHI nodes\nuv run scripts/analyze_mir_cfg.py vendor/OpenVAF/integration_tests/PSP102/psp102.va \\\n    --func eval --find-phis\n\n# Find branch points\nuv run scripts/analyze_mir_cfg.py vendor/OpenVAF/integration_tests/PSP102/psp102.va \\\n    --func eval --branches\n\n# Trace paths to a block\nuv run scripts/analyze_mir_cfg.py vendor/OpenVAF/integration_tests/PSP102/psp102.va \\\n    --func eval --target block123\n\n# Analyze specific block with PHIs\nuv run scripts/analyze_mir_cfg.py vendor/OpenVAF/integration_tests/PSP102/psp102.va \\\n    --func eval --analyze-block block4654\n</code></pre>"},{"location":"debug_tools/#transient-diagnostics-transient_diagnosticspy","title":"Transient Diagnostics (<code>transient_diagnostics.py</code>)","text":"<p>Runtime analysis of transient simulation steps \u2014 LTE behaviour, NR convergence, step acceptance/rejection, and VACASK comparison.</p>"},{"location":"debug_tools/#parsing-debug-output","title":"Parsing Debug Output","text":"<pre><code>from vajax.debug import parse_debug_output, StepRecord\n\n# Parse debug_steps text captured from a transient run\nrecords: list[StepRecord] = parse_debug_output(debug_text)\nfor r in records[:5]:\n    print(f\"Step {r.step}: t={r.t_ps}ps dt={r.dt_ps}ps NR={r.nr_iters} accepted={r.accepted}\")\n</code></pre>"},{"location":"debug_tools/#capturing-a-full-step-trace","title":"Capturing a Full Step Trace","text":"<pre><code>from vajax.debug import capture_step_trace, print_step_summary\n\n# Run a benchmark with debug_steps=True and get parsed results\nrecords, summary = capture_step_trace(\"ring\", use_sparse=True)\nprint_step_summary(records, summary)\n</code></pre>"},{"location":"debug_tools/#convergence-sweep","title":"Convergence Sweep","text":"<p>Run a benchmark at multiple <code>t_stop</code> values to find where convergence degrades:</p> <pre><code>from vajax.debug import convergence_sweep\n\nresults = convergence_sweep(\"graetz\", [1e-3, 5e-3, 7e-3, 10e-3])\nfor r in results:\n    print(f\"t_stop={r.t_stop:.0e}: steps={r.num_steps}, conv={r.convergence_rate:.1%}, \"\n          f\"rejected={r.rejected_steps}\")\n</code></pre>"},{"location":"debug_tools/#vacask-step-comparison","title":"VACASK Step Comparison","text":"<p>Parse VACASK <code>tran_debug=1</code> output for side-by-side comparison:</p> <pre><code>from vajax.debug import parse_vacask_debug_output\n\nvacask_records = parse_vacask_debug_output(vacask_stdout)\naccepted = [r for r in vacask_records if r.status == \"accept\"]\nrejected = [r for r in vacask_records if r.status == \"reject\"]\nprint(f\"VACASK: {len(accepted)} accepted, {len(rejected)} rejected\")\n</code></pre>"},{"location":"debug_tools/#lte-solver-comparison-cli","title":"LTE Solver Comparison CLI","text":"<p>Compare per-step LTE between different solver backends:</p> <pre><code># Capture a trace\nJAX_PLATFORMS=cpu uv run python scripts/compare_lte_solvers.py \\\n    --benchmark ring --output /tmp/lte_trace.json\n\n# Compare two traces\nuv run python scripts/compare_lte_solvers.py \\\n    --compare /tmp/trace_a.json /tmp/trace_b.json\n\n# Run both dense and sparse locally and compare\nJAX_PLATFORMS=cpu uv run python scripts/compare_lte_solvers.py \\\n    --benchmark ring --compare-local\n</code></pre>"},{"location":"debug_tools/#transient-debugging-workflow","title":"Transient Debugging Workflow","text":""},{"location":"debug_tools/#1-convergence-sweep","title":"1. Convergence Sweep","text":"<p>Start by checking if convergence degrades at specific simulation durations:</p> <pre><code>from vajax.debug import convergence_sweep\n\nresults = convergence_sweep(\"graetz\", [1e-3, 5e-3, 7e-3, 10e-3])\n# Look for t_stop values where rejected_steps spikes or convergence_rate drops\n</code></pre>"},{"location":"debug_tools/#2-capture-step-trace","title":"2. Capture Step Trace","text":"<p>Zoom in on a problematic duration with full per-step data:</p> <pre><code>from vajax.debug import capture_step_trace, print_step_summary\n\nrecords, summary = capture_step_trace(\"graetz\", use_sparse=False)\nprint_step_summary(records, summary)\n\n# Find rejection clusters\nrejected = [r for r in records if not r.accepted]\nfor r in rejected[:10]:\n    print(f\"  Step {r.step}: t={r.t_ps}ps LTE={r.lte_norm} NR_fail={r.nr_failed}\")\n</code></pre>"},{"location":"debug_tools/#3-vacask-comparison","title":"3. VACASK Comparison","text":"<p>Compare step-by-step behaviour with VACASK reference:</p> <pre><code>from vajax.debug import parse_debug_output, parse_vacask_debug_output\n\njax_records = parse_debug_output(jax_debug_text)\nvacask_records = parse_vacask_debug_output(vacask_debug_text)\n\n# Compare accepted step counts, dt ranges, rejection patterns\n</code></pre>"},{"location":"debug_tools/#debugging-workflow","title":"Debugging Workflow","text":""},{"location":"debug_tools/#1-initial-comparison","title":"1. Initial Comparison","text":"<pre><code>from vajax.debug import quick_compare\n\nresult = quick_compare(va_path, osdi_path, params, voltages)\nprint(result)\n\nif not result.passed:\n    print(\"Issues found:\")\n    for issue in result.issues:\n        print(f\"  - {issue}\")\n</code></pre>"},{"location":"debug_tools/#2-cache-analysis","title":"2. Cache Analysis","text":"<p>If residuals differ, check the cache first:</p> <pre><code>from vajax.debug import ModelComparator\n\ncomparator = ModelComparator(va_path, osdi_path, params)\ncache = comparator.analyze_cache()\n\n# Check for problems\nif cache.has_inf &gt; 0:\n    print(f\"WARNING: {cache.has_inf} inf values in cache\")\nif cache.has_nan &gt; 0:\n    print(f\"WARNING: {cache.has_nan} nan values in cache\")\n</code></pre>"},{"location":"debug_tools/#3-mir-inspection","title":"3. MIR Inspection","text":"<p>If cache looks OK, inspect MIR structure:</p> <pre><code>from vajax.debug import MIRInspector\n\ninspector = MIRInspector(va_path)\ninspector.print_mir_stats()\ninspector.print_phi_summary('eval')\n\n# For NMOS/PMOS models, check TYPE handling\ninspector.print_type_param_info()\n</code></pre>"},{"location":"debug_tools/#4-phi-node-analysis","title":"4. PHI Node Analysis","text":"<p>If PHI nodes are suspected:</p> <pre><code># Find PHIs with zero operand (often indicates branch issue)\nzero_phis = inspector.find_phi_nodes_with_value('v3')\nprint(f\"Found {len(zero_phis)} PHIs with zero operand\")\n\n# Use CLI for detailed analysis\n# uv run scripts/analyze_mir_cfg.py model.va --func eval --analyze-block blockXXX\n</code></pre>"},{"location":"debug_tools/#common-issues","title":"Common Issues","text":""},{"location":"debug_tools/#1-jax-returns-near-zero-current","title":"1. JAX returns near-zero current","text":"<p>Symptom: OSDI returns expected current, JAX returns ~1e-15</p> <p>Likely cause: PHI node resolution in NMOS/PMOS branching</p> <p>Debug steps: 1. Check TYPE parameter is passed correctly 2. Analyze PHI nodes for zero operands 3. Trace control flow with <code>--analyze-block</code></p>"},{"location":"debug_tools/#2-jacobian-sparsity-mismatch","title":"2. Jacobian sparsity mismatch","text":"<p>Symptom: OSDI has N non-zeros, JAX has M &lt;&lt; N</p> <p>Likely cause: Branch not taken, computations skipped</p> <p>Debug steps: 1. Use <code>print_jacobian_structure()</code> to see expected pattern 2. Check if missing entries follow a pattern (e.g., all in one row/column)</p>"},{"location":"debug_tools/#3-temperature-related-errors","title":"3. Temperature-related errors","text":"<p>Symptom: Current off by ~1% at room temperature</p> <p>Likely cause: TNOM vs $temperature handling</p> <p>Debug steps: 1. Check cache for VT values: <code>cache.temperature_related</code> 2. Verify expected VT at 300K: 0.02585 V 3. Check for sentinel values (1e21) in init params</p>"},{"location":"getting_started/","title":"Getting Started with VAJAX","text":"<p>This guide walks you through installing VAJAX and running your first circuit simulation.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11-3.13</li> <li>uv package manager</li> </ul>"},{"location":"getting_started/#installation","title":"Installation","text":"<pre><code># Clone the repository\ngit clone &lt;repo-url&gt;\ncd vajax\n\n# Install dependencies\nuv sync\n</code></pre> <p>For GPU support on NVIDIA:</p> <pre><code>uv sync --extra cuda12\n</code></pre>"},{"location":"getting_started/#your-first-simulation-rc-low-pass-filter","title":"Your First Simulation: RC Low-Pass Filter","text":"<p>Here's a simple RC circuit excited by a pulse train. Create a file called <code>rc.sim</code>:</p> <pre><code>RC circuit excited by a pulse train\n\nload \"spice/resistor.osdi\"\nload \"spice/capacitor.osdi\"\n\nmodel r sp_resistor\nmodel c sp_capacitor\nmodel vsource vsource\n\nvs (1 0) vsource dc=0 type=\"pulse\" val0=0 val1=1 rise=1u fall=1u width=1m period=2m\nr1 (1 2) r r=1k\nc1 (2 0) c c=1u\n\ncontrol\n  options tran_method=\"trap\"\n  analysis tran1 tran step=1u stop=10m maxstep=1u\nendc\n</code></pre> <p>This defines: - A pulse voltage source <code>vs</code> switching between 0V and 1V - A 1k resistor <code>r1</code> - A 1uF capacitor <code>c1</code> - The RC time constant is 1ms</p>"},{"location":"getting_started/#running-with-python","title":"Running with Python","text":"<pre><code>from pathlib import Path\nfrom vajax import CircuitEngine\n\n# Load and parse the circuit\nengine = CircuitEngine(Path(\"rc.sim\"))\nengine.parse()\n\n# Configure and run transient analysis\nengine.prepare(t_stop=10e-3, dt=1e-6)\nresult = engine.run_transient()\n\n# Access results\ntimes = result.times\nv_in = result.voltage(\"1\")    # Input node\nv_out = result.voltage(\"2\")   # Output node (across capacitor)\n\nprint(f\"Simulated {result.num_steps} timesteps\")\nprint(f\"Final output voltage: {float(v_out[-1]):.4f} V\")\n</code></pre>"},{"location":"getting_started/#plotting-results","title":"Plotting Results","text":"<pre><code>import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 5))\nplt.plot(times * 1000, v_in, label=\"V(in)\")\nplt.plot(times * 1000, v_out, label=\"V(out)\")\nplt.xlabel(\"Time [ms]\")\nplt.ylabel(\"Voltage [V]\")\nplt.title(\"RC Low-Pass Filter Response\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"getting_started/#running-from-the-command-line","title":"Running from the Command Line","text":"<p>VAJAX includes a CLI for running simulations:</p> <pre><code># Run a VACASK benchmark\nuv run vajax run vendor/VACASK/benchmark/rc/vacask/runme.sim\n\n# See all CLI options\nuv run vajax --help\n</code></pre>"},{"location":"getting_started/#available-analysis-types","title":"Available Analysis Types","text":"Analysis Method Description Transient <code>run_transient()</code> Time-domain simulation with adaptive timestep AC <code>run_ac()</code> Small-signal frequency sweep Noise <code>run_noise()</code> Thermal, shot, and flicker noise analysis DC Transfer <code>run_dcinc()</code> DC incremental (small-signal) response DC XF <code>run_dcxf()</code> DC transfer function and input impedance AC XF <code>run_acxf()</code> AC transfer function over frequency PVT Corners <code>run_corners()</code> Process/voltage/temperature sweep"},{"location":"getting_started/#built-in-benchmark-circuits","title":"Built-in Benchmark Circuits","text":"<p>VAJAX ships with several benchmark circuits in <code>vendor/VACASK/benchmark/</code>:</p> Circuit Description Nodes Complexity <code>rc/</code> RC low-pass filter 4 Beginner <code>graetz/</code> Diode bridge rectifier 6 Beginner <code>mul/</code> Diode voltage multiplier 8 Intermediate <code>ring/</code> 7-stage PSP103 ring oscillator 47 Intermediate <code>c6288/</code> 16-bit multiplier (PSP103) ~5000 Advanced (GPU)"},{"location":"getting_started/#sparse-solver-for-large-circuits","title":"Sparse Solver for Large Circuits","text":"<p>For circuits with more than ~1000 nodes, enable the sparse solver:</p> <pre><code>engine.prepare(t_stop=1e-6, dt=1e-9, use_sparse=True)\nresult = engine.run_transient()\n</code></pre>"},{"location":"getting_started/#known-limitations","title":"Known Limitations","text":"<ul> <li>No DC sweep analysis yet (only DC operating point as part of other analyses)</li> <li>Float32 only on Metal/TPU backends (float64 on CPU/CUDA)</li> <li>No interactive waveform viewer built-in (use matplotlib or export to raw files)</li> </ul>"},{"location":"getting_started/#next-steps","title":"Next Steps","text":"<ul> <li>See Architecture Overview for how VAJAX works internally</li> <li>See Supported Devices for available device models</li> <li>See API Reference for full API documentation</li> <li>See Transient Options for advanced transient configuration</li> </ul>"},{"location":"gpu_solver_architecture/","title":"GPU Solver Architecture","text":"<p>Historical document</p> <p>This document describes an early GPU solver architecture. The codebase has since been restructured: DC analysis is in <code>analysis/dc.py</code>, transient analysis is in <code>analysis/transient/</code>, and Jacobians are now computed analytically via OpenVAF. The design principles and trade-offs described here remain relevant.</p> <p>This document describes the GPU-native solver architecture for VAJAX, including DC operating point and transient analysis implementations.</p>"},{"location":"gpu_solver_architecture/#overview","title":"Overview","text":"<p>VAJAX provides two complementary GPU-native solvers:</p> <ol> <li>DC Solver (<code>analysis/dc.py</code>) - Computes steady-state operating point</li> <li>Transient Solver (<code>analysis/transient/</code>) - Time-domain simulation with adaptive BDF2</li> </ol> <p>Jacobians are computed analytically via OpenVAF-compiled Verilog-A models.</p>"},{"location":"gpu_solver_architecture/#key-design-decisions","title":"Key Design Decisions","text":""},{"location":"gpu_solver_architecture/#why-transient-instead-of-dc-for-digital-circuits","title":"Why Transient Instead of DC for Digital Circuits?","text":"<p>For digital MOSFET circuits (like the C6288 multiplier), transient analysis with <code>icmode='uic'</code> is preferred over DC operating point analysis. This matches the approach used by VACASK and other production simulators.</p> <p>The problem with DC analysis: - Digital circuits have many possible stable states (high/low combinations) - Newton-Raphson can converge to wrong states or oscillate between them - Floating gate nodes and feedback paths make convergence difficult - Source stepping and GMIN stepping help but don't always work</p> <p>Why transient works better: - Natural settling behavior from initial conditions - No ambiguity about which state to converge to - The circuit \"finds\" its own solution through time evolution - Capacitances (intrinsic or explicit) provide natural damping</p> <p>VACASK Example: <pre><code>// From c6288.sim - VACASK uses transient, not DC\nanalysis tranmul tran stop=2n step=2p icmode=\"uic\"\n// analysis op1 op  &lt;- DC is commented out\n</code></pre></p>"},{"location":"gpu_solver_architecture/#initial-condition-modes-icmode","title":"Initial Condition Modes (icmode)","text":"<p>The transient solver supports two initial condition modes:</p> <ol> <li><code>icmode='op'</code> (default): Compute DC operating point first, then run transient</li> <li>Good for analog circuits where DC solution is well-defined</li> <li> <p>Can fail for digital circuits with multiple stable states</p> </li> <li> <p><code>icmode='uic'</code>: Use Initial Conditions directly (zeros + supply voltages)</p> </li> <li>Skip DC computation entirely</li> <li>Let circuit settle through transient simulation</li> <li>Preferred for digital logic circuits</li> <li>Matches VACASK's behavior for benchmarks</li> </ol>"},{"location":"gpu_solver_architecture/#solver-architecture","title":"Solver Architecture","text":""},{"location":"gpu_solver_architecture/#data-flow","title":"Data Flow","text":"<pre><code>MNASystem (devices)\n      \u2502\n      \u25bc\nbuild_device_groups()  \u25c4\u2500\u2500 Groups devices by type (MOSFET, R, V, C)\n      \u2502\n      \u25bc\nVectorizedDeviceGroup  \u25c4\u2500\u2500 Pre-computed JAX arrays per device type\n      \u2502\n      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      \u25bc                  \u25bc\nbuild_gpu_residual_fn()  build_transient_circuit_data_fast()\n      \u2502                  \u2502\n      \u25bc                  \u25bc\n  residual_fn()      TransientCircuitData\n      \u2502                  \u2502\n      \u25bc                  \u25bc\nsparsejac.jacrev()   build_transient_residual_fn()\n      \u2502                  \u2502\n      \u25bc                  \u25bc\nSparse Jacobian      residual_fn(V_curr, V_prev, dt)\n(BCOO format)             \u2502\n      \u2502                   \u25bc\n      \u25bc              sparsejac.jacrev()\nNewton-Raphson            \u2502\nIteration                 \u25bc\n      \u2502              Newton-Raphson per timestep\n      \u25bc                   \u2502\nSolution                  \u25bc\n                    Time-domain solution\n</code></pre>"},{"location":"gpu_solver_architecture/#key-components","title":"Key Components","text":""},{"location":"gpu_solver_architecture/#1-vectorizeddevicegroup","title":"1. VectorizedDeviceGroup","text":"<p>Groups devices of the same type with pre-computed JAX arrays:</p> <pre><code>class VectorizedDeviceGroup:\n    device_type: DeviceType       # MOSFET, RESISTOR, VSOURCE, etc.\n    device_names: List[str]\n    node_indices: Array           # Shape: (n_devices, n_terminals)\n    params: Dict[str, Array]      # Device parameters as batched arrays\n</code></pre> <p>This enables vectorized device evaluation instead of per-device Python loops.</p>"},{"location":"gpu_solver_architecture/#2-gpu-residual-function","title":"2. GPU Residual Function","text":"<p>The residual function computes KCL violations at each node:</p> <pre><code>def gpu_residual_fn(V: Array) -&gt; Array:\n    \"\"\"Compute f(V) where f=0 at solution.\n\n    Returns:\n        residual: Array of shape (n_nodes - 1,) - current imbalance at each node\n    \"\"\"\n    # For each device type, compute currents vectorized:\n    # - Voltage sources: I = G_big * (V_actual - V_target)\n    # - MOSFETs: Ids = f(Vgs, Vds, W, L, model_params)\n    # - Resistors: I = G * (Vp - Vn)\n    # - Capacitors: I = C/dt * (V - V_prev)  [transient only]\n\n    # Sum contributions at each node\n    residual = sum_at_nodes(device_currents)\n\n    # Add GMIN to ground (numerical stability)\n    residual += gmin * V\n\n    return residual\n</code></pre>"},{"location":"gpu_solver_architecture/#3-sparse-jacobian-via-sparsejac","title":"3. Sparse Jacobian via sparsejac","text":"<p>Instead of manually computing Jacobian entries, we use automatic differentiation:</p> <pre><code># Create sparsity pattern (which entries are non-zero)\nsparsity = jsparse.BCOO((data, indices), shape=(n, n))\n\n# Create sparse Jacobian function via graph coloring\njacobian_fn = sparsejac.jacrev(residual_fn, sparsity=sparsity)\n\n# Evaluate at a point\nJ_sparse = jacobian_fn(V)  # Returns BCOO sparse matrix\n</code></pre> <p>Benefits: - No need for analytical derivatives - Correct derivatives even for complex models - Efficient evaluation via graph coloring</p> <p>Key insight: The sparsity pattern comes from circuit topology - a device only contributes to Jacobian entries connecting its terminal nodes.</p>"},{"location":"gpu_solver_architecture/#4-newton-raphson-iteration","title":"4. Newton-Raphson Iteration","text":"<p>Both solvers use Newton-Raphson with voltage limiting:</p> <pre><code>for iteration in range(max_iterations):\n    f = residual_fn(V)\n    if max(abs(f)) &lt; abstol:\n        break  # Converged\n\n    J = jacobian_fn(V)\n    delta_V = solve(J, -f)  # Linear solve\n\n    # Voltage limiting (prevent overshooting)\n    max_step = 0.5 * vdd\n    if max(abs(delta_V)) &gt; max_step:\n        delta_V *= max_step / max(abs(delta_V))\n\n    V = V + delta_V\n    V = clip(V, -2*vdd, 2*vdd)  # Safety clamp\n</code></pre>"},{"location":"gpu_solver_architecture/#mosfet-models","title":"MOSFET Models","text":""},{"location":"gpu_solver_architecture/#transient-solver-level-1-model","title":"Transient Solver: Level-1 Model","text":"<p>The transient solver uses a simplified level-1 MOSFET model:</p> <pre><code>beta = kp * W / L\nVgst = Vgs - Vth0\n\n# Smooth subthreshold (avoids discontinuity at Vth)\nVgst_eff = log1p(exp(alpha * Vgst)) / alpha\n\n# Saturation with soft clipping\nVdsat = max(Vgst_eff, epsilon)\nVds_eff = Vdsat * tanh(abs(Vds) / Vdsat)\n\n# Drain current\nIds = beta * Vgst_eff * Vds_eff * (1 + lambda * abs(Vds))\n</code></pre>"},{"location":"gpu_solver_architecture/#dc-solver-bsim-like-model","title":"DC Solver: BSIM-like Model","text":"<p>The DC solver uses a more sophisticated BSIM-like model from <code>mosfet_simple.py</code>:</p> <ul> <li>Body effect (gamma, phiB)</li> <li>Velocity saturation (vsat)</li> <li>Subthreshold conduction (n_sub)</li> <li>Short channel effects (theta, a0)</li> <li>Temperature dependence</li> </ul>"},{"location":"gpu_solver_architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"gpu_solver_architecture/#jit-compilation","title":"JIT Compilation","text":"<p>Both solvers benefit from JAX's JIT compilation:</p> <pre><code>First timestep (includes JIT): ~1.5s\nSubsequent timesteps: ~0.002s (750x faster)\n</code></pre> <p>Tip: For benchmarking, always exclude the first iteration or use pre-warming.</p>"},{"location":"gpu_solver_architecture/#cpu-vs-gpu","title":"CPU vs GPU","text":"Circuit Size CPU Time GPU Time Speedup Small (&lt; 100 nodes) Faster Slower 0.5x Medium (1K nodes) Similar Similar 1x Large (5K+ nodes) Slower Faster 3-10x <p>GPU acceleration becomes beneficial at ~1000+ nodes due to data transfer overhead.</p>"},{"location":"gpu_solver_architecture/#memory-usage","title":"Memory Usage","text":"<p>Sparse Jacobian memory scales with O(devices * terminals\u00b2) instead of O(nodes\u00b2):</p> <pre><code>C6288 (5123 nodes, 10112 MOSFETs):\n- Dense Jacobian: ~200 MB\n- Sparse Jacobian: ~1.3 MB\n- Savings: 150x\n</code></pre>"},{"location":"gpu_solver_architecture/#usage-examples","title":"Usage Examples","text":""},{"location":"gpu_solver_architecture/#dc-operating-point","title":"DC Operating Point","text":"<pre><code>from vajax import CircuitEngine\n\nengine = CircuitEngine(\"circuit.sim\")\nengine.parse()\n\n# DC operating point is computed automatically before transient\n# Or run DC explicitly:\n# engine.run_dcinc()\n</code></pre>"},{"location":"gpu_solver_architecture/#transient-analysis","title":"Transient Analysis","text":"<pre><code>from vajax import CircuitEngine\n\nengine = CircuitEngine(\"circuit.sim\")\nengine.parse()\n\n# For digital circuits - use icmode='uic' to skip DC\nengine.prepare(t_stop=2e-9, dt=2e-12)\nresult = engine.run_transient()\n\n# For analog circuits with sparse solver\nengine.prepare(t_stop=1e-6, dt=1e-9, use_sparse=True)\nresult = engine.run_transient()\n</code></pre>"},{"location":"gpu_solver_architecture/#current-state","title":"Current State","text":"<p>Since this document was written, major improvements have been made:</p> <ol> <li>Adaptive timestepping: BDF2 with LTE control is implemented</li> <li>Unified device models: All devices use OpenVAF-compiled Verilog-A (PSP103, etc.)</li> <li>GPU-resident time loops: Transient uses <code>lax.scan</code> for full GPU execution</li> <li>Sparse solver: BCOO/BCSR with <code>spsolve</code> for large circuits</li> <li>AC and noise analysis: Frequency-domain analyses are available</li> </ol>"},{"location":"gpu_solver_architecture/#references","title":"References","text":"<ol> <li>VACASK simulator behavior for digital circuit analysis</li> <li>sparsejac: https://github.com/mfschubert/sparsejac</li> <li>JAX documentation: https://jax.readthedocs.io</li> <li>Newton-Raphson for circuit simulation (Nagel, 1975)</li> </ol>"},{"location":"gpu_solver_jacobian/","title":"GPU Solver Jacobian: Autodiff vs Analytical","text":"<p>Historical document</p> <p>This documents a solved investigation. The files referenced below (<code>dc_gpu.py</code>, <code>transient_gpu.py</code>, <code>benchmarks/c6288.py</code>) no longer exist. DC analysis is now in <code>analysis/dc.py</code>, transient in <code>analysis/transient/</code>, and all device models use OpenVAF analytical Jacobians.</p>"},{"location":"gpu_solver_jacobian/#status-solved","title":"Status: SOLVED","text":"<p>The GPU solver has been fully migrated to analytical Jacobians, eliminating the convergence issues. This document describes the original problem and solution for reference.</p>"},{"location":"gpu_solver_jacobian/#the-original-problem","title":"The Original Problem","text":"<p>The GPU solver originally used JAX autodiff (via <code>sparsejac</code>) to compute Jacobians. This caused convergence issues for circuits with floating nodes (like series NMOS stacks in AND gates).</p>"},{"location":"gpu_solver_jacobian/#root-cause","title":"Root Cause","text":"<p>When a MOSFET is in cutoff or deep saturation, the autodiff-computed <code>dIds/dVds</code> (output conductance) can be extremely small: - GPU autodiff: <code>gds \u2248 1e-16 S</code> in cutoff - VACASK analytical: <code>gds = 1e-9 S</code> minimum (enforced)</p> <p>This creates nearly-singular Jacobians that cause Newton-Raphson to diverge.</p>"},{"location":"gpu_solver_jacobian/#comparison-at-and-gate-int-node-floating","title":"Comparison at AND Gate <code>int</code> Node (Floating)","text":"Property GPU (autodiff) VACASK (analytical) gds in cutoff ~1e-16 S 1e-9 S (min enforced) Convergence Fails (oscillates) Succeeds (34 iters) Final <code>int</code> voltage Diverges to \u00b12.4V Settles to 0.6V"},{"location":"gpu_solver_jacobian/#how-openvaf_jax-works","title":"How openvaf_jax Works","text":"<p>The <code>openvaf_jax.py</code> module translates Verilog-A models (via OpenVAF MIR) to JAX functions that return both residual and analytical Jacobian:</p> <pre><code># Generated function signature\ndef device_eval(inputs: List[float]) -&gt; Tuple[Dict, Dict]:\n    \"\"\"\n    Returns:\n        residuals: Dict[node, {'resist': float, 'react': float}]\n        jacobian: Dict[(row, col), {'resist': float, 'react': float}]\n    \"\"\"\n</code></pre>"},{"location":"gpu_solver_jacobian/#key-code-location","title":"Key Code Location","text":"<p>In <code>openvaf_jax.py</code> lines 262-277: <pre><code># Build output expressions\nlines.append(\"    residuals = {\")\nfor node, res in self.dae_data['residuals'].items():\n    resist_val = res['resist'] if res['resist'] in defined_vars else '0.0'\n    react_val = res['react'] if res['react'] in defined_vars else '0.0'\n    lines.append(f\"        '{node}': {{'resist': {resist_val}, 'react': {react_val}}},\")\n\nlines.append(\"    jacobian = {\")\nfor entry in self.dae_data['jacobian']:\n    key = f\"('{entry['row']}', '{entry['col']}')\"\n    resist_val = entry['resist'] if entry['resist'] in defined_vars else '0.0'\n    react_val = entry['react'] if entry['resist'] in defined_vars else '0.0'\n    lines.append(f\"        {key}: {{'resist': {resist_val}, 'react': {react_val}}},\")\n</code></pre></p> <p>The Jacobian entries come from <code>dae_data['jacobian']</code> which is extracted from the OpenVAF MIR - these are analytical derivatives computed by OpenVAF's symbolic differentiation of the Verilog-A model.</p>"},{"location":"gpu_solver_jacobian/#current-state","title":"Current State","text":""},{"location":"gpu_solver_jacobian/#vacask-path-works","title":"VACASK Path (works)","text":"<pre><code>c6288.sim \u2192 parser \u2192 psp103n/psp103p model\n                          \u2193\n              create_simple_mosfet_eval() \u2190 Uses explicit gm, gds stamps\n                          \u2193\n              build_sparse_jacobian_and_residual() \u2190 Stamps conductances into J\n</code></pre>"},{"location":"gpu_solver_jacobian/#gpu-path-broken","title":"GPU Path (broken)","text":"<pre><code>c6288.sim \u2192 parser \u2192 psp103n/psp103p model\n                          \u2193\n              create_simple_mosfet_eval() \u2190 Same simplified model\n                          \u2193\n              build_circuit_residual_fn() \u2190 Residual only, no J\n                          \u2193\n              sparsejac.jacrev(residual_fn) \u2190 Autodiff gives wrong gds\n</code></pre>"},{"location":"gpu_solver_jacobian/#solution-options","title":"Solution Options","text":""},{"location":"gpu_solver_jacobian/#option-1-add-gds_min-to-gpu-model-partial-fix","title":"Option 1: Add gds_min to GPU Model (Partial Fix)","text":"<p>Add minimum conductance leakage: <code>Ids += gds_min * Vds</code></p> <p>Status: Implemented but insufficient - gds_min only helps in cutoff, not saturation.</p>"},{"location":"gpu_solver_jacobian/#option-2-use-analytical-jacobian-from-openvaf_jax-preferred","title":"Option 2: Use Analytical Jacobian from openvaf_jax (Preferred)","text":"<p>Create PSP103 device via openvaf_jax and use its analytical Jacobian:</p> <pre><code>from openvaf_jax import OpenVAFToJAX\n\n# Compile PSP103 model to JAX\ntranslator = OpenVAFToJAX.from_file(\"psp103v4.va\")\npsp103_eval = translator.translate()\n\n# In GPU residual function:\ndef residual_fn(V):\n    for device in mosfets:\n        inputs = build_inputs(V, device)\n        residuals, jacobian = psp103_eval(inputs)  # Both from same call!\n        # Stamp residuals into f\n        # Jacobian available for building J analytically\n</code></pre> <p>This requires restructuring the GPU solver to: 1. Build residual AND Jacobian together (not separately via autodiff) 2. Use JAX's sparse matrix operations with explicit stamp values</p>"},{"location":"gpu_solver_jacobian/#option-3-hybrid-approach","title":"Option 3: Hybrid Approach","text":"<p>Use autodiff for most of the circuit but override MOSFET gds with minimum value: <pre><code># After autodiff Jacobian computation\nJ_diag = jnp.diag(J)\nJ_diag = jnp.where(jnp.abs(J_diag) &lt; gds_min, jnp.sign(J_diag) * gds_min, J_diag)\n</code></pre></p>"},{"location":"gpu_solver_jacobian/#files-involved","title":"Files Involved","text":"<ul> <li><code>vajax/analysis/dc.py</code> - DC operating point solver</li> <li><code>vajax/analysis/transient/</code> - Transient analysis (scan/loop strategies)</li> <li><code>vajax/analysis/solver.py</code> - Newton-Raphson with <code>lax.while_loop</code></li> <li><code>openvaf_jax/</code> - OpenVAF\u2192JAX translator</li> <li><code>vajax/devices/verilog_a.py</code> - VerilogADevice wrapper</li> </ul>"},{"location":"gpu_solver_jacobian/#test-case","title":"Test Case","text":"<p>The <code>and_test</code> circuit in <code>c6288.sim</code> is a good minimal test: - 6 MOSFETs (NAND + inverter) - Floating <code>int</code> node between series NMOS mn1/mn2 - VACASK converges in 34 iterations - GPU solver diverges</p>"},{"location":"gpu_solver_jacobian/#verification-psp103-via-openvaf_jax-works","title":"Verification: PSP103 via openvaf_jax Works","text":"<p>Confirmed that PSP103 can be compiled and evaluated via openvaf_jax:</p> <pre><code>import openvaf_py\nimport openvaf_jax\n\nva_path = 'vendor/OpenVAF/integration_tests/PSP103/psp103.va'\nmodules = openvaf_py.compile_va(va_path)\nmodule = modules[0]\n\ntranslator = openvaf_jax.OpenVAFToJAX(module)\neval_fn = translator.translate()\n\n# Evaluate - returns BOTH residual and analytical Jacobian\nresiduals, jacobian = eval_fn(inputs)\n</code></pre> <p>Results: - Module: PSP103VA - Nodes: 13 (internal nodes for the compact model) - Parameters: 2616 - Jacobian entries: 56 (analytical, not autodiff!)</p> <p>The 56 Jacobian entries are computed symbolically by OpenVAF from the Verilog-A model equations - these are the well-conditioned conductance stamps that SPICE simulators rely on.</p>"},{"location":"gpu_solver_jacobian/#how-openvaf-handles-hidden-states-cache-slots","title":"How OpenVAF Handles Hidden States (Cache Slots)","text":"<p>OpenVAF's compilation pipeline distinguishes between: 1. Model/Instance Parameters: User-specified values (like VTH0, KP, W, L) 2. Voltages: Circuit node voltages from the solver 3. Hidden States (Cache Slots): Intermediate values computed by the device model</p>"},{"location":"gpu_solver_jacobian/#the-initeval-split-in-osdi","title":"The Init/Eval Split in OSDI","text":"<p>OSDI models have two functions: - Init function: Runs once per operating point, computes parameter-dependent values - Eval function: Runs every Newton iteration, uses init outputs + voltages</p> <p>The init function computes \"cached\" values that don't depend on voltages: <pre><code>// Example from a resistor model\n// Init computes temperature-adjusted resistance:\nres = R * pow(temperature / tnom, zeta);  // Cached, doesn't change during NR\n</code></pre></p> <p>These cached values are stored in \"cache slots\" and passed to the eval function.</p>"},{"location":"gpu_solver_jacobian/#openvaf-mir-structure","title":"OpenVAF MIR Structure","text":"<p>In the MIR (Mid-level IR), cached values appear as: <pre><code>// From openvaf/sim_back/src/init.rs\npub struct CacheSlot(u32);\n\n// The init function outputs to cache slots\n// The eval function reads from cache slots\n</code></pre></p> <p>The mapping between init outputs and eval inputs is tracked in <code>cache_mapping</code>: <pre><code># From openvaf_py\ncache_mapping = [\n    {'init_value': 'init_v30', 'eval_param': 'v86'},  # sign\n    {'init_value': 'init_v31', 'eval_param': 'v37'},  # beta\n]\n</code></pre></p>"},{"location":"gpu_solver_jacobian/#how-openvaf_jax-handles-this","title":"How openvaf_jax Handles This","text":"<p>The JAX translator currently requires users to provide ALL parameters as inputs, including those that should be computed by init:</p> <pre><code># What the user provides:\ninputs = [\n    0,        # PMOS flag\n    1.0,      # sign (ideally computed from PMOS)\n    0.0,      # V(s)\n    1.2,      # V(g)\n    1.2,      # Vgs (should be computed: V(g) - V(s))\n    1.2,      # V(d)\n    1.2,      # Vds (should be computed: V(d) - V(s))\n    # ... etc\n]\n</code></pre> <p>The eval function DOES compute voltage-derived values (Vgs, Vds) internally from the terminal voltages. But it expects the init-computed values (like beta) to be provided.</p>"},{"location":"gpu_solver_jacobian/#key-insight-voltage-derived-values","title":"Key Insight: Voltage-Derived Values","text":"<p>Looking at the MOSFET model: <pre><code>// These are computed EVERY iteration from voltages\nVgs = V(g) - V(s);\nVds = V(d) - V(s);\nVov = Vgs - VTH0;\n\n// These are computed ONCE in init\nbeta = KP * W / L;  // Doesn't depend on voltages\n</code></pre></p> <p>The JAX-generated code correctly computes Vgs, Vds, Vov from the input voltages on every call. The issue is that values like <code>beta</code> need to be computed once and passed in.</p>"},{"location":"gpu_solver_jacobian/#solution-for-gpu-solver-integration","title":"Solution for GPU Solver Integration","text":"<p>To use openvaf_jax models in the GPU solver:</p> <ol> <li>Run init once at start of Newton iteration to compute cache slots</li> <li>Pass cache values as part of the inputs array</li> <li>Eval function computes residuals and Jacobians from voltages + cache</li> </ol> <p>This matches how VACASK works: it runs init once, then calls eval repeatedly with the cached values until convergence.</p>"},{"location":"gpu_solver_jacobian/#solution-implemented","title":"Solution Implemented","text":"<p>The GPU solvers now use analytical Jacobians computed via the Shichman-Hodges MOSFET model:</p> <ol> <li>dc_gpu.py: <code>build_analytical_residual_and_jacobian_fn()</code> computes both residual and Jacobian in one pass</li> <li>transient_gpu.py: <code>build_transient_residual_and_jacobian_fn()</code> adds capacitor handling for transient analysis</li> </ol>"},{"location":"gpu_solver_jacobian/#key-implementation-details","title":"Key Implementation Details","text":"<pre><code># Level-1 Shichman-Hodges MOSFET with explicit gm/gds computation\nvth0 = 0.4\nkp = 200e-6\nlambda_ = 0.01\ngds_min = 1e-9  # Minimum conductance for cutoff\n\n# Analytical Jacobian stamps (Y-matrix)\nstamps = {\n    ('D', 'D'): gds,\n    ('D', 'G'): gm,\n    ('D', 'S'): -gds - gm,\n    ('S', 'D'): -gds,\n    ('S', 'G'): -gm,\n    ('S', 'S'): gds + gm,\n}\n</code></pre>"},{"location":"gpu_solver_jacobian/#results","title":"Results","text":"Circuit Before (autodiff) After (analytical) Inverter 6 iterations 5 iterations AND gate FAILED 78 iterations NOR gate ~15 iterations ~10 iterations <p>The <code>sparsejac</code> dependency has been removed from the GPU solver code path.</p>"},{"location":"osdi_parameter_architecture/","title":"OSDI Parameter Architecture","text":"<p>This document describes how OSDI (Open Simulator Device Interface) handles parameters, the distinction between different parameter types, and how this relates to VAJAX's parameter handling through <code>openvaf_jax</code>.</p>"},{"location":"osdi_parameter_architecture/#1-osdi-parameter-kinds","title":"1. OSDI Parameter Kinds","text":"<p>OSDI defines three parameter kinds in the descriptor:</p> <pre><code>// From OSDI header\n#define PARA_KIND_MODEL 0   // Model-level parameters (shared across instances)\n#define PARA_KIND_INST  1   // Instance-level parameters (per-device)\n#define PARA_KIND_OPVAR 2   // Output variables (computed, read-only)\n</code></pre>"},{"location":"osdi_parameter_architecture/#model-parameters-para_kind_model","title":"Model Parameters (<code>PARA_KIND_MODEL</code>)","text":"<ul> <li>Shared across all instances of a model (e.g., all psp103n devices)</li> <li>Typically process parameters, physical constants</li> <li>Examples: <code>toxe</code>, <code>vth0</code>, <code>k1</code>, <code>k2</code></li> <li>Stored in model data structure at <code>descriptor-&gt;model_size</code> bytes</li> </ul>"},{"location":"osdi_parameter_architecture/#instance-parameters-para_kind_inst","title":"Instance Parameters (<code>PARA_KIND_INST</code>)","text":"<ul> <li>Per-device parameters</li> <li>Geometry, placement, multipliers</li> <li>Examples: <code>w</code>, <code>l</code>, <code>nf</code>, <code>mult</code>, <code>sa</code>, <code>sb</code></li> <li>Stored in instance data structure at <code>descriptor-&gt;instance_size</code> bytes</li> </ul>"},{"location":"osdi_parameter_architecture/#output-variables-para_kind_opvar","title":"Output Variables (<code>PARA_KIND_OPVAR</code>)","text":"<ul> <li>Computed during evaluation</li> <li>Read-only to the simulator</li> <li>Examples: <code>ids</code>, <code>gm</code>, <code>gds</code>, <code>vth</code></li> <li>Extracted after eval for probing/measurement</li> </ul>"},{"location":"osdi_parameter_architecture/#2-osdi-internal-states-not-hidden_state","title":"2. OSDI Internal States (NOT \"hidden_state\")","text":"<p>Critical distinction: OSDI has a concept of \"internal states\" that is separate from parameters. These are used for:</p> <ul> <li><code>$limit()</code> function state (voltage limiting for convergence)</li> <li><code>ddt()</code> integration state</li> <li>Other time-dependent constructs</li> </ul>"},{"location":"osdi_parameter_architecture/#how-internal-states-work","title":"How Internal States Work","text":"<pre><code>typedef struct OsdiSimInfo {\n    // ...\n    double *prev_state;   // Previous internal state array\n    double *next_state;   // Next internal state array\n    // ...\n} OsdiSimInfo;\n</code></pre> <p>During evaluation: 1. Model reads from <code>prev_state</code> (previous timestep/iteration) 2. Model writes to <code>next_state</code> (current computation) 3. After convergence, simulator swaps: <code>prev_state = next_state</code></p> <p>These are for convergence aids and time integration, NOT for geometry calculations.</p>"},{"location":"osdi_parameter_architecture/#3-what-openvaf_py-calls-hidden_state","title":"3. What openvaf_py Calls \"hidden_state\"","text":"<p>In <code>openvaf_py</code> (our Rust bindings for OpenVAF's MIR interpreter), <code>hidden_state</code> is a parameter kind that refers to something entirely different from OSDI internal states.</p>"},{"location":"osdi_parameter_architecture/#openvaf_pys-hidden_state","title":"openvaf_py's hidden_state","text":"<p>These are values computed by the model's init function and cached for use in the eval function:</p> <pre><code>// From openvaf_py/src/lib.rs\npub enum ParamKind {\n    Param,        // Regular parameters\n    DepBreak,     // Dependency break points\n    ParamHidden,  // Hidden model params (not in OSDI)\n    Voltage,      // Node voltages\n    Current,      // Branch currents\n    HiddenState,  // &lt;-- Values computed by init, cached for eval\n    StateLim,     // Limit function state\n    Temperature,  // Temperature\n}\n</code></pre>"},{"location":"osdi_parameter_architecture/#examples-of-hidden_state-values","title":"Examples of hidden_state Values","text":"<p>For PSP103, the init function computes ~462 cached values:</p> Value Computation Purpose <code>invNF</code> <code>1.0 / NF</code> Inverse number of fingers <code>LE</code>, <code>WE</code> Effective length/width after binning Geometry <code>iL</code>, <code>iW</code> <code>1.0 / L</code>, <code>1.0 / W</code> Inverse geometry <code>iLE</code>, <code>iWE</code> <code>1.0 / LE</code>, <code>1.0 / WE</code> Inverse effective geometry <code>inv_phit</code> <code>1.0 / (kT/q)</code> Inverse thermal voltage <code>inv_phita</code> Adjusted thermal voltage inverse Temperature-adjusted <code>chnl_type</code> 1 or -1 NMOS vs PMOS <code>lcinv2</code> <code>1.0 / (LC * LC)</code> Inverse LC squared"},{"location":"osdi_parameter_architecture/#why-these-exist","title":"Why These Exist","text":"<p>OpenVAF optimizes Verilog-A code by: 1. Running \"init\" phase once per parameter change 2. Caching computed values that don't depend on voltages 3. Passing cached values to \"eval\" phase for each iteration</p> <p>This avoids recomputing expensive expressions every NR iteration.</p>"},{"location":"osdi_parameter_architecture/#4-the-translation-pipeline","title":"4. The Translation Pipeline","text":""},{"location":"osdi_parameter_architecture/#openvaf-compilation","title":"OpenVAF Compilation","text":"<pre><code>Verilog-A source\n    \u2193\nOpenVAF Compiler\n    \u2193\nOSDI shared library (.so/.dylib)\n</code></pre> <p>The OSDI library contains native code with the init/eval split built-in.</p>"},{"location":"osdi_parameter_architecture/#openvaf_jax-translation","title":"openvaf_jax Translation","text":"<pre><code>Verilog-A source\n    \u2193\nOpenVAF Compiler (partial - to MIR)\n    \u2193\nopenvaf_py (Rust MIR interpreter)\n    \u2193\nopenvaf_jax.py (MIR \u2192 JAX translator)\n    \u2193\nJAX Python functions\n</code></pre> <p>The JAX translator must replicate the init/eval split:</p> <ol> <li>Init phase: Computes cached values from parameters</li> <li>Cache mapping: Passes cached values to eval via variable assignments</li> <li>Eval phase: Uses cached values + voltages to compute currents/Jacobians</li> </ol>"},{"location":"osdi_parameter_architecture/#cache-mapping-in-generated-code","title":"Cache Mapping in Generated Code","text":"<pre><code># Example from generated JAX code\ndef eval_func(voltages, params, cache_values):\n    # Cache values assigned from init results\n    v84982 = init_v12340   # invNF\n    v84983 = init_v12341   # LE\n    v84984 = init_v12342   # WE\n    # ...\n\n    # Eval uses these cached values\n    ids = v84982 * some_expression(voltages)\n</code></pre>"},{"location":"osdi_parameter_architecture/#5-vajax-parameter-handling","title":"5. VAJAX Parameter Handling","text":""},{"location":"osdi_parameter_architecture/#the-problem","title":"The Problem","text":"<p>VAJAX's <code>runner.py</code> batches devices for GPU efficiency. The vectorized path must set:</p> <ol> <li>Regular parameters (<code>l</code>, <code>w</code>, <code>nf</code>, etc.) - from netlist</li> <li>Hidden_state parameters - computed geometry values</li> </ol>"},{"location":"osdi_parameter_architecture/#what-runnerpy-does","title":"What runner.py Does","text":"<pre><code># From runner.py lines 650-745\n\n# Set regular parameters\nl_vals = np.array([float(p.get('l', 1e-6)) for p in all_dev_params])\nw_vals = np.array([float(p.get('w', 1e-6)) for p in all_dev_params])\nnf_vals = np.maximum(np.array([float(p.get('nf', 1.0)) for p in all_dev_params]), 1.0)\n\n# Compute and set hidden_state params\nwe_vals = np.maximum(w_vals / nf_vals, 1e-9)  # Effective width\nle_vals = np.maximum(l_vals, 1e-9)            # Effective length\n\nif 'invnf' in hidden_to_col:\n    all_inputs[:, hidden_to_col['invnf']] = 1.0 / nf_vals\nif 'le' in hidden_to_col:\n    all_inputs[:, hidden_to_col['le']] = le_vals\n# ... ~40 more hidden_state params\n</code></pre>"},{"location":"osdi_parameter_architecture/#current-issues","title":"Current Issues","text":"<ol> <li>1705 hidden_state params in PSP103, only ~40 handled</li> <li>Many values still 0, causing division by zero</li> <li>NaN propagation through model calculations</li> <li>Should JAX code compute these? The generated JAX init function should compute them, but the vectorized runner bypasses this</li> </ol>"},{"location":"osdi_parameter_architecture/#6-comparison-vacask-vs-vajax","title":"6. Comparison: VACASK vs VAJAX","text":"Aspect VACASK VAJAX Init execution Native code, once per setup Should use generated JAX init Cache passing Automatic in native code Manual via cache_mapping Vectorization Per-device sequential Batched vmap over devices Hidden_state Computed by init function Currently computed in runner.py GPU support None (CPU only) Full JAX GPU acceleration"},{"location":"osdi_parameter_architecture/#7-recommended-architecture","title":"7. Recommended Architecture","text":""},{"location":"osdi_parameter_architecture/#current-problematic","title":"Current (Problematic)","text":"<pre><code>runner.py manually sets ~40 hidden_state params\n    \u2193\nGenerated eval function expects all 1705 values\n    \u2193\nMissing values = 0 \u2192 Division by zero \u2192 NaN\n</code></pre>"},{"location":"osdi_parameter_architecture/#proposed-solution","title":"Proposed Solution","text":"<pre><code>runner.py sets only regular params (l, w, nf, etc.)\n    \u2193\nGenerated init function computes all hidden_state\n    \u2193\nCache passed to eval function\n    \u2193\nNo manual geometry computation needed\n</code></pre> <p>This requires: 1. <code>openvaf_jax.py</code> to generate a proper init function 2. <code>runner.py</code> to call init before eval 3. Batched init execution via vmap</p>"},{"location":"osdi_parameter_architecture/#8-analysis-does-openvaf-pys-hidden_state-model-make-sense","title":"8. Analysis: Does openvaf-py's hidden_state Model Make Sense?","text":""},{"location":"osdi_parameter_architecture/#the-architectural-issue","title":"The Architectural Issue","text":"<p>openvaf-py exposes <code>hidden_state</code> as a parameter kind, but this is architecturally confused:</p> <ol> <li>Eval function's hidden_state params are UNUSED</li> <li><code>insert_var_init</code> (in <code>sim_back/src/state.rs</code>) replaces all HiddenState references with their computed values</li> <li>After this pass, HiddenState params have 0 operand references in the eval function</li> <li> <p>They exist in the param list but aren't actually read by any instruction</p> </li> <li> <p>Init function's hidden_state params ARE used</p> </li> <li>These represent variable initialization expressions</li> <li> <p>The init function computes them and they become cache values</p> </li> <li> <p>The cache_mapping is the correct mechanism</p> </li> <li><code>compiled.init.cached_vals</code> maps init outputs \u2192 eval inputs</li> <li>This is what should be used to pass values from init to eval</li> </ol>"},{"location":"osdi_parameter_architecture/#what-openvaf-actually-does-in-sim_backsrcinitrs","title":"What OpenVAF Actually Does (in sim_back/src/init.rs)","text":"<pre><code>// From Initialization::new()\nwhile let Some(bb) = blocks.next(&amp;builder.func.layout) {\n    // Copy instructions that are NOT op dependent to instance setup MIR\n    // and zap them in module MIR.\n    builder.split_block(bb);\n}\n</code></pre> <p>The init/eval split: 1. Instructions NOT operating-point dependent \u2192 moved to init function 2. Instructions operating-point dependent \u2192 kept in eval function 3. Values computed in init that eval needs \u2192 become cache slots</p>"},{"location":"osdi_parameter_architecture/#the-hidden-state-flow","title":"The Hidden State Flow","text":"<pre><code>Verilog-A variable 'real LE;'\n    \u2193\nParamKind::HiddenState(LE) created in MIR\n    \u2193\ninsert_var_init() replaces HiddenState with actual computation\n    \u2193\nInitialization::new() moves computation to init function\n    \u2193\nValue becomes a cache slot in cached_vals\n    \u2193\ncache_mapping connects init output \u2192 eval input param\n</code></pre> <p>After this flow, HiddenState is no longer needed - it's been replaced by the cache system.</p>"},{"location":"osdi_parameter_architecture/#why-openvaf-pys-model-is-problematic","title":"Why openvaf-py's Model is Problematic","text":"<ol> <li> <p>Misleading API: Exposing hidden_state in eval params suggests they're inputs, but they're unused</p> </li> <li> <p>Fragile workarounds: openvaf_jax.py uses value-number matching (<code>_build_hidden_state_assignments</code>) to work around the architecture:    <pre><code># If eval uses vN for a hidden_state param and init computed init_vN,\n# add assignment vN = init_vN\n</code></pre>    This relies on OpenVAF using same value numbers, which isn't guaranteed.</p> </li> <li> <p>Manual computation in runner.py: Because the workarounds fail for batched execution, runner.py manually computes ~40 hidden_state values, missing 1600+.</p> </li> </ol>"},{"location":"osdi_parameter_architecture/#the-correct-solution","title":"The Correct Solution","text":"<p>Short term: runner.py should call the init function (via vmap) for each device, using the output via cache_mapping.</p> <p>Long term: openvaf-py should: 1. Not expose hidden_state as eval params (or mark them as \"internal/unused\") 2. Provide a clear API: <code>init(params) \u2192 cache</code>, <code>eval(voltages, cache) \u2192 residuals</code> 3. Make both functions easily vmappable for batched GPU execution</p>"},{"location":"osdi_parameter_architecture/#summary","title":"Summary","text":"Aspect Current Correct hidden_state in eval Exposed as params Should be internal Init function Generated but not used in batched mode Should be called via vmap Cache values Workaround via value-number matching Proper cache_mapping API Runner computation Manual ~40 params None needed"},{"location":"osdi_parameter_architecture/#9-related-documentation","title":"9. Related Documentation","text":"<ul> <li>VACASK OSDI Inputs - How VACASK interfaces with OSDI</li> <li>Architecture Overview - Overall VAJAX architecture</li> <li>OpenVAF CLAUDE.md - OpenVAF compiler architecture</li> </ul>"},{"location":"osdi_parameter_architecture/#9-file-references","title":"9. File References","text":"Purpose File OSDI header definitions <code>vendor/OpenVAF/openvaf/osdi/header/osdi.h</code> Rust MIR interpreter <code>openvaf_jax/openvaf_py/src/lib.rs</code> JAX code translator <code>openvaf_jax/__init__.py</code> Benchmark runner <code>vajax/benchmarks/runner.py</code> VACASK OSDI interface <code>vendor/VACASK/lib/osdiinstance.cpp</code>"},{"location":"parallelism_architecture/","title":"Parallelism Architecture: c6288 Case Study","text":"<p>This document traces how VAJAX exploits parallelism at every stage of circuit simulation, using the c6288 16x16 combinational multiplier as a concrete example.</p>"},{"location":"parallelism_architecture/#circuit-overview","title":"Circuit Overview","text":"<p>The c6288 circuit is a 16-bit Wallace-tree multiplier:</p> <ul> <li>256 AND gates (6 MOSFETs each: 3 PMOS + 3 NMOS)</li> <li>2,128 NOR gates (4 MOSFETs each: 2 PMOS + 2 NMOS)</li> <li>10,048 PSP103 MOSFETs total (single model, TYPE parameter distinguishes NMOS/PMOS)</li> <li>32 resistors (in input drivers)</li> <li>34 voltage sources (32 driver + VDD + VSS)</li> <li>~5,089 external circuit nodes</li> </ul> <p>After node collapse (PSP103 has 8 internal nodes, 6 collapse), the system has: - 5,089 external nodes + 20,096 internal nodes (2 per MOSFET) + 34 vsource branch currents - ~25,219 unknowns in the augmented MNA system</p>"},{"location":"parallelism_architecture/#end-to-end-pipeline","title":"End-to-End Pipeline","text":"<p>The entire simulation -- all timesteps, all Newton-Raphson iterations, all device evaluations -- compiles into a single XLA program via <code>jax.jit</code>. After the one-time JIT warmup, zero Python interpreter overhead remains.</p> <pre><code>flowchart TB\n    subgraph once [\"One-time setup (Python)\"]\n        direction TB\n        A[Parse .sim netlist] --&gt; B[Compile PSP103.va via OpenVAF]\n        B --&gt; C[Group 10,048 MOSFETs by model type]\n        C --&gt; D[\"Split params: shared vs per-device\"]\n        D --&gt; E[Pre-compute COO stamp indices]\n        E --&gt; F[Trial eval \u2192 discover sparsity pattern]\n        F --&gt; G[Pre-compute COO\u2192CSR permutation]\n    end\n\n    subgraph jit [\"JIT-compiled XLA program (GPU/CPU)\"]\n        direction TB\n        H[\"Transient loop (lax.while_loop)\"]\n        H --&gt; I[Compute integration coefficients]\n        I --&gt; J[Evaluate source waveforms]\n        J --&gt; K[Predict voltages from history]\n        K --&gt; L[\"NR loop (lax.while_loop)\"]\n        L --&gt; M{Converged?}\n        M --&gt;|No| L\n        M --&gt;|Yes| N[LTE estimation]\n        N --&gt; O{Accept step?}\n        O --&gt;|No, halve dt| H\n        O --&gt;|Yes| P[Store solution, advance time]\n        P --&gt; H\n    end\n\n    once --&gt; jit</code></pre>"},{"location":"parallelism_architecture/#newton-raphson-iteration-detail","title":"Newton-Raphson Iteration Detail","text":"<p>Each NR iteration is the performance-critical inner loop. Here is what happens inside <code>build_system_mna</code> + <code>linear_solve</code>:</p> <pre><code>flowchart TB\n    subgraph nr [\"Single NR Iteration\"]\n        direction TB\n\n        subgraph extract [\"1. Voltage Extraction (vectorized gather)\"]\n            V[\"V: solution vector (25,219)\"]\n            VE[\"V[node1] - V[node2]&lt;br/&gt;10,048 \u00d7 13 terminal voltages\"]\n            V --&gt; VE\n        end\n\n        subgraph eval [\"2. Batched Device Evaluation (jax.vmap)\"]\n            direction TB\n            E1[\"PSP103 batch: vmap over 10,048 devices&lt;br/&gt;shared_params (broadcast) + device_params (10,048 \u00d7 ~20)\"]\n            E2[\"Resistor batch: vmap over 32 devices\"]\n            E1 --&gt; R1[\"10,048 \u00d7 residuals + 10,048 \u00d7 Jacobian entries\"]\n            E2 --&gt; R2[\"32 \u00d7 residuals + 32 \u00d7 Jacobian entries\"]\n        end\n\n        subgraph stamp [\"3. COO Stamping (pre-computed index arrays)\"]\n            direction TB\n            S1[\"Map local \u2192 global indices via stamp_indices\"]\n            S2[\"mask_coo_vector: zero out ground-node entries\"]\n            S1 --&gt; S2\n        end\n\n        subgraph asm [\"4. Matrix Assembly (segment_sum)\"]\n            direction TB\n            A1[\"~320K COO triplets (row, col, val)\"]\n            A2[\"segment_sum scatter-add \u2192 BCOO sparse matrix\"]\n            A1 --&gt; A2\n        end\n\n        subgraph solve [\"5. Sparse Linear Solve\"]\n            direction TB\n            L1[\"COO\u2192CSR via pre-computed permutation + segment_sum\"]\n            L2[\"Enforce NOI constraints (zero rows/cols, unit diagonal)\"]\n            L3[\"UMFPACK (CPU) or cuDSS (GPU) sparse LU solve\"]\n            L1 --&gt; L2 --&gt; L3\n            L3 --&gt; D1[\"\u03b4V: Newton update (25,219)\"]\n        end\n\n        extract --&gt; eval --&gt; stamp --&gt; asm --&gt; solve\n    end</code></pre>"},{"location":"parallelism_architecture/#where-parallelism-happens","title":"Where Parallelism Happens","text":"<p>Each stage has a distinct parallelism mechanism:</p> <pre><code>flowchart LR\n    subgraph stages [\"Pipeline Stages\"]\n        direction TB\n        S1[\"Voltage&lt;br/&gt;Extraction\"]\n        S2[\"Device&lt;br/&gt;Evaluation\"]\n        S3[\"COO&lt;br/&gt;Stamping\"]\n        S4[\"Matrix&lt;br/&gt;Assembly\"]\n        S5[\"Linear&lt;br/&gt;Solve\"]\n    end\n\n    subgraph parallel [\"Parallelism Mechanism\"]\n        direction TB\n        P1[\"Vectorized gather&lt;br/&gt;V[indices] - V[indices]\"]\n        P2[\"jax.vmap&lt;br/&gt;10,048 parallel threads\"]\n        P3[\"Vectorized index&lt;br/&gt;mapping + masking\"]\n        P4[\"jax.ops.segment_sum&lt;br/&gt;parallel scatter-add\"]\n        P5[\"Sparse LU factorization&lt;br/&gt;(cuDSS on GPU)\"]\n    end\n\n    subgraph scale [\"Scale for c6288\"]\n        direction TB\n        D1[\"10,048 \u00d7 13 lookups\"]\n        D2[\"10,048 PSP103 evals&lt;br/&gt;+ 32 resistor evals\"]\n        D3[\"~320K COO entries\"]\n        D4[\"320K \u2192 ~200K unique&lt;br/&gt;in 25K \u00d7 25K matrix\"]\n        D5[\"25,219 \u00d7 25,219&lt;br/&gt;sparse system\"]\n    end\n\n    S1 --- P1 --- D1\n    S2 --- P2 --- D2\n    S3 --- P3 --- D3\n    S4 --- P4 --- D4\n    S5 --- P5 --- D5</code></pre>"},{"location":"parallelism_architecture/#parameter-splitting-shared-vs-per-device","title":"Parameter Splitting: Shared vs Per-Device","text":"<p>The key optimization for batched evaluation is separating parameters that are constant across all 10,048 MOSFETs from those that vary per device.</p> <pre><code>graph LR\n    subgraph shared [\"Shared (broadcast, 1D)\"]\n        SP[\"~800 model params&lt;br/&gt;(TOX, VFB0, NSUBO, ...)\"]\n        SC[\"~400 cache values&lt;br/&gt;(computed by init)\"]\n        SIM[\"simparams&lt;br/&gt;(analysis_type, gmin)\"]\n    end\n\n    subgraph varying [\"Per-device (batched, 2D)\"]\n        VP[\"device_params&lt;br/&gt;10,048 \u00d7 ~20&lt;br/&gt;(voltages + W, L, TYPE)\"]\n        VC[\"device_cache&lt;br/&gt;10,048 \u00d7 ~60&lt;br/&gt;(init results that vary)\"]\n        LS[\"limit_state&lt;br/&gt;10,048 \u00d7 n_lim\"]\n    end\n\n    subgraph vmap_call [\"jax.vmap(eval_fn, in_axes=(None, 0, None, 0, None, 0))\"]\n        EVAL[\"PSP103 compact&lt;br/&gt;model equations\"]\n    end\n\n    shared --&gt; vmap_call\n    varying --&gt; vmap_call\n    vmap_call --&gt; OUT[\"10,048 \u00d7 residuals&lt;br/&gt;10,048 \u00d7 Jacobian entries\"]</code></pre> <p>The <code>in_axes=(None, 0, None, 0, None, 0)</code> specification tells JAX: - <code>None</code>: broadcast this input to all 10,048 invocations (shared params, shared cache, simparams) - <code>0</code>: slice along the first dimension, one row per device (device params, device cache, limit state)</p> <p>This means the ~800 shared model parameters are loaded once into registers/cache, while only the ~20 varying parameters differ per thread.</p>"},{"location":"parallelism_architecture/#coo-stamping-and-assembly","title":"COO Stamping and Assembly","text":"<p>Each device produces local residuals and Jacobian entries indexed by local node numbers (0..12 for PSP103). These must be mapped to global circuit indices.</p> <pre><code>flowchart TB\n    subgraph local [\"Per-device local output\"]\n        direction LR\n        LR[\"residual[0..5]&lt;br/&gt;(6 node contributions)\"]\n        LJ[\"jacobian[0..31]&lt;br/&gt;(up to 32 dI/dV entries)\"]\n    end\n\n    subgraph mapping [\"Stamp index mapping\"]\n        direction LR\n        RI[\"res_indices: (10,048 \u00d7 6)&lt;br/&gt;local node \u2192 global row\"]\n        JR[\"jac_row_indices: (10,048 \u00d7 32)\"]\n        JC[\"jac_col_indices: (10,048 \u00d7 32)\"]\n    end\n\n    subgraph global [\"Global COO arrays\"]\n        direction LR\n        GR[\"f_resist: ~60K valid entries&lt;br/&gt;\u2192 segment_sum \u2192 f[25,219]\"]\n        GJ[\"J entries: ~320K triplets&lt;br/&gt;\u2192 segment_sum \u2192 J[25,219 \u00d7 25,219]\"]\n    end\n\n    local --&gt; mapping --&gt; global</code></pre> <p>Ground-node entries are mapped to index -1 and masked to zero, so they don't pollute the system.</p>"},{"location":"parallelism_architecture/#sparse-solver-path","title":"Sparse Solver Path","text":"<p>The c6288 system is too large for dense linear algebra (25K \u00d7 25K \u00d7 8 bytes = ~5GB). The sparse path avoids materializing the full matrix:</p> <pre><code>flowchart TB\n    subgraph coo [\"BCOO from assembly\"]\n        C1[\"~320K COO triplets&lt;br/&gt;(row, col, val)\"]\n    end\n\n    subgraph convert [\"COO \u2192 CSR (pre-computed)\"]\n        C2[\"sort by (row, col) via permutation\"]\n        C3[\"segment_sum to merge duplicates\"]\n        C4[\"CSR: ~200K stored elements\"]\n    end\n\n    subgraph noi [\"NOI Constraint Enforcement\"]\n        N1[\"Zero out NOI rows/cols in CSR data\"]\n        N2[\"Set NOI diagonal to 1.0\"]\n        N3[\"Zero NOI entries in RHS\"]\n    end\n\n    subgraph solve [\"Backend-specific solve\"]\n        direction LR\n        GPU[\"GPU: cuDSS/Spineax&lt;br/&gt;Cached symbolic factorization&lt;br/&gt;Only numerical refactor per NR iter\"]\n        CPU[\"CPU: UMFPACK via FFI&lt;br/&gt;Direct sparse LU\"]\n    end\n\n    coo --&gt; convert --&gt; noi --&gt; solve</code></pre> <p>The COO\u2192CSR conversion is itself parallel: the permutation and segment_sum are pre-computed during setup, so at runtime it's just a gather + scatter-add.</p>"},{"location":"parallelism_architecture/#transient-time-stepping-loop","title":"Transient Time-Stepping Loop","text":"<p>The outer loop is also JIT-compiled via <code>lax.while_loop</code>:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; ComputeCoeffs: t &lt; t_stop\n\n    ComputeCoeffs: Compute integration coefficients\n    ComputeCoeffs --&gt; EvalSources: c0, c1 from BDF/Trap\n\n    EvalSources: Evaluate source waveforms\n    EvalSources --&gt; Predict: vsource_vals at t+dt\n\n    Predict: Extrapolate V from history\n    Predict --&gt; NRSolve: V_pred as initial guess\n\n    NRSolve: Newton-Raphson solve\n    NRSolve --&gt; CheckNR\n\n    CheckNR: NR converged?\n    CheckNR --&gt; LTE: Yes\n    CheckNR --&gt; Reject: No (halve dt)\n\n    LTE: Estimate local truncation error\n    LTE --&gt; CheckLTE\n\n    CheckLTE: LTE acceptable?\n    CheckLTE --&gt; Accept: Yes\n    CheckLTE --&gt; Reject: No (reduce dt)\n\n    Reject: Reduce timestep\n    Reject --&gt; ComputeCoeffs\n\n    Accept: Store solution\n    Accept --&gt; AdvanceTime\n\n    AdvanceTime: Update history, advance t\n    AdvanceTime --&gt; ComputeCoeffs: t &lt; t_stop\n    AdvanceTime --&gt; [*]: t &gt;= t_stop</code></pre>"},{"location":"parallelism_architecture/#performance-profile","title":"Performance Profile","text":"<p>For c6288 on CPU (CI benchmark results):</p> Metric Value Timesteps ~1,000 NR iterations/step 5-20 Device evals/NR iter 10,048 PSP103 + 32 resistors Per-step time (VAJAX) 90 ms Per-step time (VACASK) 80 ms Total wall time (VAJAX) 65.7s (includes JIT) Total wall time (VACASK) 80.2s Speedup (total) 1.22x faster (JIT amortized) <p>The per-step overhead (~10ms) comes from adaptive timestep machinery, <code>jnp.where</code> branching, and COO assembly. This overhead is fixed regardless of circuit size, which is why c6288 (~90ms/step) is competitive while small circuits (rc: 0.014ms VAJAX vs 0.002ms VACASK) show higher ratios.</p> <p>On GPU, the vmap'd device evaluation and cuDSS sparse solve provide additional speedup for large circuits, as the 10,048 parallel PSP103 evaluations map directly to GPU threads.</p>"},{"location":"parallelism_architecture/#scale-comparison-benchmarks","title":"Scale Comparison: Benchmarks","text":"Metric c6288 (16x16) mul64 (64x64) Ratio Architecture Wallace-tree Array multiplier \u2014 Partial product ANDs 256 4,096 16x Total MOSFETs ~10,048 ~266,408 ~27x Estimated unknowns ~25,219 ~400K+ ~16x Adder cells ~2,160 ~3,969 ~2x <p>The <code>mul64</code> benchmark serves as a GPU stress test \u2014 at ~266K MOSFETs and ~400K+ unknowns, it exercises the sparse solver and vmap'd device evaluation at a scale where GPU parallelism is essential.</p>"},{"location":"performance_analysis/","title":"Performance Analysis","text":"<p>This document analyzes VAJAX performance characteristics, explaining the overhead profile relative to VACASK (C++ reference simulator) and the GPU acceleration crossover point.</p>"},{"location":"performance_analysis/#benchmark-results","title":"Benchmark Results","text":"<p>All measurements from GitHub Actions CI runners (CPU: ubuntu-latest, GPU: nvidia-runner-1). VACASK numbers on CPU use live execution; GPU comparisons use reference values.</p>"},{"location":"performance_analysis/#cpu-vajax-vs-vacask","title":"CPU: VAJAX vs VACASK","text":"Benchmark Nodes Steps JAX (ms/step) VACASK (ms/step) Ratio rc 4 1M 0.012 0.002 6.6x graetz 6 1M 0.020 0.004 5.4x mul 8 500k 0.041 0.004 10.9x ring 47 20k 0.511 0.109 4.7x c6288 ~5000 1k 88.060 76.390 1.2x mul64 ~133k \u2014 \u2014 \u2014 \u2014 <p>mul64 (64x64 array multiplier): ~266k MOSFETs, ~666k unknowns (133k nodes + 533k internal). Requires &gt;16GB GPU VRAM for cuDSS sparse factorization \u2014 the Tesla T4 (16GB) runs out of memory during symbolic analysis. Needs A100 or larger.</p>"},{"location":"performance_analysis/#gpu-vajax-acceleration","title":"GPU: VAJAX Acceleration","text":"Benchmark Nodes GPU (ms/step) CPU (ms/step) GPU Speedup vs VACASK CPU mul64 ~133k \u2014 \u2014 \u2014 \u2014 c6288 ~5000 19.81 88.06 4.4x 0.35x (faster) ring 47 1.49 0.51 0.3x 33x (slower) graetz 6 0.30 0.02 0.07x 161x (slower) rc 4 0.24 0.01 0.05x 257x (slower) <p>mul64 requires &gt;16GB GPU VRAM \u2014 cuDSS symbolic factorization of the 666k x 666k sparse Jacobian (3.3M non-zeros) exceeds Tesla T4 (16GB) memory. Needs A100 (40/80GB) or similar. This benchmark is excluded from T4-based CI runs.</p> <p>GPU results for circuits below ~500 nodes reflect GPU kernel overhead on tiny workloads, not simulation inefficiency. The auto-threshold (<code>gpu_threshold=500</code>) prevents this in normal usage; the benchmark uses <code>--force-gpu</code> to measure all circuits for tracking purposes.</p>"},{"location":"performance_analysis/#accuracy-vs-vacask","title":"Accuracy (vs VACASK)","text":"Benchmark Dense RMS Sparse RMS Threshold rc 0.00% 0.00% 5% graetz 0.00% 0.00% 15% mul 0.00% 0.00% 2% c6288 - 2.01% 10%"},{"location":"performance_analysis/#per-step-overhead-analysis","title":"Per-Step Overhead Analysis","text":"<p>The overhead ratio decreases as circuit size increases, confirming a fixed per-step overhead in the JAX path that VACASK doesn't have:</p> <pre><code>Overhead ratio vs circuit size:\n\n    mul (8 nodes)      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  10.9x\n    rc (4 nodes)       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             6.6x\n    graetz (6 nodes)   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                 5.4x\n    ring (47 nodes)    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                   4.7x\n    c6288 (5k nodes)   \u2588\u2588\u2588\u2588                             1.2x\n    mul64 (133k nodes) \u2588                                TBD (GPU-only)\n</code></pre>"},{"location":"performance_analysis/#overhead-breakdown","title":"Overhead Breakdown","text":"<p>Each timestep in <code>full_mna.py</code> body_fn executes ~11 major operations beyond the core Newton-Raphson solve:</p> Operation Estimated Cost VACASK Equivalent Notes LTE estimation 2-3 us Similar Per-node tolerance checking, error coefficients Voltage prediction 1-2 us Simpler predictor Lagrange polynomial from multi-point history BDF2 coefficients 0.5-1 us Pre-computed Variable-step formula recomputed every step History management 1-2 us In-place mutation <code>jnp.roll</code> on V_history, dt_history arrays <code>jnp.where</code> branching 2-3 us Runtime <code>if</code> Evaluates both branches unconditionally Vmap device eval 1-2 us/NR iter Sequential loop Overhead dominates for &lt;10 devices COO assembly 1-2 us/NR iter Direct stamping Concatenate + sum duplicates Simparams <code>.at[].set()</code> 0.5-1 us/NR iter Struct writes Creates intermediate arrays Total fixed overhead ~10-15 us/step ~0 us"},{"location":"performance_analysis/#scaling-model","title":"Scaling Model","text":"<p>The per-step cost can be modeled as:</p> <pre><code>T_jax(n) = T_fixed + T_compute(n)\nT_vacask(n) = T_compute_vacask(n)\n\nwhere:\n  T_fixed ~ 10-15 us (JAX overhead, independent of circuit size)\n  T_compute(n) ~ T_compute_vacask(n) for large n (same algorithm)\n</code></pre> <p>This explains the convergence to 1.2x at ~5000 nodes:</p> Circuit T_fixed T_compute Overhead % Overall Ratio rc 10 us 2 us 83% 6.6x graetz 10 us 4 us 71% 5.4x ring 10 us 100 us 9% 4.7x c6288 10 us 76,000 us 0.01% 1.2x"},{"location":"performance_analysis/#why-jax-has-per-step-overhead","title":"Why JAX Has Per-Step Overhead","text":""},{"location":"performance_analysis/#1-functional-array-updates","title":"1. Functional Array Updates","text":"<p>JAX arrays are immutable. Inside <code>lax.while_loop</code>, conditional updates use <code>jnp.where</code> which evaluates both branches and selects elementwise:</p> <pre><code># JAX: evaluates both new_val and old_val, then selects\nstate = jnp.where(accept_step, new_val, old_val)\n</code></pre> <pre><code>// VACASK (C++): skips the else branch entirely\nif (accept_step) state = new_val;\n</code></pre> <p>The body_fn has ~15 such conditional updates per step for history management, step acceptance, and NR failure handling.</p>"},{"location":"performance_analysis/#2-vmap-batching-for-small-counts","title":"2. Vmap Batching for Small Counts","text":"<p>Device evaluation uses <code>jax.vmap</code> to batch all instances of each device type. This is essential for GPU parallelism on large circuits but adds overhead for small batch sizes:</p> <pre><code># 2 resistors: vmap adds vectorization overhead &gt; sequential evaluation\nvmapped_eval = jax.vmap(device_eval)(batched_params)\n</code></pre> <p>For rc (2 resistors), the vmap overhead exceeds the actual computation. For c6288 (~86,000 transistors), vmap amortizes perfectly.</p>"},{"location":"performance_analysis/#3-coo-matrix-assembly","title":"3. COO Matrix Assembly","text":"<p>VAJAX builds the Jacobian from COO (coordinate) format: 1. Each device type produces (row, col, value) triplets 2. Triplets are concatenated across device types 3. Duplicate indices are summed to form the final matrix</p> <p>VACASK stamps directly into a pre-allocated matrix with known positions. The COO approach enables JAX tracing and GPU parallelism but adds indirection.</p>"},{"location":"performance_analysis/#4-integration-coefficient-recomputation","title":"4. Integration Coefficient Recomputation","text":"<p>Variable-step BDF2 requires recomputing integration coefficients each step based on the step-size ratio. VACASK may use lookup tables or simplified formulas for common step ratios.</p>"},{"location":"performance_analysis/#gpu-acceleration-why-large-circuits-win","title":"GPU Acceleration: Why Large Circuits Win","text":"<p>GPU acceleration becomes beneficial when the per-step compute time exceeds the kernel launch and memory overhead (~100-500 us per step). This happens around 500+ nodes.</p>"},{"location":"performance_analysis/#mul64-133k-nodes-gpu-stress-test","title":"mul64 (133k nodes): GPU Stress Test","text":"<ul> <li>~266k PSP103 MOSFET evaluations per NR iteration</li> <li>Sparse Jacobian: 666,409 unknowns (133k nodes + 533k internal + 130 currents)</li> <li>3,259,918 CSR entries (from 30.5M COO triplets)</li> <li>Dense solve impossible (~3.3TB memory); sparse solver required</li> <li>Requires &gt;16GB GPU VRAM for cuDSS symbolic factorization</li> <li>Tesla T4 (16GB): OOM during <code>cudssExecute analysis</code></li> <li>Target: A100 40GB+ or similar</li> </ul>"},{"location":"performance_analysis/#c6288-5000-nodes-gpu-advantage","title":"c6288 (5000 nodes): GPU Advantage","text":"<ul> <li>Jacobian: 5000x5000 matrix operations</li> <li>Dense solve: O(n^3) = O(125 billion) operations per NR iteration</li> <li>GPU parallelism: thousands of concurrent threads</li> <li>Result: 4.4x speedup over CPU, 2.9x faster than VACASK</li> </ul>"},{"location":"performance_analysis/#rc-4-nodes-gpu-disadvantage","title":"rc (4 nodes): GPU Disadvantage","text":"<ul> <li>Jacobian: 4x4 matrix operations</li> <li>Dense solve: 64 multiply-adds per NR iteration</li> <li>GPU overhead: kernel launch &gt; actual compute</li> <li>Result: 20x slower than CPU (expected and correct)</li> </ul> <p>The <code>gpu_threshold</code> parameter (default: 500 nodes) automatically routes small circuits to CPU, avoiding this overhead in normal usage.</p>"},{"location":"performance_analysis/#potential-optimizations","title":"Potential Optimizations","text":"<p>These are known areas where the per-step overhead could be reduced:</p> <ol> <li> <p>Fused operations: Combine BDF2 coefficient computation with history    updates into a single kernel to reduce launch overhead.</p> </li> <li> <p>Direct stamping: For CPU path, stamp directly into pre-allocated    Jacobian instead of building COO triplets.</p> </li> <li> <p>Sequential device eval on CPU: Use a simple loop instead of vmap    when running on CPU with few device instances.</p> </li> <li> <p>Pre-computed coefficients: Cache BDF2 coefficients for common    step-size ratios.</p> </li> <li> <p>Reduced history depth: Currently maintains multi-step history for    BDF2; simpler methods (trapezoidal) would reduce overhead.</p> </li> </ol> <p>These optimizations would primarily benefit small-circuit CPU performance without affecting the large-circuit GPU path where VAJAX already outperforms VACASK.</p>"},{"location":"phi_nodes_guide/","title":"Guide to PHI Nodes in OpenVAF MIR","text":"<p>This guide explains PHI nodes: what they are, how they work in SSA (Static Single Assignment) form, how they're represented in OpenVAF's MIR, and how they translate to JAX's functional programming model.</p>"},{"location":"phi_nodes_guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>What Are PHI Nodes?</li> <li>How PHI Nodes Work</li> <li>PHI Nodes in OpenVAF MIR</li> <li>Converting PHI Nodes to JAX</li> <li>Debugging PHI Node Issues</li> </ol>"},{"location":"phi_nodes_guide/#what-are-phi-nodes","title":"What Are PHI Nodes?","text":"<p>PHI (\u03c6) nodes are a fundamental construct in Static Single Assignment (SSA) form, an intermediate representation used by compilers. They solve a key problem: how do you track which value a variable has when control flow merges from multiple paths?</p>"},{"location":"phi_nodes_guide/#the-problem-phi-nodes-solve","title":"The Problem PHI Nodes Solve","text":"<p>Consider this Verilog-A snippet:</p> <pre><code>if (TYPE == 1)\n    ids = ids_nmos;  // NMOS branch\nelse\n    ids = ids_pmos;  // PMOS branch\n// What is `ids` here?\n</code></pre> <p>After the if-else, <code>ids</code> could be either <code>ids_nmos</code> or <code>ids_pmos</code> depending on which branch executed. In SSA form, every variable can only be assigned once, so we can't write:</p> <pre><code>ids = ids_nmos    // definition 1\nids = ids_pmos    // definition 2 - ERROR! SSA violation\n</code></pre> <p>PHI nodes resolve this by explicitly representing the merge:</p> <pre><code>block_merge:\n    ids = phi [ids_nmos, block_nmos], [ids_pmos, block_pmos]\n</code></pre> <p>The PHI node says: \"The value of <code>ids</code> depends on which predecessor block we came from.\"</p>"},{"location":"phi_nodes_guide/#why-ssa-form","title":"Why SSA Form?","text":"<p>SSA form is used by most high-quality optimizing compilers (LLVM, GCC, OpenVAF) because it makes optimizations easier:</p> <ul> <li>Dead code elimination: Unused definitions are obvious</li> <li>Constant propagation: Each value has one definition to trace</li> <li>Register allocation: No need to track \"live ranges\" of variables</li> </ul>"},{"location":"phi_nodes_guide/#how-phi-nodes-work","title":"How PHI Nodes Work","text":""},{"location":"phi_nodes_guide/#semantics","title":"Semantics","text":"<p>A PHI node: 1. Is placed at the start of a basic block (before any other instructions) 2. Selects a value based on control flow \u2014 which predecessor we came from 3. Executes instantaneously \u2014 conceptually happens \"on the edge\" between blocks</p> <pre><code>phi [v1, block_a], [v2, block_b], [v3, block_c]\n</code></pre> <p>Means: - If we came from <code>block_a</code>, use <code>v1</code> - If we came from <code>block_b</code>, use <code>v2</code> - If we came from <code>block_c</code>, use <code>v3</code></p>"},{"location":"phi_nodes_guide/#example-loop-counter","title":"Example: Loop Counter","text":"<pre><code>block_entry:\n    v0 = 0\n    br block_loop\n\nblock_loop:\n    v1 = phi [v0, block_entry], [v2, block_loop]  // i = 0 or i+1\n    v2 = add v1, 1\n    cond = lt v2, 10\n    br_if cond, block_loop, block_exit\n</code></pre> <p>The PHI node tracks the loop counter: on first iteration it's <code>v0</code> (0), on subsequent iterations it's <code>v2</code> (the incremented value).</p>"},{"location":"phi_nodes_guide/#example-conditional-assignment","title":"Example: Conditional Assignment","text":"<pre><code>real x;\nif (a &gt; 0)\n    x = sqrt(a);\nelse\n    x = 0;\ny = x * 2;\n</code></pre> <p>Becomes:</p> <pre><code>block_entry:\n    cond = gt a, 0\n    br_if cond, block_true, block_false\n\nblock_true:\n    v1 = sqrt a\n    br block_merge\n\nblock_false:\n    v2 = 0.0\n    br block_merge\n\nblock_merge:\n    v3 = phi [v1, block_true], [v2, block_false]\n    v4 = mul v3, 2.0\n</code></pre>"},{"location":"phi_nodes_guide/#phi-nodes-in-openvaf-mir","title":"PHI Nodes in OpenVAF MIR","text":""},{"location":"phi_nodes_guide/#data-structure","title":"Data Structure","text":"<p>From <code>openvaf/mir/src/instructions.rs</code>:</p> <pre><code>pub struct PhiNode {\n    pub args: ValueList,   // Pool-allocated list of SSA values\n    pub blocks: PhiMap,    // Maps predecessor Block \u2192 index into args\n}\n</code></pre> <p>Key design choices: - Memory efficient: Values stored in external pool, not inline - B-forest mapping: O(log n) lookup for predecessor values - Sorted iteration: Deterministic block ordering</p>"},{"location":"phi_nodes_guide/#supporting-types","title":"Supporting Types","text":"<pre><code>pub type PhiForest = bforest::MapForest&lt;Block, u32&gt;;\npub type PhiMap = bforest::Map&lt;Block, u32&gt;;\n</code></pre> <p>The <code>PhiMap</code> uses a B-forest (balanced tree forest) data structure for efficient predecessor lookups.</p>"},{"location":"phi_nodes_guide/#text-representation","title":"Text Representation","text":"<p>When you see MIR output (via <code>openvaf-viz</code> or debug prints):</p> <pre><code>v17 = phi [v16, block0], [v18, block1], [v19, block2]\n</code></pre> <p>This means: - <code>v17</code> is the result of the PHI node - Coming from <code>block0</code> \u2192 use <code>v16</code> - Coming from <code>block1</code> \u2192 use <code>v18</code> - Coming from <code>block2</code> \u2192 use <code>v19</code></p>"},{"location":"phi_nodes_guide/#phi-node-creation-braun-algorithm","title":"PHI Node Creation (Braun Algorithm)","text":"<p>OpenVAF uses the Braun et al. (2013) algorithm for efficient SSA construction. PHI nodes are created when a variable is used in a block that has multiple predecessor blocks with different definitions.</p> <p>From <code>openvaf/mir_build/src/ssa.rs</code>:</p> <pre><code>ZeroOneOrMore::More =&gt; {\n    // Predecessors disagree on value - create PHI node\n    let mut args = ValueList::new();\n    let mut blocks = Map::new();\n\n    for (pred_block, pred_val) in predecessors {\n        let i = args.push(pred_val, &amp;mut pool);\n        blocks.insert(pred_block, i);\n    }\n\n    // Insert PHI at block entry point\n    cursor.at_first_insertion_point(dest_block)\n        .build(PhiNode { blocks, args });\n}\n</code></pre>"},{"location":"phi_nodes_guide/#phi-node-optimization","title":"PHI Node Optimization","text":"<p>PHI nodes can be simplified when all inputs are identical:</p> <pre><code>// From openvaf/mir_opt/src/simplify.rs\npub fn simplify_phi(&amp;mut self, phi: PhiNode) -&gt; Option&lt;Value&gt; {\n    let mut iter = self.func.dfg.phi_edges(&amp;phi);\n    if let Some((_, all_eq_val)) = iter.next() {\n        // If ALL edges have the same value, eliminate the PHI\n        if iter.all(|(_, val)| self.map_val(val) == all_eq_val) {\n            return Some(all_eq_val);  // Replace PHI with single value\n        }\n    }\n    None\n}\n</code></pre>"},{"location":"phi_nodes_guide/#converting-phi-nodes-to-jax","title":"Converting PHI Nodes to JAX","text":""},{"location":"phi_nodes_guide/#the-equivalence-ssa-functional-programming","title":"The Equivalence: SSA \u2248 Functional Programming","text":"<p>There's a well-known correspondence between SSA form and functional programming, established by Appel's seminal paper \"SSA is Functional Programming\":</p> SSA Concept Functional Equivalent Basic block Named function PHI node Function parameter Jump to block Tail call to function PHI edge value Argument in tail call <p>In functional terms, each basic block becomes a function, and PHI nodes become the parameters to those functions. The call sites determine which values reach the PHI.</p>"},{"location":"phi_nodes_guide/#if-conversion-phi-to-select","title":"If-Conversion: PHI to Select","text":"<p>For JAX specifically, we use if-conversion (also called predication) to transform control flow with PHI nodes into data-parallel select operations. This is necessary because:</p> <ol> <li>JAX traces programs into a dataflow graph (jaxpr)</li> <li><code>jnp.where</code> evaluates both branches (no lazy short-circuiting)</li> <li>GPU execution benefits from branchless code</li> </ol> <p>The transformation converts:</p> <pre><code>block_merge:\n    v3 = phi [v1, block_true], [v2, block_false]\n</code></pre> <p>Into:</p> <pre><code>v3 = jnp.where(condition, v1, v2)\n</code></pre>"},{"location":"phi_nodes_guide/#the-algorithm","title":"The Algorithm","text":"<p>The general if-conversion algorithm for PHI nodes:</p> <ol> <li>Identify the condition that determines which predecessor was taken</li> <li>Compute both branch values (even if one won't be used)</li> <li>Use select to merge based on the condition</li> </ol> <p>For a 2-way PHI (if-else): <pre><code># MIR: v_result = phi [v_true, block_true], [v_false, block_false]\n# JAX: v_result = jnp.where(cond, v_true, v_false)\n</code></pre></p> <p>For an N-way PHI (switch/case): <pre><code># MIR: v_result = phi [v0, block0], [v1, block1], [v2, block2]\n# JAX: v_result = jnp.select([cond0, cond1, cond2], [v0, v1, v2], default)\n# Or:  v_result = lax.switch(index, [lambda: v0, lambda: v1, lambda: v2])\n</code></pre></p>"},{"location":"phi_nodes_guide/#jax-control-flow-primitives","title":"JAX Control Flow Primitives","text":"Primitive Use Case Evaluation <code>jnp.where(cond, t, f)</code> 2-way select Both branches evaluated <code>jnp.select(conds, vals)</code> N-way select All branches evaluated <code>lax.cond(cond, t_fn, f_fn)</code> Scalar condition Lazy (one branch) <code>lax.switch(idx, fns)</code> N-way scalar Lazy (one branch) <p>For openvaf_jax, we typically use <code>jnp.where</code> because: - Device evaluation is batched (conditions are arrays) - Both branches contain useful gradient information - GPUs prefer branchless code</p>"},{"location":"phi_nodes_guide/#nested-phi-nodes","title":"Nested PHI Nodes","text":"<p>Complex control flow creates nested PHI nodes:</p> <pre><code>if (a &gt; 0) {\n    if (b &gt; 0)\n        x = 1;\n    else\n        x = 2;\n} else {\n    x = 3;\n}\n</code></pre> <p>This creates PHI nodes at two levels, which translate to nested <code>jnp.where</code>:</p> <pre><code>x_inner = jnp.where(b &gt; 0, 1, 2)\nx = jnp.where(a &gt; 0, x_inner, 3)\n</code></pre>"},{"location":"phi_nodes_guide/#performance-considerations","title":"Performance Considerations","text":"<p>Eager evaluation: <code>jnp.where</code> always computes both branches. This is usually fine for numerical code but can be wasteful for: - Expensive computations only needed in one branch - Branches with different numerical stability requirements</p> <p>Solution for expensive branches: Use <code>lax.cond</code> when: - Condition is a scalar (not batched) - One branch is significantly more expensive - You need lazy evaluation for correctness</p>"},{"location":"phi_nodes_guide/#debugging-phi-node-issues","title":"Debugging PHI Node Issues","text":""},{"location":"phi_nodes_guide/#why-phi-nodes-matter-for-openvaf_jax","title":"Why PHI Nodes Matter for openvaf_jax","text":"<p>When OpenVAF compiles Verilog-A to JAX Python code, PHI nodes become <code>jnp.where()</code> calls. If the condition is wrong, or if one branch returns 0.0 when it shouldn't, the PHI node propagates that error through the entire computation.</p>"},{"location":"phi_nodes_guide/#common-phi-node-bugs","title":"Common PHI Node Bugs","text":"<ol> <li> <p>Zero from wrong branch: A PHI has <code>[v3, block_unused]</code> where <code>v3 = 0.0</code>. If control flow incorrectly takes this path, output goes to zero.</p> </li> <li> <p>TYPE parameter issues: NMOS/PMOS selection depends on a PHI that chooses based on <code>TYPE == 1</code>. If TYPE isn't propagated correctly, wrong branch executes.</p> </li> <li> <p>Constant folding artifacts: Optimizer inlines a constant into one PHI edge but not others, creating asymmetry.</p> </li> <li> <p>Dead branch pollution: A branch that \"shouldn't\" execute still contributes values that get selected by <code>jnp.where</code>.</p> </li> </ol>"},{"location":"phi_nodes_guide/#debugging-tools","title":"Debugging Tools","text":""},{"location":"phi_nodes_guide/#mir-analysis-script","title":"MIR Analysis Script","text":"<pre><code># Find all PHI nodes\nuv run scripts/analyze_mir_cfg.py model.va --func eval --find-phis\n\n# Trace what value feeds into a specific PHI\nuv run scripts/analyze_mir_cfg.py model.va --func eval --trace-value v12345\n\n# See which block defines a suspicious value\nuv run scripts/analyze_mir_cfg.py model.va --func eval --analyze-block block4654\n\n# Find branch points (conditionals)\nuv run scripts/analyze_mir_cfg.py model.va --func eval --branches\n</code></pre>"},{"location":"phi_nodes_guide/#mirinspector-class","title":"MIRInspector Class","text":"<pre><code>from vajax.debug import MIRInspector\n\ninspector = MIRInspector(va_path)\ninspector.print_phi_summary('eval')  # Show all PHI nodes\n\n# Find PHIs that have v3 (often 0.0) as an operand\ninspector.find_phi_nodes_with_value('v3')\n</code></pre>"},{"location":"phi_nodes_guide/#typical-debugging-workflow","title":"Typical Debugging Workflow","text":"<ol> <li>Identify symptom: JAX returns wrong current or zeros</li> <li>Compare outputs: Use <code>ModelComparator</code> to find discrepancy</li> <li>Check cache: Look for inf/nan or wrong temperature values</li> <li>Inspect PHIs: Find PHI nodes with suspicious zero operands</li> <li>Trace control flow: Identify which branch condition is wrong</li> <li>Fix translation: Usually a parameter mapping or type issue</li> </ol>"},{"location":"phi_nodes_guide/#example-zero-current-bug","title":"Example: Zero Current Bug","text":"<p>Symptom: OSDI returns 1mA drain current, JAX returns 1e-15A</p> <p>Investigation: <pre><code>inspector = MIRInspector(va_path)\nzero_phis = inspector.find_phi_nodes_with_value('v3')  # v3 = 0.0\n# Found: v789 = phi [v788, block_nmos], [v3, block_pmos]\n</code></pre></p> <p>Root cause: TYPE parameter wasn't passed correctly, so JAX took the PMOS branch (which returns 0 for an NMOS device).</p> <p>Fix: Ensure <code>TYPE</code> is included in the parameter array passed to the compiled function.</p>"},{"location":"phi_nodes_guide/#summary","title":"Summary","text":"Concept Description Purpose Merge values from different control flow paths in SSA form Syntax <code>v_result = phi [v1, block1], [v2, block2], ...</code> Semantics \"Select value based on which predecessor we came from\" Placement Always at the start of a basic block In JAX Becomes <code>jnp.where(condition, val_true, val_false)</code> Algorithm If-conversion / predication transforms branches to selects Common bug One PHI edge has 0.0 and wrong branch is taken"},{"location":"phi_nodes_guide/#references","title":"References","text":"<ul> <li>Appel, A. W. (1998). SSA is Functional Programming. ACM SIGPLAN Notices.</li> <li>Braun, M. et al. (2013). Simple and Efficient Construction of Static Single Assignment Form. CC 2013.</li> <li>Chuang, W. et al. (2003). Phi-Predication for Light-Weight If-Conversion. CGO 2003.</li> <li>Kelsey, R. A. (1995). A Correspondence between Continuation Passing Style and Static Single Assignment Form. IR'95.</li> <li>JAX Documentation: Control Flow</li> </ul>"},{"location":"psp102_debug_plan/","title":"PSP102 Debug Plan","text":""},{"location":"psp102_debug_plan/#current-status","title":"Current Status","text":"<p>PSP102 model comparison tests show false positives - tests pass due to absolute tolerance masking a 5 order of magnitude error.</p>"},{"location":"psp102_debug_plan/#quantified-problem","title":"Quantified Problem","text":"Metric OSDI JAX Issue Ids (drain current) 4.79e-11 A 5e-16 A ~100,000x too small Jacobian max 4.76e+11 1.0 Almost all zeros Non-zero Jacobian entries 11 1 Missing entries <p>The test uses <code>max_diff &lt; 1e-6</code> absolute tolerance. Since <code>4.79e-11 &lt; 1e-6</code>, the test passes despite JAX returning essentially zero current.</p>"},{"location":"psp102_debug_plan/#what-works","title":"What Works","text":"<ul> <li>Cache computation (init): 364 values, 242 non-zero, no inf/nan</li> <li>Voltage mapping: Correct node names (D, G, S, B, NOI, NOI2, GP, BP, BI, BS, BD)</li> <li>Parameter setting: TYPE=1, W=1e-6, L=1e-7 passed correctly to init</li> </ul>"},{"location":"psp102_debug_plan/#what-doesnt-work","title":"What Doesn't Work","text":"<ul> <li>Eval function: Returns near-zero residuals and Jacobian</li> <li>NMOS/PMOS branching: PSP102 uses TYPE parameter for device polarity</li> <li>PHI node resolution: 313 blocks with PHIs in eval function</li> </ul>"},{"location":"psp102_debug_plan/#root-cause-hypothesis","title":"Root Cause Hypothesis","text":"<p>PSP102 has complex NMOS/PMOS conditional branching controlled by the TYPE parameter. The JAX translator likely has issues with:</p> <ol> <li>PHI node resolution in the NMOS/PMOS branch selection</li> <li>TYPE parameter flow from init cache to eval computation</li> <li>Control flow merging where NMOS and PMOS paths rejoin</li> </ol> <p>Since the current is ~1e-15 (numerical noise level), the entire current computation is likely being skipped or zeroed out due to incorrect branch selection.</p>"},{"location":"psp102_debug_plan/#debugging-strategy","title":"Debugging Strategy","text":""},{"location":"psp102_debug_plan/#phase-1-trace-type-parameter-flow","title":"Phase 1: Trace TYPE Parameter Flow","text":"<ol> <li>Find where TYPE is stored in the cache</li> <li>Verify TYPE value propagates correctly to eval</li> <li>Check if TYPE-dependent branches are executing</li> </ol>"},{"location":"psp102_debug_plan/#phase-2-identify-divergence-point","title":"Phase 2: Identify Divergence Point","text":"<p>Compare OSDI vs JAX at intermediate computation points:</p> <ol> <li>Input arrays: Verify voltages and cache values match</li> <li>Early computations: Find first value that diverges</li> <li>PHI resolutions: Check if PHI nodes select correct predecessor</li> </ol>"},{"location":"psp102_debug_plan/#phase-3-mir-analysis","title":"Phase 3: MIR Analysis","text":"<p>Use the debug tools we developed:</p> <pre><code># Find PHI nodes in PSP102 eval\nuv run scripts/analyze_mir_cfg.py vendor/OpenVAF/integration_tests/PSP102/psp102.va \\\n    --func eval --find-phis\n\n# Trace control flow to specific blocks\nuv run scripts/analyze_mir_cfg.py vendor/OpenVAF/integration_tests/PSP102/psp102.va \\\n    --func eval --branches\n</code></pre>"},{"location":"psp102_debug_plan/#phase-4-compare-with-working-models","title":"Phase 4: Compare with Working Models","text":"<p>EKV and MVSG work correctly. Compare their: - PHI node count and complexity - TYPE parameter handling (EKV also has TYPE for NMOS/PMOS) - Control flow structure</p>"},{"location":"psp102_debug_plan/#tools-available","title":"Tools Available","text":"Tool Purpose <code>scripts/analyze_mir_cfg.py</code> CFG analysis, PHI node finding, path tracing <code>vajax/debug/mir_tracer.py</code> Value flow tracing through MIR <code>vajax/debug/param_analyzer.py</code> Parameter kind analysis <code>vajax/debug/jacobian.py</code> Format-aware Jacobian comparison"},{"location":"psp102_debug_plan/#next-steps","title":"Next Steps","text":"<ol> <li>[ ] Generate detailed MIR dump for PSP102 eval function</li> <li>[ ] Find TYPE-dependent branch points in the CFG</li> <li>[ ] Trace which path JAX takes vs which path it should take</li> <li>[ ] Compare with EKV (working) to identify pattern differences</li> <li>[ ] Fix PHI resolution or branch selection issue</li> <li>[ ] Update test tolerances to catch this class of error</li> </ol>"},{"location":"psp102_debug_plan/#test-improvement","title":"Test Improvement","text":"<p>After fixing PSP102, update tests to use relative tolerance:</p> <pre><code># Current (masks errors):\nassert max_diff &lt; 1e-6\n\n# Better (catches magnitude errors):\nassert np.allclose(osdi_ids, jax_ids, rtol=1e-4, atol=1e-20)\n</code></pre>"},{"location":"sim_back_vs_openvaf_jax/","title":"sim_back vs openvaf_jax: Compilation Pipeline Comparison","text":"<p>This document compares the OpenVAF <code>sim_back</code> crate's compilation pipeline with our <code>openvaf_jax</code> implementation. Understanding the differences helps identify where our implementation may be missing features or taking shortcuts.</p>"},{"location":"sim_back_vs_openvaf_jax/#overview","title":"Overview","text":"Aspect sim_back (OpenVAF) openvaf_jax Target OSDI (LLVM IR) JAX Python code Approach Full compilation with optimization Interpret MIR, generate Python Optimization Multi-pass (GVN, DCE, SCCP) None (relies on JAX JIT) Auto-diff Internal MIR-based autodiff Relies on JAX autodiff (partial)"},{"location":"sim_back_vs_openvaf_jax/#pipeline-stages-comparison","title":"Pipeline Stages Comparison","text":""},{"location":"sim_back_vs_openvaf_jax/#sim_back-pipeline","title":"sim_back Pipeline","text":"<pre><code>HIR \u2192 MIR \u2192 Optimize \u2192 Topology \u2192 DAE System \u2192 Optimize \u2192 Init Extraction \u2192 OSDI Codegen\n</code></pre>"},{"location":"sim_back_vs_openvaf_jax/#openvaf_jax-pipeline","title":"openvaf_jax Pipeline","text":"<pre><code>MIR (from openvaf_py) \u2192 Parse \u2192 Generate Python \u2192 exec() \u2192 JAX JIT\n</code></pre>"},{"location":"sim_back_vs_openvaf_jax/#stage-by-stage-comparison","title":"Stage-by-Stage Comparison","text":""},{"location":"sim_back_vs_openvaf_jax/#1-input-representation","title":"1. Input Representation","text":"sim_back openvaf_jax Builds MIR from HIR using <code>MirBuilder</code> Receives pre-computed MIR from <code>openvaf_py</code> Has full access to HIR for symbol resolution Has serialized MIR data + metadata Can modify/rebuild MIR during compilation Read-only interpretation of MIR <p>What we receive from openvaf_py: - <code>get_mir_instructions()</code> - Eval function MIR - <code>get_init_mir_instructions()</code> - Init function MIR - <code>get_dae_system()</code> - Pre-computed DAE structure - Metadata: params, nodes, cache_mapping</p>"},{"location":"sim_back_vs_openvaf_jax/#2-optimization","title":"2. Optimization","text":"sim_back openvaf_jax Initial: DCE, SCCP, inst_combine, CFG simplify, GVN None PostDerivative: SCCP, inst_combine, CFG simplify, GVN None Final: Aggressive DCE None <p>Gap: We skip all IR-level optimization, relying on: - OpenVAF's optimization (runs before MIR export) - JAX's JIT compilation (XLA)</p>"},{"location":"sim_back_vs_openvaf_jax/#3-topology-construction","title":"3. Topology Construction","text":"sim_back openvaf_jax Branch extraction from MIR Pre-computed in <code>dae_data['residuals']</code> Linearization of <code>ddt()</code>, noise Pre-computed (result embedded in MIR) Small-signal detection Not implemented Implicit equation creation Pre-computed <p>sim_back's linearization logic: <pre><code>For each ddt()/noise:\n  If only used in linear chain (fadd, fsub, fneg, fmul with non-OP-dep) \u2192\n    Extract as separate \"dimension\" (react coefficient)\n  Else \u2192\n    Create implicit equation (new unknown)\n</code></pre></p> <p>Our approach: OpenVAF has already done linearization. The MIR we receive has: - Resistive contributions (<code>resist</code>) - Reactive contributions (<code>react</code>) - These are separate outputs in <code>dae_data</code></p>"},{"location":"sim_back_vs_openvaf_jax/#4-dae-system-construction","title":"4. DAE System Construction","text":"sim_back openvaf_jax Builds residuals from branch contributions Receives <code>dae_data['residuals']</code> Runs autodiff on MIR to get Jacobian Receives <code>dae_data['jacobian']</code> Computes <code>lim_rhs</code> correction terms Receives <code>lim_rhs_resist</code>, <code>lim_rhs_react</code> Handles mfactor scaling Pre-computed Extracts noise sources Pre-computed (not used in JAX path) <p>sim_back's autodiff: <pre><code>let derivatives = auto_diff(ctx, residuals, unknowns);\n// Returns: (residual_value, unknown) \u2192 derivative_value\n</code></pre></p> <p>Our approach: We receive pre-differentiated MIR. The Jacobian entries in <code>dae_data['jacobian']</code> reference MIR values that are already the partial derivatives.</p>"},{"location":"sim_back_vs_openvaf_jax/#5-op-dependence-analysis","title":"5. OP-Dependence Analysis","text":"sim_back openvaf_jax Tracks which values depend on unknowns Not explicit Uses dominance frontiers for control deps CFG analysis for loops only Two-phase: <code>init_op_dependent_insts</code>, <code>refresh_op_dependent_insts</code> Implicit via init/eval split <p>sim_back's OP-dependent roots: - <code>ParamKind::Voltage</code> - Node voltages - <code>ParamKind::Current</code> - Branch currents - <code>ParamKind::ImplicitUnknown</code> - Internal unknowns - System functions: <code>$abstime</code>, <code>$temperature</code></p> <p>Our approach: OpenVAF already split the code: - <code>init</code> function: OP-independent (cached values) - <code>eval</code> function: OP-dependent (per Newton iteration)</p>"},{"location":"sim_back_vs_openvaf_jax/#6-initialization-extraction","title":"6. Initialization Extraction","text":"sim_back openvaf_jax <code>Initialization::new()</code> splits MIR Pre-split by OpenVAF GVN deduplication of cache slots Pre-computed cache_mapping Creates separate <code>init</code> and <code>eval</code> MIR functions Receives separate MIR for each Cache slot assignment <code>cache_mapping[i]['init_value']</code> \u2192 <code>cache_mapping[i]['eval_param']</code> <p>sim_back cache slot assignment: <pre><code>fn ensure_cache_slot(inst, res, ty) -&gt; CacheSlot {\n    let class = gvn.inst_class(inst);  // GVN equivalence\n    cache_slots.insert((class, res), ty)\n}\n</code></pre></p> <p>Our approach: <code>cache_mapping</code> from OpenVAF maps init values to eval params.</p>"},{"location":"sim_back_vs_openvaf_jax/#7-node-collapse","title":"7. Node Collapse","text":"sim_back openvaf_jax <code>NodeCollapse::new()</code> detects collapsible pairs <code>collapsible_pairs</code> from module Runtime collapse decisions <code>collapse_decision_outputs</code> from init <p>Both handle: Nodes that can be shorted under certain parameter conditions.</p>"},{"location":"sim_back_vs_openvaf_jax/#8-code-generation","title":"8. Code Generation","text":"sim_back openvaf_jax LLVM IR via <code>osdi</code> crate Python AST \u2192 source code Type-safe register allocation Dynamic Python typing Inlined operations JAX operations Memory layout control JAX arrays"},{"location":"sim_back_vs_openvaf_jax/#feature-coverage","title":"Feature Coverage","text":""},{"location":"sim_back_vs_openvaf_jax/#fully-supported","title":"Fully Supported","text":"Feature sim_back openvaf_jax Resistive contributions \u2705 \u2705 Reactive contributions (ddt) \u2705 \u2705 Sparse Jacobian \u2705 \u2705 Node collapse \u2705 \u2705 Parameter caching (init/eval split) \u2705 \u2705 Limiting (lim_rhs correction) \u2705 \u2705 mfactor scaling \u2705 \u2705 (pre-computed) Small-signal data extraction \u2705 \u2705"},{"location":"sim_back_vs_openvaf_jax/#partially-supported","title":"Partially Supported","text":"Feature sim_back openvaf_jax Gap Implicit equations \u2705 \u26a0\ufe0f Partial We handle pre-resolved implicit eqns Switch branches \u2705 \u26a0\ufe0f Partial Not fully tested Temperature dependence \u2705 \u26a0\ufe0f Need to verify param mapping"},{"location":"sim_back_vs_openvaf_jax/#not-supported","title":"Not Supported","text":"Feature sim_back openvaf_jax Reason Noise analysis \u2705 \u274c Not in scope Runtime branch switching \u2705 \u274c Complex control flow"},{"location":"sim_back_vs_openvaf_jax/#data-structure-mapping","title":"Data Structure Mapping","text":""},{"location":"sim_back_vs_openvaf_jax/#residuals","title":"Residuals","text":"<pre><code>sim_back:                          openvaf_jax:\nResidual {                         dae_data['residuals'][i] = {\n  resist: Value,                     'resist_var': 'mir_XX',\n  react: Value,                      'react_var': 'mir_YY',\n  resist_small_signal: Value,        'resist_small_signal_var': 'mir_SS1',\n  react_small_signal: Value,         'react_small_signal_var': 'mir_SS2',\n  resist_lim_rhs: Value,             'resist_lim_rhs_var': 'mir_ZZ',\n  react_lim_rhs: Value,              'react_lim_rhs_var': 'mir_WW',\n  nature_kind: Flow|Potential|Switch 'node_name': 'A'\n}                                  }\n</code></pre> <p>Additionally, <code>dae_data['small_signal_params']</code> lists parameters known to be zero in large-signal analysis.</p>"},{"location":"sim_back_vs_openvaf_jax/#jacobian","title":"Jacobian","text":"<pre><code>sim_back:                          openvaf_jax:\nMatrixEntry {                      dae_data['jacobian'][i] = {\n  row: SimUnknown,                   'row_node_name': 'A',\n  col: SimUnknown,                   'col_node_name': 'B',\n  resist: Value,                     'resist': 'mir_XX',\n  react: Value,                      'react': 'mir_YY',\n}                                  }\n</code></pre>"},{"location":"sim_back_vs_openvaf_jax/#cache","title":"Cache","text":"<pre><code>sim_back:                          openvaf_jax:\nInitialization {                   init_mir_data['cache_mapping'][i] = {\n  cached_vals: {                     'init_value': 'mir_XX',\n    eval_value \u2192 CacheSlot           'eval_param': 42\n  },                               }\n  cache_slots: {\n    (gvn_class, res_idx) \u2192 Type\n  }\n}\n</code></pre>"},{"location":"sim_back_vs_openvaf_jax/#performance-implications","title":"Performance Implications","text":""},{"location":"sim_back_vs_openvaf_jax/#sim_back-advantages","title":"sim_back Advantages","text":"<ol> <li>Multi-pass optimization reduces instruction count before codegen</li> <li>GVN deduplication minimizes cache size</li> <li>Aggressive DCE removes truly dead code</li> <li>LLVM backend can do further optimization</li> </ol>"},{"location":"sim_back_vs_openvaf_jax/#openvaf_jax-advantages","title":"openvaf_jax Advantages","text":"<ol> <li>JAX JIT provides XLA optimization at runtime</li> <li>vmap enables efficient batched device evaluation</li> <li>GPU acceleration via JAX backends</li> <li>Python ecosystem for debugging/analysis</li> </ol>"},{"location":"sim_back_vs_openvaf_jax/#potential-improvements-for-openvaf_jax","title":"Potential Improvements for openvaf_jax","text":"<ol> <li>Dead code elimination - Some MIR values may be unused</li> <li>Constant folding - Could pre-compute constant expressions</li> <li>Cache optimization - Verify no redundant cache entries</li> <li>Small-signal support - For AC analysis in future</li> </ol>"},{"location":"sim_back_vs_openvaf_jax/#recommendations","title":"Recommendations","text":""},{"location":"sim_back_vs_openvaf_jax/#short-term","title":"Short-term","text":"<ol> <li>Verify all <code>dae_data</code> fields are correctly used</li> <li>Add validation for cache_mapping completeness</li> <li>Test limiting (lim_rhs) paths more thoroughly</li> </ol>"},{"location":"sim_back_vs_openvaf_jax/#medium-term","title":"Medium-term","text":"<ol> <li>Consider MIR-level dead code elimination</li> <li>Profile cache usage to identify redundancies</li> <li>Implement small_signal handling if AC needed</li> </ol>"},{"location":"sim_back_vs_openvaf_jax/#long-term","title":"Long-term","text":"<ol> <li>Evaluate whether MIR-level optimization adds value</li> <li>Consider autodiff at Python level for flexibility</li> <li>Noise analysis support if needed</li> </ol>"},{"location":"sim_back_vs_openvaf_jax/#references","title":"References","text":"<ul> <li><code>vendor/OpenVAF/docs/sim_back/sim_back.md</code> - Main overview</li> <li><code>vendor/OpenVAF/docs/sim_back/init.md</code> - Initialization extraction</li> <li><code>vendor/OpenVAF/docs/sim_back/dae.md</code> - DAE system construction</li> <li><code>vendor/OpenVAF/docs/sim_back/topology.md</code> - Branch/linearization</li> <li><code>vendor/OpenVAF/docs/sim_back/context.md</code> - Compilation context</li> </ul>"},{"location":"sparse_solver_roadmap/","title":"Roadmap: GPU/TPU-Agnostic Sparse Linear Solvers in JAX","text":"<p>Date: 2025-12-20 Status: Draft Authors: Robert Taylor, Claude</p>"},{"location":"sparse_solver_roadmap/#goal","title":"Goal","text":"<p>Enable efficient sparse linear solving in VAJAX that works across CPU, GPU (NVIDIA, AMD), and TPU, with cached symbolic factorization for Newton-Raphson iterations.</p>"},{"location":"sparse_solver_roadmap/#current-state-of-jax-sparse-support","title":"Current State of JAX Sparse Support","text":""},{"location":"sparse_solver_roadmap/#what-exists","title":"What Exists","text":"Feature Status Source BCOO format Stable PR #6824 BCSR format Stable jax.experimental.sparse <code>spsolve</code> Experimental Uses cuSOLVER on GPU, no caching <code>gmres</code>, <code>cg</code>, <code>bicgstab</code> Experimental Issue #11376 Sparse matmul (SpMV, SpMM) Stable Uses cusparse on GPU"},{"location":"sparse_solver_roadmap/#whats-missing","title":"What's Missing","text":"<ol> <li>Cached symbolic factorization - Every <code>spsolve</code> call redoes METIS ordering</li> <li>TPU sparse support - Limited to dense operations</li> <li>Sparse triangular solve - Not exposed as primitive</li> <li>Pre-factorization API - JAX Issue #22500</li> </ol>"},{"location":"sparse_solver_roadmap/#relevant-jaxxlamlir-work","title":"Relevant JAX/XLA/MLIR Work","text":""},{"location":"sparse_solver_roadmap/#closedstale-prs-potential-revival","title":"Closed/Stale PRs (Potential Revival)","text":"PR Description Status Relevance #6555 MLIR/TACO-like sparse representation Closed (stale) HIGH - Explored MLIR sparse tensor integration #4422 Add experimental sparse support Merged Foundation for current sparse module #2566 scipy.sparse.linalg.cg Merged Iterative solver baseline"},{"location":"sparse_solver_roadmap/#activerecent-work","title":"Active/Recent Work","text":"PR/Issue Description Status Relevance #25958 Performance note on sparse docs Merged (Jan 2025) Documents current limitations #11376 Development of scipy.sparse.linalg Open Tracking issue for sparse solvers LLVM #151885 MLIR sparse loop ordering heuristics Active 30% speedup on sparse workloads"},{"location":"sparse_solver_roadmap/#mlir-sparse-tensor-dialect","title":"MLIR Sparse Tensor Dialect","text":"<p>The MLIR Sparse Tensor Dialect provides: - ~40 sparse tensor operations - Multiple storage formats (COO, CSR, CSC, etc.) - Automatic code generation from sparsity-agnostic Linalg ops - GPU codegen (experimental)</p> <p>Gap: No direct LU factorization or triangular solve ops. Focus is on SpMM/SpMV.</p> <p>Reference: Compiler Support for Sparse Tensor Computations in MLIR</p>"},{"location":"sparse_solver_roadmap/#xla-sparse-support","title":"XLA Sparse Support","text":"<p>XLA has limited sparse support: - <code>SparseTensorDotGeneral</code> for sparse matmul - Custom calls to cuSPARSE for GPU - No native sparse LU or triangular solve</p> <p>Relevant issues: - openxla/xla#6834 - Triangular solve integer overflow (fixed) - openxla/xla#6871 - Fix for above</p>"},{"location":"sparse_solver_roadmap/#proposed-architecture","title":"Proposed Architecture","text":""},{"location":"sparse_solver_roadmap/#phase-1-hybrid-backend-immediate","title":"Phase 1: Hybrid Backend (Immediate)","text":"<pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  VAJAX NR   \u2502\n                    \u2502    Solver       \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502              \u2502              \u2502\n              \u25bc              \u25bc              \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 Spineax \u2502   \u2502  GMRES  \u2502   \u2502  Dense  \u2502\n        \u2502 (cuDSS) \u2502   \u2502 + Prec  \u2502   \u2502  BLAS   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            GPU          TPU/CPU       CPU\n</code></pre> <p>Implementation: Done (Spineax integration committed)</p>"},{"location":"sparse_solver_roadmap/#phase-2-pure-jax-iterative-solver-short-term","title":"Phase 2: Pure JAX Iterative Solver (Short-term)","text":"<p>Add GMRES with block-Jacobi preconditioner as agnostic fallback:</p> <pre><code># vajax/analysis/iterative_solver.py\n\ndef build_block_jacobi_preconditioner(J_diag_blocks):\n    \"\"\"Build M^-1 from diagonal blocks of Jacobian.\"\"\"\n    inv_blocks = [jnp.linalg.inv(b) for b in J_diag_blocks]\n    def apply_M_inv(v):\n        # Apply block-diagonal inverse\n        return jnp.concatenate([inv @ v_i for inv, v_i in zip(inv_blocks, split(v))])\n    return apply_M_inv\n\ndef gmres_solve(J, b, preconditioner=None, restart=30, maxiter=100):\n    \"\"\"Solve Jx = b using preconditioned GMRES.\"\"\"\n    return jax.scipy.sparse.linalg.gmres(\n        lambda v: J @ v,\n        b,\n        M=preconditioner,\n        restart=restart,\n        maxiter=maxiter,\n    )\n</code></pre> <p>Effort: 1-2 weeks Benefit: Works on all backends, no custom ops</p>"},{"location":"sparse_solver_roadmap/#phase-3-xla-sparse-primitive-medium-term","title":"Phase 3: XLA Sparse Primitive (Medium-term)","text":"<p>Add sparse triangular solve to XLA via custom call:</p> <pre><code>XLA HLO:\n  SparseLU(sparse_matrix) -&gt; (L, U, perm)  # Factorize\n  SparseTriangularSolve(L, b) -&gt; x         # Forward sub\n  SparseTriangularSolve(U, x) -&gt; y         # Back sub\n</code></pre> <p>This requires: 1. Define HLO ops for sparse LU components 2. Implement CPU lowering (via SuiteSparse/KLU) 3. Implement GPU lowering (via cuDSS) 4. Add JAX bindings</p> <p>Effort: 2-3 months (significant XLA contribution) Benefit: Native caching, works with XLA optimizations</p>"},{"location":"sparse_solver_roadmap/#phase-4-mlir-sparse-integration-long-term","title":"Phase 4: MLIR Sparse Integration (Long-term)","text":"<p>Leverage MLIR Sparse Tensor Dialect:</p> <ol> <li>Define sparse LU in Linalg dialect - Express as sparse tensor operations</li> <li>Use MLIR sparsifier - Generate optimized code automatically</li> <li>Multi-backend codegen - CPU, GPU, TPU from single definition</li> </ol> <p>Reference: MLIR Sparsifier JAX Colab</p> <p>Effort: 6-12 months (research project) Benefit: True platform independence, compiler-level optimization</p>"},{"location":"sparse_solver_roadmap/#technical-challenges","title":"Technical Challenges","text":""},{"location":"sparse_solver_roadmap/#1-symbolic-factorization-caching-in-xla","title":"1. Symbolic Factorization Caching in XLA","text":"<p>XLA's functional model doesn't naturally support mutable state (cached factorization).</p> <p>Options: - Use XLA state tokens (like RNG state) - Store factorization as \"constant\" in compiled program - Use external state via custom call</p>"},{"location":"sparse_solver_roadmap/#2-tpu-sparse-support","title":"2. TPU Sparse Support","text":"<p>TPUs are optimized for dense, regular computation. Sparse operations have overhead.</p> <p>Options: - Dense solver for small matrices (our current approach works) - Padded block-sparse for structured sparsity - Iterative solvers (GMRES) which are more TPU-friendly</p>"},{"location":"sparse_solver_roadmap/#3-dynamic-sparsity-patterns","title":"3. Dynamic Sparsity Patterns","text":"<p>Some applications have varying sparsity. Our circuit simulation has fixed patterns.</p> <p>Options: - Re-analyze on pattern change (expensive but rare) - Approximate with superset pattern - Fall back to iterative solver</p>"},{"location":"sparse_solver_roadmap/#recommendations","title":"Recommendations","text":""},{"location":"sparse_solver_roadmap/#for-vajax-immediate","title":"For VAJAX (Immediate)","text":"<ol> <li>\u2705 Use Spineax on NVIDIA GPUs (done)</li> <li>Add GMRES fallback for TPU/other GPUs</li> <li>Keep dense option for small circuits</li> </ol>"},{"location":"sparse_solver_roadmap/#for-jax-ecosystem-contribution","title":"For JAX Ecosystem (Contribution)","text":"<ol> <li>Propose <code>spsolve_prefactor</code> API to JAX (Issue #22500)</li> <li>Add sparse triangular solve primitive</li> <li>Document hybrid sparse strategy</li> </ol>"},{"location":"sparse_solver_roadmap/#for-long-term-research","title":"For Long-term Research","text":"<ol> <li>Explore MLIR sparsifier for LU</li> <li>Work with XLA team on sparse primitive design</li> <li>Investigate AMD ROCm sparse solver integration</li> </ol>"},{"location":"sparse_solver_roadmap/#todo-tpu-and-non-nvidia-gpu-support","title":"TODO: TPU and Non-NVIDIA GPU Support","text":""},{"location":"sparse_solver_roadmap/#open-issues","title":"Open Issues","text":"<ul> <li>[ ] TPU CI failing - PR #1 adds TPU CI but tests are timing out/cancelled</li> <li>TPU tests ran for 6+ hours before being cancelled</li> <li>Need to investigate: is it a VM provisioning issue or actual test hang?</li> </ul>"},{"location":"sparse_solver_roadmap/#tpu-support-tasks","title":"TPU Support Tasks","text":"<ul> <li>[ ] Implement GMRES + block-Jacobi fallback solver</li> <li>Create <code>vajax/analysis/iterative_solver.py</code></li> <li>Extract diagonal blocks from Jacobian for preconditioner</li> <li>Use <code>jax.scipy.sparse.linalg.gmres</code> with matrix-free matvec</li> <li> <p>Benchmark on TPU vs dense solver</p> </li> <li> <p>[ ] Test dense solver on TPU</p> </li> <li>Verify current dense path works on TPU</li> <li>Measure performance for c6288 benchmark</li> <li> <p>Document TPU-specific tuning (e.g., padding for XLA efficiency)</p> </li> <li> <p>[ ] Fix TPU CI workflow</p> </li> <li>Debug why TPU tests timeout</li> <li>Add proper timeout handling</li> <li>Consider running smaller benchmarks for CI</li> </ul>"},{"location":"sparse_solver_roadmap/#non-nvidia-gpu-support-tasks","title":"Non-NVIDIA GPU Support Tasks","text":"<ul> <li>[ ] AMD ROCm investigation</li> <li>Check if JAX <code>spsolve</code> works on ROCm</li> <li>Investigate hipSPARSE/rocSOLVER for cached factorization</li> <li> <p>Look for ROCm equivalent to cuDSS</p> </li> <li> <p>[ ] Intel GPU investigation</p> </li> <li>Check JAX Intel plugin status</li> <li>Investigate oneMKL sparse solver support</li> </ul>"},{"location":"sparse_solver_roadmap/#backend-detection-strategy","title":"Backend Detection Strategy","text":"<p>Current auto-detection in <code>runner.py</code>: <pre><code>if jax.default_backend() == 'gpu':\n    try:\n        from spineax.cudss.solver import CuDSSSolver\n        use_spineax = True  # NVIDIA GPU with Spineax\n    except ImportError:\n        use_spineax = False  # Non-NVIDIA GPU, fall back to spsolve\nelif jax.default_backend() == 'tpu':\n    # TODO: Use GMRES or dense\n    pass\nelse:\n    # CPU: dense solver is fast enough\n    pass\n</code></pre></p> <p>Need to extend this to: 1. Detect NVIDIA vs AMD vs Intel GPU 2. Select appropriate solver for each 3. Fall back gracefully when optimal solver unavailable</p>"},{"location":"sparse_solver_roadmap/#references","title":"References","text":""},{"location":"sparse_solver_roadmap/#jax-sparse","title":"JAX Sparse","text":"<ul> <li>jax.experimental.sparse docs</li> <li>JAX Issue #6544 - Sparse matrices (CLOSED)</li> <li>JAX Issue #11376 - scipy.sparse.linalg (OPEN)</li> <li>JAX PR #6555 - MLIR/TACO sparse (CLOSED - stale)</li> </ul>"},{"location":"sparse_solver_roadmap/#mlir-sparse","title":"MLIR Sparse","text":"<ul> <li>MLIR Sparse Tensor Dialect</li> <li>MLIR Sparsifier Guide</li> <li>Compiler Support Paper</li> </ul>"},{"location":"sparse_solver_roadmap/#gpu-sparse-solvers","title":"GPU Sparse Solvers","text":"<ul> <li>NVIDIA cuDSS</li> <li>Spineax</li> <li>cuSOLVER Sparse</li> </ul>"},{"location":"sparse_solver_roadmap/#iterative-solvers","title":"Iterative Solvers","text":"<ul> <li>JAX GMRES</li> <li>Lineax</li> </ul>"},{"location":"supported_devices/","title":"Supported Devices","text":"<p>VAJAX supports device models compiled from Verilog-A via OpenVAF, plus built-in voltage and current sources.</p>"},{"location":"supported_devices/#core-devices-tested-in-vacask-suite","title":"Core Devices (Tested in VACASK Suite)","text":"<p>These devices are validated against VACASK and ngspice reference results:</p> Device OSDI Module Verilog-A Source Benchmarks Resistor <code>sp_resistor</code> <code>devices/resistor.va</code> rc Capacitor <code>sp_capacitor</code> <code>devices/capacitor.va</code> rc Diode <code>diode</code> <code>devices/diode.va</code> graetz, mul PSP103 MOSFET <code>psp103va</code> <code>PSP103/psp103.va</code> ring, c6288"},{"location":"supported_devices/#additional-verilog-a-models","title":"Additional Verilog-A Models","text":"<p>These models are available in <code>vendor/VACASK/devices/</code> but have less test coverage:</p> Device OSDI Module Verilog-A Source Status BSIM3v3 <code>bsim3v3</code> <code>devices/bsim3v3.va</code> Compiles, needs integration tests BSIM4v8 <code>bsim4v8</code> <code>devices/bsim4v8.va</code> Compiles, needs integration tests BSIM-BULK 106 <code>bsimbulk106</code> <code>devices/bsimbulk106.va</code> Compiles, needs integration tests Inductor <code>inductor</code> <code>devices/inductor.va</code> Compiles, needs integration tests Op-Amp <code>opamp</code> <code>devices/opamp.va</code> Compiles, needs integration tests VBIC BJT <code>vbic</code> <code>devices/vbic.va</code> Compiles, needs integration tests"},{"location":"supported_devices/#built-in-sources","title":"Built-in Sources","text":"<p>Voltage and current sources are implemented directly in Python (<code>vajax/devices/vsource.py</code>), not via Verilog-A:</p> Source Type Parameters DC Voltage/Current <code>dc</code> (value) Pulse Voltage/Current <code>val0</code>, <code>val1</code>, <code>delay</code>, <code>rise</code>, <code>fall</code>, <code>width</code>, <code>period</code> Sine Voltage/Current <code>offset</code>, <code>amplitude</code>, <code>frequency</code>, <code>delay</code>, <code>damping</code> PWL Voltage/Current Time-value pairs"},{"location":"supported_devices/#source-example","title":"Source Example","text":"<pre><code>// DC source\nvdd (vdd 0) vsource dc=1.8\n\n// Pulse source\nvin (in 0) vsource dc=0 type=\"pulse\" val0=0 val1=1.8 rise=100p fall=100p width=5n period=10n\n\n// Sine source\nvsin (sig 0) vsource dc=0 type=\"sin\" offset=0.9 amplitude=0.1 frequency=1e6\n\n// Current source\nibias (vdd out) isource dc=100u\n</code></pre>"},{"location":"supported_devices/#spice-model-type-mapping","title":"SPICE Model Type Mapping","text":"<p>When converting from SPICE netlists, VAJAX maps model types to OSDI modules via <code>vajax/netlist_converter/spiceparser/elements.py</code>:</p>"},{"location":"supported_devices/#passive-devices","title":"Passive Devices","text":"SPICE Type Family OSDI Module <code>r</code>, <code>res</code> <code>r</code> <code>spice/resistor.osdi</code> <code>c</code> <code>c</code> <code>spice/capacitor.osdi</code> <code>l</code> <code>l</code> <code>spice/inductor.osdi</code>"},{"location":"supported_devices/#diodes","title":"Diodes","text":"SPICE Type Family Level OSDI Module <code>d</code> <code>d</code> 1, 3 <code>spice/diode.osdi</code>"},{"location":"supported_devices/#bjts","title":"BJTs","text":"SPICE Type Family Level OSDI Module <code>npn</code>, <code>pnp</code> <code>bjt</code> 1 (default) <code>spice/bjt.osdi</code> (Gummel-Poon) <code>npn</code>, <code>pnp</code> <code>bjt</code> 4, 9 <code>spice/vbic.osdi</code> (VBIC)"},{"location":"supported_devices/#mosfets","title":"MOSFETs","text":"SPICE Type Family Level OSDI Module <code>nmos</code>, <code>pmos</code> <code>mos</code> 1 <code>spice/mos1.osdi</code> <code>nmos</code>, <code>pmos</code> <code>mos</code> 2 <code>spice/mos2.osdi</code> <code>nmos</code>, <code>pmos</code> <code>mos</code> 3 <code>spice/mos3.osdi</code> <code>nmos</code>, <code>pmos</code> <code>mos</code> 8, 49 <code>spice/bsim3v3.osdi</code> (BSIM3) <code>nmos</code>, <code>pmos</code> <code>mos</code> 14, 54 <code>spice/bsim4.osdi</code> (BSIM4)"},{"location":"supported_devices/#other-devices","title":"Other Devices","text":"SPICE Type Family OSDI Module <code>njf</code>, <code>pjf</code> <code>jfet</code> <code>spice/jfet1.osdi</code> <code>nmf</code>, <code>pmf</code> <code>mes</code> <code>spice/mes1.osdi</code>"},{"location":"supported_devices/#adding-a-new-device","title":"Adding a New Device","text":"<p>All devices (except sources) are compiled from Verilog-A via OpenVAF. To add a new device:</p> <ol> <li>Obtain or write a Verilog-A model (<code>.va</code> file)</li> <li>Compile it with OpenVAF to produce an <code>.osdi</code> module</li> <li>Reference it in a VACASK <code>.sim</code> netlist with <code>load \"your_model.osdi\"</code></li> <li>The engine will automatically wrap it via <code>VerilogADevice</code> with batched <code>jax.vmap</code> evaluation</li> </ol> <p>No Python device code is needed. See CONTRIBUTING.md for details.</p>"},{"location":"transient_options/","title":"Transient Analysis Options","text":"<p>VAJAX supports VACASK-compatible options for controlling transient analysis behavior. Options can be specified in the netlist and are automatically used as defaults.</p>"},{"location":"transient_options/#simplest-usage","title":"Simplest Usage","text":"<pre><code>from vajax import CircuitEngine\nfrom vajax.analysis.transient import FullMNAStrategy\n\nengine = CircuitEngine('circuit.sim')\nengine.parse()\n\nstrategy = FullMNAStrategy(engine)\n\n# Run with all defaults from netlist - no args needed!\ntimes, V, stats = strategy.run()\n</code></pre> <p>The <code>run()</code> method uses: - <code>stop</code> from netlist analysis line as <code>t_stop</code> - <code>step</code> from netlist analysis line as <code>dt</code> - <code>tran_lteratio</code>, <code>nr_convtol</code>, etc. from netlist options</p>"},{"location":"transient_options/#quick-start","title":"Quick Start","text":"<p>Options in netlist are automatically used:</p> <pre><code>// In your .sim file\noptions tran_lteratio=1.5 nr_convtol=1.0 reltol=1e-4\nanalysis top tran step=1p stop=10n\n</code></pre> <pre><code>from vajax import CircuitEngine\nfrom vajax.analysis.transient import FullMNAStrategy\n\nengine = CircuitEngine('circuit.sim')\nengine.parse()\n\n# Strategy automatically uses netlist options\nstrategy = FullMNAStrategy(engine, use_sparse=True)\n# strategy.config.lte_ratio == 1.5  (from tran_lteratio)\n</code></pre>"},{"location":"transient_options/#supported-options","title":"Supported Options","text":""},{"location":"transient_options/#lte-local-truncation-error-control","title":"LTE (Local Truncation Error) Control","text":"Netlist Option AdaptiveConfig Default Description <code>tran_lteratio</code> <code>lte_ratio</code> 3.5 LTE tolerance multiplier. Higher values allow larger LTE before reducing timestep. <code>tran_redofactor</code> <code>redo_factor</code> 2.5 Rejection threshold. If <code>current_dt / new_dt &gt; redo_factor</code>, the step is rejected and retried."},{"location":"transient_options/#tolerances","title":"Tolerances","text":"Netlist Option AdaptiveConfig Default Description <code>reltol</code> <code>reltol</code> 1e-3 Relative tolerance for LTE and NR convergence. <code>abstol</code> <code>abstol</code> 1e-12 Absolute tolerance (current) for LTE and NR convergence. <code>nr_convtol</code> <code>nr_convtol</code> 1.0 NR convergence tolerance factor (multiplier on abstol). Values &lt; 1.0 are stricter."},{"location":"transient_options/#timestep-control","title":"Timestep Control","text":"Netlist Option AdaptiveConfig Default Description <code>tran_method</code> <code>integration_method</code> <code>trap</code> Integration method: <code>be</code> (backward Euler), <code>trap</code> (trapezoidal), <code>gear2</code> (Gear order 2). <code>tran_fs</code> <code>tran_fs</code> 0.25 Initial timestep scale factor. Scales user-specified <code>step</code> to start smaller. <code>tran_minpts</code> <code>tran_minpts</code> 50 Minimum output points. Automatically caps <code>max_dt</code> to <code>t_stop / tran_minpts</code>. <code>maxstep</code> <code>max_dt</code> inf Maximum allowed timestep (from tran analysis line)."},{"location":"transient_options/#convergence-aids","title":"Convergence Aids","text":"Netlist Option AdaptiveConfig Default Description <code>tran_gshunt</code> <code>gshunt_init</code> 0.0 Initial conductance to ground for all nodes. Helps with singular matrices in UIC mode. - <code>gshunt_steps</code> 5 Steps to ramp gshunt from <code>gshunt_init</code> to <code>gshunt_target</code>. - <code>gshunt_target</code> 0.0 Final gshunt value after ramping."},{"location":"transient_options/#debug-options","title":"Debug Options","text":"AdaptiveConfig Default Description <code>debug_steps</code> False Print per-step info (time, dt, NR iterations, LTE). <code>debug_lte</code> False Print detailed LTE debug info (top contributing nodes). <code>progress_interval</code> 100 Report progress every N steps. Set to 0 to disable."},{"location":"transient_options/#internal-parameters","title":"Internal Parameters","text":"AdaptiveConfig Default Description <code>min_dt</code> 1e-18 Minimum allowed timestep (seconds). <code>max_order</code> 2 Maximum polynomial order for predictor (0=constant, 1=linear, 2=quadratic). <code>grow_factor</code> 2.0 Maximum factor by which timestep can grow per step. <code>warmup_steps</code> 2 Fixed-dt steps before enabling LTE control (need history for predictor). <code>max_consecutive_rejects</code> 5 Force accept after this many consecutive LTE rejects."},{"location":"transient_options/#default-behavior","title":"Default Behavior","text":"<p>When no explicit <code>AdaptiveConfig</code> is passed to <code>FullMNAStrategy</code>:</p> <ol> <li>Netlist options are parsed during <code>engine.parse()</code> and stored in <code>engine.analysis_params</code></li> <li>Strategy builds config from <code>analysis_params</code> automatically</li> <li>Defaults apply for any options not specified in the netlist</li> </ol> <p>Example with defaults: <pre><code># No options in netlist - uses all defaults\nstrategy = FullMNAStrategy(engine)\n# lte_ratio=3.5, redo_factor=2.5, reltol=1e-3, etc.\n</code></pre></p>"},{"location":"transient_options/#programmatic-override","title":"Programmatic Override","text":"<p>Explicit <code>AdaptiveConfig</code> completely overrides netlist options:</p> <pre><code>from vajax.analysis.transient import AdaptiveConfig, FullMNAStrategy\n\n# Override specific options\nconfig = AdaptiveConfig(\n    lte_ratio=2.0,      # Stricter than default 3.5\n    tran_fs=0.1,        # Even smaller initial timesteps\n    debug_steps=True,   # Enable per-step debugging\n)\nstrategy = FullMNAStrategy(engine, config=config)\n</code></pre>"},{"location":"transient_options/#vacask-compatibility","title":"VACASK Compatibility","text":""},{"location":"transient_options/#supported-functional","title":"Supported (Functional)","text":"VACASK Option Status Notes <code>tran_lteratio</code> \u2705 Full Maps to <code>lte_ratio</code> <code>tran_redofactor</code> \u2705 Full Maps to <code>redo_factor</code> <code>tran_method</code> \u2705 Full Supports be, trap, gear2 <code>tran_fs</code> \u2705 Full Initial timestep scaling <code>tran_minpts</code> \u2705 Full Auto-computes max_dt <code>reltol</code> \u2705 Full Relative tolerance <code>abstol</code> \u2705 Full Absolute tolerance <code>nr_convtol</code> \u2705 Full NR tolerance factor"},{"location":"transient_options/#not-yet-implemented","title":"Not Yet Implemented","text":"VACASK Option Status Notes <code>nr_bypass</code> \u274c Device bypass for unchanged nodes <code>nr_bypasstol</code> \u274c Bypass tolerance threshold <code>nr_contbypass</code> \u274c Bypass in continuation mode <code>tran_predictor</code> \u274c We always use predictor <code>tran_maxord</code> Partial Fixed at order 2 <code>tran_itl</code> \u274c Max NR iterations per step <code>tran_ft</code> \u274c Timestep cut factor on NR failure <code>tran_xmu</code> \u274c Trap/Euler mixture parameter"},{"location":"transient_options/#example-c6288-benchmark","title":"Example: C6288 Benchmark","text":"<p>The c6288 multiplier benchmark uses these options:</p> <pre><code>options nr_convtol=1 tran_lteratio=1.5\nanalysis top tran step=2p stop=2n icmode=\"uic\"\n</code></pre> <p>This sets: - <code>nr_convtol=1.0</code> - Standard NR tolerance - <code>tran_lteratio=1.5</code> - Tighter LTE control than default (3.5) - <code>icmode=\"uic\"</code> - Use Initial Conditions (skip DC operating point)</p> <pre><code>engine = CircuitEngine('c6288.sim')\nengine.parse()\n\n# These options are automatically applied\nstrategy = FullMNAStrategy(engine, use_sparse=True)\nassert strategy.config.lte_ratio == 1.5\nassert strategy.config.nr_convtol == 1.0\n</code></pre>"},{"location":"vacask_osdi_inputs/","title":"VACASK OSDI Model Input Handling","text":"<p>This document describes how VACASK interfaces with OSDI compiled models (.so/.dylib files) generated by OpenVAF.</p>"},{"location":"vacask_osdi_inputs/#overview","title":"Overview","text":"<p>VACASK loads OSDI shared libraries at runtime and interfaces with them through the OSDI API. This is fundamentally different from <code>openvaf_jax</code> which generates JAX functions - VACASK uses the native compiled code directly.</p>"},{"location":"vacask_osdi_inputs/#1-osdi-library-loading","title":"1. OSDI Library Loading","text":"<p>Files: <code>VACASK/lib/dynload.cpp</code>, <code>VACASK/lib/osdifile.cpp</code></p> <pre><code>OsdiFile::open()\n  \u2514\u2500&gt; openDynamicLibrary(filename)\n      \u251c\u2500&gt; dlopen(filename, RTLD_NOW) [Linux/macOS]\n      \u2514\u2500&gt; LoadLibrary(filename) [Windows]\n</code></pre> <p>Symbols Retrieved from Library: - <code>OSDI_DESCRIPTORS</code> - Array of device descriptors - <code>OSDI_NUM_DESCRIPTORS</code> - Number of devices - <code>OSDI_VERSION_MAJOR/MINOR</code> - API version - <code>OSDI_LIM_TABLE</code> - Limit function table - <code>osdi_log</code> - Logging callback</p>"},{"location":"vacask_osdi_inputs/#2-model-and-instance-parameters","title":"2. Model and Instance Parameters","text":"<p>Parameter Access Architecture:</p> <p>Parameters are accessed through a callback function pointer in the descriptor: <pre><code>void *(*access)(void *inst, void *model, uint32_t id, uint32_t flags)\n</code></pre></p> <p>Parameter Types: - Model Parameters: Shared across all instances (e.g., process corners) - Instance Parameters: Per-device (e.g., W, L) - Output Variables (OpVars): Read-only computed values</p> <p>Access Flags: - <code>ACCESS_FLAG_READ</code> (0) - Read parameter - <code>ACCESS_FLAG_SET</code> (1) - Set parameter - <code>ACCESS_FLAG_INSTANCE</code> (4) - Instance vs model parameter</p> <p>Parameter Storage: - Model data: allocated at <code>descriptor-&gt;model_size</code> bytes - Instance data: allocated at <code>descriptor-&gt;instance_size</code> bytes - Parameters stored at offsets within these structures</p>"},{"location":"vacask_osdi_inputs/#3-voltage-provision-to-models","title":"3. Voltage Provision to Models","text":"<p>Key Insight: Voltages are NOT passed as function arguments. Instead:</p> <ol> <li> <p>Node Mapping Setup: <pre><code>auto nodeMapping = nodeMappingArray();  // at descriptor-&gt;node_mapping_offset\nnodeMapping[i] = nodes_[i]-&gt;unknownIndex();  // circuit matrix index\n</code></pre></p> </li> <li> <p>Solution Vector Passed via OsdiSimInfo: <pre><code>simInfo.prev_solve = evalSetup-&gt;oldSolution;  // entire circuit solution\n</code></pre></p> </li> <li> <p>Model Reads Voltages Internally: <pre><code>// Inside OSDI model (generated by OpenVAF)\nvoltage_at_node_i = prev_solve[nodeMapping[i]];\n</code></pre></p> </li> </ol>"},{"location":"vacask_osdi_inputs/#4-the-eval-function","title":"4. The Eval Function","text":"<p>Signature: <pre><code>uint32_t (*eval)(void *handle, void *inst, void *model, OsdiSimInfo *info)\n</code></pre></p> <p>Called From: <code>OsdiInstance::evalCore()</code> in osdiinstance.cpp</p> <pre><code>auto evalFlags = descr-&gt;eval(&amp;handle, core(), model_-&gt;core(), &amp;simInfo);\n</code></pre> <p>OsdiSimInfo Structure: <pre><code>typedef struct OsdiSimInfo {\n    OsdiSimParas paras;      // gmin, tnom, scale, iteration, etc.\n    double abstime;          // Current simulation time\n    double *prev_solve;      // Circuit solution vector (node voltages!)\n    double *prev_state;      // Previous internal state\n    double *next_state;      // Next internal state\n    uint32_t flags;          // What to compute\n} OsdiSimInfo;\n</code></pre></p> <p>Calculation Flags: - <code>CALC_RESIST_RESIDUAL</code> - Compute resistive residual (f) - <code>CALC_REACT_RESIDUAL</code> - Compute reactive residual (q) - <code>CALC_RESIST_JACOBIAN</code> - Compute resistive Jacobian (df/dx) - <code>CALC_REACT_JACOBIAN</code> - Compute reactive Jacobian (dq/dx) - <code>ANALYSIS_DC</code> / <code>ANALYSIS_TRAN</code> / <code>ANALYSIS_AC</code> - <code>ENABLE_LIM</code> / <code>INIT_LIM</code> - Limiting control</p>"},{"location":"vacask_osdi_inputs/#5-jacobian-handling","title":"5. Jacobian Handling","text":"<p>Critical Design: Jacobians are NOT returned by eval(). Instead, matrix pointers are bound beforehand, and the model writes directly to them.</p> <p>Binding Phase (before iteration): <pre><code>// From bindCore()\nauto jacResistArray = resistiveJacobianPointers();  // at descriptor-&gt;jacobian_ptr_resist_offset\nfor(auto&amp; entry : jacobian_entries) {\n    jacResistArray[i] = matResist-&gt;valuePtr(row, col);  // Direct matrix pointer!\n}\n</code></pre></p> <p>During Eval: The OSDI model writes Jacobian values directly to the bound matrix pointers - no intermediate copies.</p> <p>Load Phase (after eval): <pre><code>descr-&gt;load_jacobian_resist(core(), model_-&gt;core());\ndescr-&gt;load_jacobian_react(core(), model_-&gt;core(), factor);\n</code></pre></p>"},{"location":"vacask_osdi_inputs/#6-residual-handling","title":"6. Residual Handling","text":"<p>Storage: Residuals are stored in the instance core structure at offsets: <pre><code>// OsdiNode structure\nuint32_t resist_residual_off;   // Offset to resistive residual\nuint32_t react_residual_off;    // Offset to reactive residual\n</code></pre></p> <p>Extraction: <pre><code>for(auto i : device-&gt;nonzeroResistiveResiduals()) {\n    auto resOff = descr-&gt;nodes[i].resist_residual_off;\n    auto contrib = *getDataPtr&lt;double*&gt;(core(), resOff);\n    // Load to matrix RHS\n}\n</code></pre></p>"},{"location":"vacask_osdi_inputs/#7-complete-evaluation-flow","title":"7. Complete Evaluation Flow","text":"<pre><code>1. SETUP PHASE:\n   Circuit::setup()\n     \u2514\u2500&gt; OsdiDevice::setup()\n         \u2514\u2500&gt; OsdiInstance::setup()\n             \u2514\u2500&gt; setup_instance(handle, core, model_core, temp)\n                 \u2514\u2500&gt; Allocate internal states\n\n2. BIND PHASE (once per matrix structure change):\n   OsdiInstance::bindCore()\n     \u2514\u2500&gt; Bind Jacobian pointers to matrix entries\n     \u2514\u2500&gt; Bind node mapping to circuit unknowns\n\n3. ITERATION LOOP (Newton-Raphson):\n   OsdiDevice::evalAndLoad()\n\n   a. Populate OsdiSimInfo:\n      \u251c\u2500&gt; simInfo.paras = {gmin, tnom, scale, iteration, ...}\n      \u251c\u2500&gt; simInfo.abstime = current_time\n      \u251c\u2500&gt; simInfo.prev_solve = circuit_solution_vector  // VOLTAGES HERE!\n      \u251c\u2500&gt; simInfo.prev_state = previous_internal_states\n      \u251c\u2500&gt; simInfo.next_state = next_internal_states\n      \u2514\u2500&gt; simInfo.flags = CALC_RESIST_RESIDUAL | CALC_RESIST_JACOBIAN | ...\n\n   b. For each instance:\n      eval(&amp;handle, instance_core, model_core, &amp;simInfo)\n        \u2514\u2500&gt; Model internally:\n            \u251c\u2500&gt; Reads voltages: V[i] = prev_solve[nodeMapping[i]]\n            \u251c\u2500&gt; Computes currents, charges\n            \u251c\u2500&gt; Writes residuals to instance_core offsets\n            \u251c\u2500&gt; Writes Jacobians DIRECTLY to matrix pointers\n            \u2514\u2500&gt; Updates internal states\n\n   c. For each instance:\n      loadCore()\n        \u251c\u2500&gt; load_residual_resist() \u2192 to matrix RHS\n        \u251c\u2500&gt; load_residual_react() \u2192 to matrix RHS\n        \u2514\u2500&gt; Jacobians already written by eval!\n\n4. SOLVE and repeat until converged\n</code></pre>"},{"location":"vacask_osdi_inputs/#8-key-differences-from-openvaf_jax","title":"8. Key Differences from openvaf_jax","text":"Aspect VACASK + OSDI openvaf_jax Code type Native compiled (.so) JAX Python functions Voltage input Via prev_solve array + node mapping Direct function arguments Jacobian output Direct write to matrix pointers Returned as dictionary Residual output Read from instance core offsets Returned as dictionary Autodiff Not used - analytical Jacobians Can use JAX autodiff GPU support CPU only JAX GPU acceleration"},{"location":"vacask_osdi_inputs/#9-implications-for-gpu-solver","title":"9. Implications for GPU Solver","text":"<p>The GPU solver currently uses JAX autodiff for Jacobians, but this misses:</p> <ol> <li>Minimum Conductances: OSDI models enforce <code>gds &gt;= GDSMIN</code>, autodiff doesn't</li> <li>Limiting Functions: <code>$limit()</code> in Verilog-A handled by OSDI, not autodiff</li> <li>Analytical Derivatives: OpenVAF computes symbolic derivatives with numerical stability</li> </ol> <p>Solution: Use <code>openvaf_jax</code> to get the same analytical Jacobians that OSDI models provide, rather than relying on autodiff.</p>"},{"location":"vacask_osdi_inputs/#10-file-references","title":"10. File References","text":"Purpose VACASK File Library loading <code>lib/dynload.cpp</code>, <code>lib/osdifile.cpp</code> Instance evaluation <code>lib/osdiinstance.cpp</code> Device management <code>lib/osdidevice.cpp</code> OSDI API definitions <code>include/osdi.h</code> Parameter access <code>lib/osdimodel.cpp</code>"},{"location":"vacask_sim_format/","title":"VACASK .sim File Format","text":"<p>This document describes the VACASK simulation file format and how to adapt it for use with vajax using openvaf_jax models instead of OSDI.</p>"},{"location":"vacask_sim_format/#file-structure","title":"File Structure","text":"<p>VACASK .sim files are netlist files with a custom syntax defined in <code>lib/dflparser.y</code> (a Bison grammar). Key elements:</p>"},{"location":"vacask_sim_format/#1-load-statements","title":"1. Load Statements","text":"<pre><code>load \"psp103v4.osdi\"\nload \"spice/resistor.osdi\"\n</code></pre> <p>These load OSDI compiled libraries. For vajax, we need to: - Replace with openvaf_jax compilation of the corresponding .va files - Map the module name (e.g., <code>psp103va</code>) to the JAX function</p>"},{"location":"vacask_sim_format/#2-model-definitions","title":"2. Model Definitions","text":"<pre><code>model psp103n psp103va (\n    type=1\n    vfbo=-1.1\n    toxo=1.5e-9\n    ...\n)\n</code></pre> <ul> <li>First identifier: model name (user-defined)</li> <li>Second identifier: module name from OSDI library</li> <li>Parameters in parentheses: model parameters</li> </ul>"},{"location":"vacask_sim_format/#3-subcircuit-definitions","title":"3. Subcircuit Definitions","text":"<pre><code>subckt nmos (d g s b)\nparameters w=1u l=0.2u\n  m (d g s b) psp103n w=w l=l\nends\n\nsubckt and(out in1 in2)\n  mp1 (outx in1 vdd vdd) pmos w=1u l=0.2u\n  mn1 (outx in1 int vss) nmos w=0.5u l=0.2u\n  ...\nends\n</code></pre>"},{"location":"vacask_sim_format/#4-instance-statements","title":"4. Instance Statements","text":"<pre><code>v1 (1 0) vsource dc=1\nr1 (1 0) resistor r=2k\nm (d g s b) psp103n w=w l=l\n</code></pre> <p>Format: <code>name (nodes) model_name param=value ...</code></p>"},{"location":"vacask_sim_format/#5-control-block","title":"5. Control Block","text":"<pre><code>control\n  options nr_convtol=1\n  save v(p0) v(p1)\n  elaborate circuit(\"and_test\")\n  analysis tranand tran stop=0.8n step=10p\n  postprocess(PYTHON, \"runme.py\")\nendc\n</code></pre>"},{"location":"vacask_sim_format/#key-test-cases","title":"Key Test Cases","text":""},{"location":"vacask_sim_format/#simple-tests-vendorvacasktest","title":"Simple Tests (vendor/VACASK/test/)","text":"File Description Models Used <code>test_resistor.sim</code> Basic resistor resistor.osdi <code>test_diode.sim</code> Diode I-V sweep diode.osdi, resistor.osdi <code>test_capacitor.sim</code> Capacitor capacitor.osdi <code>test_op.sim</code> Operating point Various <code>test_inverter.sim</code> CMOS inverter MOSFET model"},{"location":"vacask_sim_format/#benchmark-tests-vendorvacaskbenchmark","title":"Benchmark Tests (vendor/VACASK/benchmark/)","text":"Directory Description Key Files <code>c6288/vacask/</code> 16x16 multiplier runme.sim, models.inc, multiplier.inc <code>ring/</code> Ring oscillator Various <code>graetz/</code> Graetz rectifier Various"},{"location":"vacask_sim_format/#c6288-and-gate-test","title":"C6288 AND Gate Test","text":"<p>The <code>and_test</code> subcircuit in <code>benchmark/c6288/vacask/runme.sim</code> is our target:</p> <pre><code>subckt and(out in1 in2)\n  mp2 (outx in2 vdd vdd) pmos w=1u l=0.2u\n  mp1 (outx in1 vdd vdd) pmos w=1u l=0.2u\n  mn1 (outx in1 int vss) nmos w=0.5u l=0.2u  // &lt;-- Floating 'int' node!\n  mn2 (int  in2 vss vss) nmos w=0.5u l=0.2u\n  mp3 (out outx vdd vdd) pmos w=1u l=0.2u\n  mn3 (out outx vss vss) nmos w=0.5u l=0.2u\nends\n</code></pre> <p>The <code>int</code> node between mn1 and mn2 is the floating node that causes convergence issues with autodiff Jacobians.</p>"},{"location":"vacask_sim_format/#adapting-for-vajax","title":"Adapting for vajax","text":""},{"location":"vacask_sim_format/#step-1-parse-the-sim-file","title":"Step 1: Parse the .sim file","text":"<p>Key elements to extract: 1. <code>load</code> statements \u2192 Compile .va files with openvaf_jax 2. <code>model</code> statements \u2192 Create model parameter dictionaries 3. <code>subckt</code> definitions \u2192 Build subcircuit templates 4. Instance statements \u2192 Create circuit instances 5. <code>elaborate</code> \u2192 Build the flattened circuit 6. <code>analysis</code> \u2192 Run DC/transient analysis</p>"},{"location":"vacask_sim_format/#step-2-replace-osdi-with-openvaf_jax","title":"Step 2: Replace OSDI with openvaf_jax","text":"<p>Instead of: <pre><code># VACASK: Load OSDI library\nosdi_lib = load_osdi(\"psp103v4.osdi\")\n</code></pre></p> <p>Use: <pre><code># vajax: Compile to JAX\nimport openvaf_py\nimport openvaf_jax\n\nmodules = openvaf_py.compile_va(\"psp103v4.va\")\ntranslator = openvaf_jax.OpenVAFToJAX(modules[0])\npsp103_eval = translator.translate()\n</code></pre></p>"},{"location":"vacask_sim_format/#step-3-map-model-names-to-jax-functions","title":"Step 3: Map model names to JAX functions","text":"<pre><code>model_registry = {\n    'psp103va': psp103_eval,\n    'resistor': resistor_eval,\n    'diode': diode_eval,\n}\n</code></pre>"},{"location":"vacask_sim_format/#step-4-build-circuit-with-analytical-jacobians","title":"Step 4: Build circuit with analytical Jacobians","text":"<p>Use the JAX functions' returned Jacobians instead of autodiff:</p> <pre><code>def evaluate_device(model_fn, voltages, params):\n    inputs = build_inputs(voltages, params)\n    residuals, jacobian = model_fn(inputs)  # Analytical Jacobian!\n    return residuals, jacobian\n</code></pre>"},{"location":"vacask_sim_format/#vajax-parser-compatibility","title":"vajax Parser Compatibility","text":"<p>The existing vajax parser (<code>vajax/netlist/parser.py</code>) is a Python recursive descent parser that handles the core VACASK netlist format. It successfully parses 40 out of 46 VACASK-format test files (87%).</p>"},{"location":"vacask_sim_format/#supported-features","title":"Supported Features","text":"<ul> <li><code>load</code> statements</li> <li><code>include</code> statements (with recursive file loading)</li> <li><code>ground</code> and <code>global</code> declarations</li> <li><code>model</code> definitions with parameters</li> <li><code>subckt</code>/<code>ends</code> definitions</li> <li>Instance statements with terminals and parameters</li> <li><code>control</code>/<code>endc</code> blocks (skipped, not parsed)</li> <li><code>embed</code> blocks (skipped)</li> <li>Multi-line parameter lists in parentheses</li> <li>Comments (<code>//</code>)</li> </ul>"},{"location":"vacask_sim_format/#known-limitations","title":"Known Limitations","text":"<p>The following VACASK features are not yet supported:</p> <ol> <li>Titles with parentheses - A title like \"SPICE JFET (verilog-A)\" confuses the parser</li> <li>Conditional blocks (<code>@if/@endif</code>) - Used in <code>test_cblock.sim</code>, <code>test_cblocksweep.sim</code></li> <li>Vector parameters (<code>vec=[...]</code>) - Used in <code>test_sweepvec.sim</code></li> <li>Control block content - Currently skipped; analysis commands not extracted</li> </ol>"},{"location":"vacask_sim_format/#working-test-cases","title":"Working Test Cases","text":"<p>All key test cases parse successfully: - <code>test_resistor.sim</code> - Basic resistor - <code>test_diode.sim</code> - Diode I-V sweep - <code>test_capacitor.sim</code> - Capacitor - <code>test_inverter.sim</code> - CMOS inverter - <code>benchmark/c6288/vacask/runme.sim</code> - 16x16 multiplier (includes models.inc, multiplier.inc) - <code>benchmark/ring/vacask/runme.sim</code> - Ring oscillator - <code>benchmark/mul/vacask/runme.sim</code> - Multiplier benchmark</p>"},{"location":"vacask_sim_format/#vacask-bison-grammar-reference","title":"VACASK Bison Grammar Reference","text":"<p>The full VACASK parser (<code>lib/dflparser.y</code>) uses: - Bison 3.3+ with C++ skeleton - Custom scanner (<code>lib/dflscanner.l</code>) - Token types: IDENTIFIER, INTEGER, FLOAT, STRING - Expression evaluation via RPN (Reverse Polish Notation)</p> <p>Key grammar rules: - <code>load</code>: <code>LOAD STRING NEWLINE</code> - <code>model_def</code>: <code>MODEL IDENTIFIER IDENTIFIER opt_parameter_list NEWLINE</code> - <code>subcircuit_def</code>: <code>SUBCKT IDENTIFIER terminal_def ... ENDS</code> - <code>instance</code>: <code>IDENTIFIER terminal_def IDENTIFIER opt_parameter_list NEWLINE</code></p>"},{"location":"vacask_sim_format/#file-locations","title":"File Locations","text":"Purpose Path Parser grammar <code>vendor/VACASK/lib/dflparser.y</code> Scanner <code>vendor/VACASK/lib/dflscanner.l</code> Test cases <code>vendor/VACASK/test/*.sim</code> Benchmarks <code>vendor/VACASK/benchmark/*/vacask/runme.sim</code> PSP103 model <code>vendor/VACASK/benchmark/c6288/vacask/models.inc</code> Gate definitions <code>vendor/VACASK/benchmark/c6288/vacask/multiplier.inc</code>"},{"location":"verilog_a_system_functions/","title":"Verilog-A System Functions Analysis","text":"<p>Analysis of <code>$</code> system functions used in OpenVAF and VACASK <code>.va</code> files, and how they are handled in the JAX and OSDI paths.</p> <p>Reference: This document summarizes system functions per the Verilog-AMS Language Reference Manual (VAMS-LRM-2023), Section 9.</p>"},{"location":"verilog_a_system_functions/#summary-statistics","title":"Summary Statistics","text":"<p>From 135 <code>.va</code> files analyzed:</p> Function Count Category Description <code>$param_given</code> 1891 Device Check if param was explicitly set <code>$strobe</code> 1434 Debug Print at end of timestep <code>$simparam</code> 481 Simulation Simulator parameters <code>$temperature</code> 274 Simulation Device temperature in K <code>$limit</code> 270 Device Limiting function for convergence <code>$write</code> 251 Debug Print immediately <code>$warning</code> 212 Debug Issue warning message <code>$mfactor</code> 191 Simulation Device multiplier <code>$finish</code> 92 Debug End simulation <code>$fatal</code> 64 Debug Fatal error, stop simulation <code>$port_connected</code> 57 Device Check if port is connected <code>$discontinuity</code> 42 Device Notify simulator of discontinuity <code>$vt</code> 28 Simulation Thermal voltage kT/q <code>$display</code> 11 Debug Print with newline <code>$abstime</code> 5 Simulation Absolute simulation time"},{"location":"verilog_a_system_functions/#simulation-critical-functions","title":"Simulation-Critical Functions","text":"<p>These must be handled correctly for accurate simulation results.</p>"},{"location":"verilog_a_system_functions/#temperature-274-uses","title":"<code>$temperature</code> (274 uses)","text":"<p>Returns the circuit ambient temperature in Kelvin (LRM 9.15).</p> <p>LRM Definition: <code>$temperature</code> returns the ambient temperature as a real value in Kelvin.</p> Path Handling JAX Param with <code>kind='temperature'</code> \u2192 uses <code>temperature</code> argument from <code>translate_init()</code>/<code>translate_eval()</code> OSDI <code>OsdiSimInfo.temperature</code> field"},{"location":"verilog_a_system_functions/#simparam-481-uses","title":"<code>$simparam</code> (481 uses)","text":"<p>Queries simulator parameters (LRM 9.15). Usage pattern: <code>$simparam(\"name\", default)</code></p> <p>LRM Definition: <code>$simparam()</code> queries the simulator for a real-valued simulation parameter named <code>param_name</code>. If <code>param_name</code> is not known and no default is supplied, an error is generated.</p>"},{"location":"verilog_a_system_functions/#standard-parameters-lrm-table-9-27","title":"Standard Parameters (LRM Table 9-27)","text":"Parameter Units LRM Description <code>gdev</code> 1/Ohms Additional conductance for conductance homotopy convergence <code>gmin</code> 1/Ohms Minimum conductance placed in parallel with nonlinear branches <code>imax</code> Amps Branch current threshold above which constitutive relation should be linearized <code>imelt</code> Amps Branch current threshold indicating device failure <code>iteration</code> - Iteration number of the analog solver <code>scale</code> - Scale factor for device instance geometry parameters <code>shrink</code> - Optical linear shrink factor <code>simulatorSubversion</code> - The simulator sub-version <code>simulatorVersion</code> - The simulator version <code>sourceScaleFactor</code> - Multiplicative factor for independent sources (source stepping homotopy) <code>tnom</code> Celsius Default temperature at which model parameters were extracted <code>timeUnit</code> s Time unit as specified in 'timescale <code>timePrecision</code> s Time precision as specified in 'timescale"},{"location":"verilog_a_system_functions/#usage-in-vendored-models","title":"Usage in Vendored Models","text":"Parameter Default Count Notes <code>gmin</code> 1e-12 88 Standard LRM parameter <code>tnom</code> 27 74 Standard LRM parameter <code>scale</code> 1 41 Standard LRM parameter <code>iteration</code> 10 36 Standard LRM parameter <code>iniLim</code> -1 36 Non-standard (SPICE-specific) <code>oldlimit</code> 0 34 Non-standard (SPICE-specific) <code>defl</code> 1e-4 30 Non-standard (SPICE default L) <code>defw</code> 1e-4 30 Non-standard (SPICE default W) <code>defas</code> 0 30 Non-standard (SPICE default AS) <code>defad</code> 0 30 Non-standard (SPICE default AD) <code>reltol</code> 1e-3 10 Non-standard (SPICE tolerance) <code>epsmin</code> 1e-28 10 Non-standard <code>abstol</code> 1e-12 6 Non-standard (SPICE tolerance) <code>vntol</code> 1e-6 6 Non-standard (SPICE voltage tolerance) Path Handling JAX Only <code>gmin</code> handled \u2192 <code>inputs[-1]</code>. Others return 0.0 or default. OSDI <code>OsdiSimParas</code> struct with <code>names[]</code> and <code>vals[]</code> arrays <p>Gap: JAX only handles <code>gmin</code>. Models using <code>scale</code>, <code>tnom</code>, or iteration-dependent behavior may differ.</p>"},{"location":"verilog_a_system_functions/#mfactor-191-uses","title":"<code>$mfactor</code> (191 uses)","text":"<p>Shunt multiplicity factor (LRM 9.18).</p> <p>LRM Definition: <code>$mfactor</code> is the shunt multiplicity factor of the instance, that is, the number of identical devices that should be combined in parallel and modeled. The value is computed by multiplying values from the top of the hierarchy down to the instance.</p> <p>Hierarchy Combination: <code>$mfactor = $mfactor_specified * $mfactor_hier</code></p> <p>Top-level value: 1.0</p> Path Handling JAX Param with <code>kind='sysfun'</code> \u2192 uses <code>mfactor</code> argument (default 1.0) OSDI Instance parameter in OSDI descriptor"},{"location":"verilog_a_system_functions/#vt-28-uses","title":"<code>$vt</code> (28 uses)","text":"<p>Thermal voltage kT/q (LRM 9.15).</p> <p>LRM Definition: <code>$vt</code> can optionally have temperature (in Kelvin units) as an input argument and returns the thermal voltage (kT/q) at the given temperature. <code>$vt</code> without the optional input temperature argument returns the thermal voltage using <code>$temperature</code>.</p> <p>Formula: <code>$vt(T) = k * T / q</code> where k = Boltzmann constant, q = electron charge</p> <p>Usage patterns found: - <code>$vt</code> or <code>$vt()</code> - 21 uses - thermal voltage at simulation temperature - <code>$vt($temperature)</code> - 4 uses - explicit simulation temperature - <code>$vt(Tnom)</code> - 1 use - thermal voltage at nominal temperature - <code>$vt(DevTemp)</code> - 1 use - thermal voltage at device temperature</p> Path Handling JAX Computed inline as <code>k * T / q</code> where T comes from temperature param OSDI Computed inline"},{"location":"verilog_a_system_functions/#abstime-5-uses","title":"<code>$abstime</code> (5 uses)","text":"<p>Absolute simulation time (LRM Table 9-7). Only relevant for transient analysis.</p> <p>LRM Definition: <code>$abstime</code> returns the absolute time as a real number in seconds. The absolute time at the beginning of a simulation is typically zero.</p> Path Handling JAX Param with <code>kind='abstime'</code> \u2192 defaults to 0.0. For transient, caller updates the input. OSDI <code>OsdiSimInfo.abstime</code> field <p>Note: For DC analysis, <code>abstime=0.0</code> is correct. For transient analysis, the simulator must provide the current time value.</p>"},{"location":"verilog_a_system_functions/#device-behavior-functions","title":"Device Behavior Functions","text":""},{"location":"verilog_a_system_functions/#param_given-1891-uses","title":"<code>$param_given</code> (1891 uses)","text":"<p>Checks if a parameter was explicitly provided vs using default (LRM 9.19).</p> <p>LRM Definition: The <code>$param_given()</code> function can be used to determine whether a parameter value was obtained from the default value in its declaration statement or if that value was overridden. The return value shall be one (1) if the parameter was overridden, either by a <code>defparam</code> statement or by a module instance parameter value assignment, and zero (0) otherwise.</p> <p>Note: The return value is constant during simulation (fixed at elaboration). This allows use in genvar expressions controlling conditional/looping behavior of analog operators.</p> <pre><code>if ($param_given(VTH0)) begin\n    // Use provided VTH0\nend else begin\n    // Calculate VTH0 from other params\nend\n</code></pre> Path Handling JAX Param with <code>kind='param_given'</code> \u2192 1.0 if param in user dict, else 0.0 OSDI Tracked per-parameter in OSDI descriptor"},{"location":"verilog_a_system_functions/#limit-270-uses","title":"<code>$limit</code> (270 uses)","text":"<p>Convergence limiting functions (LRM 9.17.3).</p> <p>LRM Definition: The <code>$limit()</code> function is a special-purpose system function whose purpose, like that of <code>limexp()</code>, is to provide the simulator with help in managing convergence problems. <code>$limit()</code> has internal state containing information about the argument from iteration to iteration. It internally limits the change of the output from iteration to iteration in order to improve convergence.</p> <p>Built-in limiting algorithms: - <code>pnjlim</code> - Limiting arguments to exponentials (PN junction)   - Additional args: <code>vte</code> (step size), <code>vcrit</code> (critical voltage) - <code>fetlim</code> - Limiting potential across MOS oxide   - Additional arg: <code>vto</code> (threshold voltage) - User-defined functions can also be used</p> <p>Common patterns: - <code>$limit(V(g, ...), \"fetlim\", ...)</code> - 76 uses - <code>$limit(V(b, ...), \"pnjlim\", ...)</code> - 72 uses - <code>$limit(V(d_int, ...), ...)</code> - 40 uses</p> Path Handling JAX Translated to JAX limiting functions OSDI Native OSDI limiting support"},{"location":"verilog_a_system_functions/#port_connected-57-uses","title":"<code>$port_connected</code> (57 uses)","text":"<p>Checks if an optional port is connected (LRM 9.19).</p> <p>LRM Definition: The <code>$port_connected()</code> function can be used to determine whether a connection was specified for a port. The return value shall be one (1) if the port was connected to a net (by order or by name) when the module was instantiated, and zero (0) otherwise. Note that the port may be connected to a net that has no other connections, but <code>$port_connected()</code> shall still return one.</p> <p>Note: The return value is constant during simulation (fixed at elaboration).</p> <pre><code>if ($port_connected(bulk)) begin\n    // 4-terminal device\nend else begin\n    // 3-terminal device (bulk tied internally)\nend\n</code></pre> Path Handling JAX Assumed all ports connected (returns true) OSDI Proper port connection checking <p>Gap: Models with optional ports may behave differently.</p>"},{"location":"verilog_a_system_functions/#discontinuity-42-uses","title":"<code>$discontinuity</code> (42 uses)","text":"<p>Notifies simulator of a discontinuity for timestep control (LRM 9.17.1).</p> <p>LRM Definition: The <code>$discontinuity</code> task is used to give hints to the simulator about the behavior of the module so the simulator can control its simulation algorithms to properly handle the discontinuity. <code>$discontinuity(i)</code> implies a discontinuity in the i'th derivative of the constitutive equation. <code>$discontinuity(0)</code> indicates a discontinuity in the equation, <code>$discontinuity(1)</code> indicates a discontinuity in slope, etc.</p> <p>Special case: <code>$discontinuity(-1)</code> is used with the <code>$limit()</code> function.</p> <pre><code>$discontinuity(-1);  // Always notify (42 uses found)\n</code></pre> Path Handling JAX Ignored (DC analysis only currently) OSDI Passed to simulator for timestep control"},{"location":"verilog_a_system_functions/#debug-functions-ignored","title":"Debug Functions (Ignored)","text":"<p>These functions are for debugging/output and are safely ignored during simulation.</p> Function Count Purpose <code>$strobe</code> 1434 Print at end of timestep <code>$write</code> 251 Print immediately <code>$warning</code> 212 Issue warning message <code>$finish</code> 92 End simulation <code>$fatal</code> 64 Fatal error <code>$display</code> 11 Print with newline <code>$debug</code> 4 Debug output <code>$fopen</code> 2 Open file <code>$fdisplay</code> 2 Write to file"},{"location":"verilog_a_system_functions/#gap-analysis","title":"Gap Analysis","text":""},{"location":"verilog_a_system_functions/#currently-missing-in-jax-path","title":"Currently Missing in JAX Path","text":"<ol> <li><code>$simparam</code> parameters beyond <code>gmin</code></li> <li><code>tnom</code> - May affect temperature-dependent calculations</li> <li><code>scale</code> - Layout scaling (41 uses)</li> <li><code>iteration</code> - Iteration-dependent limiting (36 uses)</li> <li> <p>Tolerance values - May affect limiting behavior</p> </li> <li> <p><code>$port_connected</code> - Always returns true</p> </li> <li> <p>Risk: Models with optional ports (bulk, substrate) may behave differently</p> </li> <li> <p><code>$vt(T)</code> with explicit temperature</p> </li> <li>Need to verify correct handling of <code>$vt(Tnom)</code> vs <code>$vt($temperature)</code></li> </ol>"},{"location":"verilog_a_system_functions/#recommendations","title":"Recommendations","text":"<ol> <li>Add <code>tnom</code> simparam support - Used in 74 places for temperature normalization</li> <li>Add <code>scale</code> simparam support - Used in 41 places for geometry scaling</li> <li>Consider <code>$port_connected</code> - May explain differences in some models</li> <li>Verify <code>$vt</code> temperature handling - Ensure consistency with OSDI</li> </ol>"},{"location":"verilog_a_system_functions/#implementation-details","title":"Implementation Details","text":""},{"location":"verilog_a_system_functions/#jax-parameter-handling","title":"JAX Parameter Handling","text":"<p>Parameters are handled by <code>kind</code> in <code>_build_param_inputs()</code>:</p> Kind Handling <code>param</code> User-provided or OSDI default <code>voltage</code> Placeholder 0.0 (set at runtime) <code>temperature</code> Uses <code>temperature</code> argument <code>sysfun</code> (mfactor) Uses <code>mfactor</code> argument <code>param_given</code> 1.0 if param in user dict, else 0.0 <code>port_connected</code> Always 1.0 (all ports assumed connected) <code>abstime</code> Defaults to 0.0 (DC); caller updates for transient <code>hidden_state</code> Placeholder 0.0 (filled by init) <code>current</code> Placeholder 0.0"},{"location":"verilog_a_system_functions/#special-input-array-indices","title":"Special Input Array Indices","text":"<p>For codegen, special values accessed via negative indices: <pre><code>inputs[-1]  \u2192  gmin (from $simparam(\"gmin\"))\ninputs[-2]  \u2192  analysis_type (for analysis() function)\n</code></pre></p>"},{"location":"verilog_a_system_functions/#openvaf-compile-time-handling","title":"OpenVAF Compile-Time Handling","text":"<p>Some system functions are evaluated at compile time by OpenVAF: - <code>$simparam(\"name\", default)</code> with default \u2192 default value inlined - <code>$discontinuity</code> \u2192 Simulator hint, stripped during optimization - <code>$vt</code> \u2192 Computed inline as <code>k * T / q</code></p> <p>This means warnings for unknown <code>$simparam</code> only appear if OpenVAF preserves the call.</p>"},{"location":"verilog_a_system_functions/#osdi-structures","title":"OSDI Structures","text":"<pre><code>typedef struct OsdiSimParas {\n    char** names;      // Array of simparam names\n    double* vals;      // Array of simparam values\n} OsdiSimParas;\n\ntypedef struct OsdiSimInfo {\n    double temperature;  // Simulation temperature (K)\n    double abstime;      // Absolute time (s)\n    // ... other fields\n} OsdiSimInfo;\n</code></pre>"},{"location":"verilog_a_system_functions/#references","title":"References","text":"<ul> <li>Verilog-AMS LRM 2023 - System Tasks and Functions - Section 9</li> <li>Verilog-A Language Reference (SIMetrix)</li> <li>OSDI v4.0 Specification</li> <li>OpenVAF Source</li> </ul>"},{"location":"verilog_a_system_functions/#lrm-section-references","title":"LRM Section References","text":"Section Content 9.15 Analog kernel parameter functions (<code>$temperature</code>, <code>$vt</code>, <code>$simparam</code>, <code>$simparam$str</code>) 9.17 Analog kernel control functions (<code>$discontinuity</code>, <code>$bound_step</code>, <code>$limit</code>) 9.18 Hierarchical parameter functions (<code>$mfactor</code>, <code>$xposition</code>, <code>$yposition</code>, <code>$angle</code>, <code>$hflip</code>, <code>$vflip</code>) 9.19 Explicit binding detection (<code>$param_given</code>, <code>$port_connected</code>) Table 9-27 Standard <code>$simparam</code> parameter names Table 9-28 Standard <code>$simparam$str</code> parameter names"},{"location":"design/verilog-a-source-coverage-tracking/","title":"Verilog-A Source Coverage Tracking - System Design Document","text":"<p>Author: VAJAX Team Date: 2025-12-29 Status: Draft Version: 1.0</p>"},{"location":"design/verilog-a-source-coverage-tracking/#1-executive-summary","title":"1. Executive Summary","text":"<p>System Purpose: Track which lines of Verilog-A source code are exercised during VAJAX circuit simulations, enabling coverage-driven verification and CI integration.</p> <p>Scale: - VA Models: ~50 standard models (resistor, capacitor, diode, PSP103, BSIM, etc.) - Lines per Model: 100 - 10,000+ lines - Simulations: 1000s of test runs in CI</p> <p>Key Challenges: 1. Source location information must survive the OpenVAF \u2192 Python \u2192 JAX transformation pipeline 2. JAX's JIT compilation and XLA optimizations obscure the mapping between operations and source 3. Runtime tracing must not significantly impact simulation performance 4. Coverage data must be aggregated across multiple simulation runs</p>"},{"location":"design/verilog-a-source-coverage-tracking/#2-requirements","title":"2. Requirements","text":""},{"location":"design/verilog-a-source-coverage-tracking/#21-functional-requirements","title":"2.1 Functional Requirements","text":"<ol> <li>Source Mapping</li> <li>FR-1: Map each generated JAX expression to its originating Verilog-A source line</li> <li>FR-2: Preserve source file, line number, and column information</li> <li> <p>FR-3: Handle multi-line expressions and macro expansions</p> </li> <li> <p>Execution Tracking</p> </li> <li>FR-4: Track which source lines are executed during simulation</li> <li>FR-5: Count execution frequency per source line</li> <li> <p>FR-6: Track branch coverage (if/else, case statements)</p> </li> <li> <p>Output &amp; Integration</p> </li> <li>FR-7: Generate Cobertura-compatible XML coverage reports</li> <li>FR-8: Support incremental coverage merging across runs</li> <li>FR-9: Integrate with GitHub Actions coverage visualization</li> </ol>"},{"location":"design/verilog-a-source-coverage-tracking/#22-non-functional-requirements","title":"2.2 Non-Functional Requirements","text":"Category Requirement Target Priority Performance Overhead with coverage disabled 0% Critical Performance Overhead with coverage enabled &lt; 20% High Accuracy Source line attribution 100% for direct mappings High Compatibility Cobertura DTD compliance Full High Usability Enable/disable at runtime Single flag Medium"},{"location":"design/verilog-a-source-coverage-tracking/#3-system-context","title":"3. System Context","text":""},{"location":"design/verilog-a-source-coverage-tracking/#31-current-pipeline-no-coverage","title":"3.1 Current Pipeline (No Coverage)","text":"<pre><code>flowchart LR\n    subgraph \"Compile Time\"\n        VA[\ud83d\udcc4 Verilog-A&lt;br/&gt;.va files] --&gt; OC[\u2699\ufe0f OpenVAF&lt;br/&gt;Compiler]\n        OC --&gt; IR[\ud83d\udd27 OpenVAF IR&lt;br/&gt;+ Metadata]\n        IR --&gt; PY[\ud83d\udc0d openvaf-py&lt;br/&gt;Module]\n    end\n\n    subgraph \"Translation Time\"\n        PY --&gt; JAX[\ud83d\udcca openvaf-jax&lt;br/&gt;Translator]\n        JAX --&gt; FN[\u03bb JAX Functions&lt;br/&gt;eval, init]\n    end\n\n    subgraph \"Runtime\"\n        FN --&gt; JIT[\u26a1 JAX JIT&lt;br/&gt;Compilation]\n        JIT --&gt; XLA[\ud83d\ude80 XLA/GPU&lt;br/&gt;Execution]\n    end\n\n    classDef compile fill:#90EE90,stroke:#333,stroke-width:2px,color:darkgreen\n    classDef translate fill:#87CEEB,stroke:#333,stroke-width:2px,color:darkblue\n    classDef runtime fill:#FFB6C1,stroke:#333,stroke-width:2px,color:darkred\n\n    class VA,OC,IR,PY compile\n    class JAX,FN translate\n    class JIT,XLA runtime</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#32-target-pipeline-with-coverage","title":"3.2 Target Pipeline (With Coverage)","text":"<pre><code>flowchart LR\n    subgraph \"Compile Time\"\n        VA[\ud83d\udcc4 Verilog-A&lt;br/&gt;.va files] --&gt; OC[\u2699\ufe0f OpenVAF&lt;br/&gt;Compiler]\n        OC --&gt; IR[\ud83d\udd27 OpenVAF IR&lt;br/&gt;+ Source Spans]\n        IR --&gt; PY[\ud83d\udc0d openvaf-py&lt;br/&gt;Module + SourceMap]\n    end\n\n    subgraph \"Translation Time\"\n        PY --&gt; JAX[\ud83d\udcca openvaf-jax&lt;br/&gt;Translator]\n        JAX --&gt; FN[\u03bb JAX Functions&lt;br/&gt;+ Coverage Hooks]\n        JAX --&gt; SM[\ud83d\uddfa\ufe0f Source Map&lt;br/&gt;JAX Op \u2192 VA Line]\n    end\n\n    subgraph \"Runtime\"\n        FN --&gt; JIT[\u26a1 JAX JIT&lt;br/&gt;Compilation]\n        JIT --&gt; XLA[\ud83d\ude80 XLA/GPU&lt;br/&gt;Execution]\n        XLA --&gt; PROF[\ud83d\udcc8 Profiler&lt;br/&gt;Op Counters]\n        PROF --&gt; SM\n        SM --&gt; COV[\ud83d\udccb Coverage&lt;br/&gt;Aggregator]\n    end\n\n    subgraph \"Output\"\n        COV --&gt; XML[\ud83d\udcc4 Cobertura&lt;br/&gt;XML]\n        COV --&gt; HTML[\ud83c\udf10 HTML&lt;br/&gt;Report]\n    end\n\n    classDef compile fill:#90EE90,stroke:#333,stroke-width:2px,color:darkgreen\n    classDef translate fill:#87CEEB,stroke:#333,stroke-width:2px,color:darkblue\n    classDef runtime fill:#FFB6C1,stroke:#333,stroke-width:2px,color:darkred\n    classDef output fill:#E6E6FA,stroke:#333,stroke-width:2px,color:purple\n\n    class VA,OC,IR,PY compile\n    class JAX,FN,SM translate\n    class JIT,XLA,PROF,COV runtime\n    class XML,HTML output</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#4-high-level-architecture","title":"4. High-Level Architecture","text":""},{"location":"design/verilog-a-source-coverage-tracking/#41-component-overview","title":"4.1 Component Overview","text":"<pre><code>graph TB\n    subgraph \"Layer 1: OpenVAF Compiler\"\n        PARSE[Parser&lt;br/&gt;AST + Spans]\n        HIR[HIR Lowering&lt;br/&gt;Preserve Spans]\n        MIR[MIR Generation&lt;br/&gt;Instruction Spans]\n        EXPORT[Span Export API]\n\n        PARSE --&gt; HIR --&gt; MIR --&gt; EXPORT\n    end\n\n    subgraph \"Layer 2: openvaf-py Bindings\"\n        PYMOD[Python Module&lt;br/&gt;param_names, nodes]\n        SPANS[SpanInfo Class&lt;br/&gt;file, line, col]\n        MAPPING[Instruction\u2192Span Map]\n\n        EXPORT --&gt; PYMOD\n        EXPORT --&gt; SPANS\n        PYMOD --- SPANS\n        SPANS --&gt; MAPPING\n    end\n\n    subgraph \"Layer 3: openvaf-jax Translator\"\n        TRANS[JAX Translator&lt;br/&gt;Generate Python]\n        SRCMAP[SourceMap Builder&lt;br/&gt;JAX expr \u2192 VA line]\n        HOOKS[Coverage Hooks&lt;br/&gt;Instrumentation]\n\n        MAPPING --&gt; TRANS\n        TRANS --&gt; SRCMAP\n        TRANS --&gt; HOOKS\n    end\n\n    subgraph \"Layer 4: Runtime Tracking\"\n        COUNTER[Op Counter&lt;br/&gt;Execution counts]\n        BRANCH[Branch Tracker&lt;br/&gt;if/else coverage]\n        PROF[JAX Profiler&lt;br/&gt;HLO Execution]\n\n        HOOKS --&gt; COUNTER\n        HOOKS --&gt; BRANCH\n        SRCMAP --&gt; PROF\n    end\n\n    subgraph \"Layer 5: Reporting\"\n        AGG[Coverage Aggregator&lt;br/&gt;Merge runs]\n        COBERTURA[Cobertura XML&lt;br/&gt;Generator]\n        REPORT[HTML Report&lt;br/&gt;Generator]\n\n        COUNTER --&gt; AGG\n        BRANCH --&gt; AGG\n        PROF --&gt; AGG\n        AGG --&gt; COBERTURA\n        AGG --&gt; REPORT\n    end\n\n    classDef l1 fill:#FFE4B5,stroke:#333,stroke-width:2px,color:black\n    classDef l2 fill:#98FB98,stroke:#333,stroke-width:2px,color:black\n    classDef l3 fill:#87CEEB,stroke:#333,stroke-width:2px,color:black\n    classDef l4 fill:#DDA0DD,stroke:#333,stroke-width:2px,color:black\n    classDef l5 fill:#F0E68C,stroke:#333,stroke-width:2px,color:black\n\n    class PARSE,HIR,MIR,EXPORT l1\n    class PYMOD,SPANS,MAPPING l2\n    class TRANS,SRCMAP,HOOKS l3\n    class COUNTER,BRANCH,PROF l4\n    class AGG,COBERTURA,REPORT l5</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#5-component-design","title":"5. Component Design","text":""},{"location":"design/verilog-a-source-coverage-tracking/#51-layer-1-openvaf-compiler-modifications","title":"5.1 Layer 1: OpenVAF Compiler Modifications","text":"<p>Current State: OpenVAF has internal span information for error reporting but doesn't expose it through the compilation output.</p> <p>Required Changes:</p> <pre><code>// New: SourceSpan struct for export\n#[derive(Debug, Clone, Serialize)]\npub struct SourceSpan {\n    pub file_id: u32,\n    pub start_line: u32,\n    pub start_col: u32,\n    pub end_line: u32,\n    pub end_col: u32,\n}\n\n// New: Instruction metadata with span\n#[derive(Debug, Clone, Serialize)]\npub struct InstructionMeta {\n    pub span: SourceSpan,\n    pub kind: InstructionKind,  // assignment, branch, call, etc.\n    pub variable: Option&lt;String&gt;,\n}\n\n// New: Module metadata export\nimpl CompiledModule {\n    pub fn export_source_map(&amp;self) -&gt; SourceMap {\n        // Export mapping: instruction_id -&gt; SourceSpan\n    }\n\n    pub fn export_file_table(&amp;self) -&gt; Vec&lt;PathBuf&gt; {\n        // Export file_id -&gt; file path mapping\n    }\n}\n</code></pre> <p>Scope of Changes: - <code>osdi/src/compilation.rs</code> - Add span preservation during MIR generation - <code>osdi/src/metadata.rs</code> - New module for source map export - <code>melange/src/lib.rs</code> - Expose through FFI</p>"},{"location":"design/verilog-a-source-coverage-tracking/#52-layer-2-openvaf-py-bindings","title":"5.2 Layer 2: openvaf-py Bindings","text":"<p>New Python API:</p> <pre><code>@dataclass\nclass SourceSpan:\n    \"\"\"Source location in Verilog-A file.\"\"\"\n    file: str\n    start_line: int\n    start_col: int\n    end_line: int\n    end_col: int\n\n    def __str__(self) -&gt; str:\n        return f\"{self.file}:{self.start_line}:{self.start_col}\"\n\n@dataclass\nclass InstructionInfo:\n    \"\"\"Metadata for a single compiled instruction.\"\"\"\n    id: int\n    span: SourceSpan\n    kind: str  # 'assign', 'branch', 'contrib', 'call'\n    variable: Optional[str]\n\nclass CompiledModule:\n    # Existing properties\n    param_names: List[str]\n    param_kinds: List[str]\n    nodes: List[str]\n\n    # New: Source mapping\n    source_files: List[str]\n    instructions: List[InstructionInfo]\n\n    def get_instructions_for_line(self, file: str, line: int) -&gt; List[InstructionInfo]:\n        \"\"\"Get all instructions originating from a source line.\"\"\"\n\n    def get_span_for_instruction(self, inst_id: int) -&gt; Optional[SourceSpan]:\n        \"\"\"Get source location for an instruction.\"\"\"\n</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#53-layer-3-openvaf-jax-source-map","title":"5.3 Layer 3: openvaf-jax Source Map","text":"<p>Source Map Format:</p> <pre><code>@dataclass\nclass JAXSourceMap:\n    \"\"\"Maps JAX expressions to Verilog-A source lines.\"\"\"\n\n    # file_id -&gt; file path\n    files: Dict[int, str]\n\n    # Maps JAX variable name to source span\n    # e.g., \"contrib_0\" -&gt; SourceSpan(psp103.va, 1234, 1, 1234, 45)\n    variable_spans: Dict[str, SourceSpan]\n\n    # Maps array index to source span (for vectorized ops)\n    # e.g., (\"residual\", 5) -&gt; SourceSpan(...)\n    array_spans: Dict[Tuple[str, int], SourceSpan]\n\n    # Branch tracking: branch_id -&gt; (condition_span, true_span, false_span)\n    branches: Dict[int, Tuple[SourceSpan, SourceSpan, Optional[SourceSpan]]]\n\n    def to_json(self) -&gt; str:\n        \"\"\"Serialize for caching.\"\"\"\n\n    @classmethod\n    def from_json(cls, data: str) -&gt; \"JAXSourceMap\":\n        \"\"\"Deserialize from cache.\"\"\"\n</code></pre> <p>Translation with Source Tracking:</p> <pre><code>class OpenVAFToJAX:\n    def translate_with_coverage(self) -&gt; Tuple[Callable, JAXSourceMap]:\n        \"\"\"Generate JAX function with source mapping.\"\"\"\n\n        source_map = JAXSourceMap()\n\n        for inst in self.module.instructions:\n            # Generate JAX code\n            jax_var = self._translate_instruction(inst)\n\n            # Record mapping\n            source_map.variable_spans[jax_var] = inst.span\n\n            if inst.kind == 'branch':\n                source_map.branches[inst.id] = self._extract_branch_spans(inst)\n\n        return jax_fn, source_map\n</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#54-layer-4-runtime-coverage-tracking","title":"5.4 Layer 4: Runtime Coverage Tracking","text":"<p>Coverage Modes:</p> <pre><code>flowchart TD\n    START([Simulation Start]) --&gt; MODE{Coverage Mode?}\n\n    MODE --&gt;|disabled| FAST[\u26a1 Fast Path&lt;br/&gt;No instrumentation]\n    MODE --&gt;|line| LINE[\ud83d\udccd Line Coverage&lt;br/&gt;Track executed lines]\n    MODE --&gt;|branch| BRANCH[\ud83d\udd00 Branch Coverage&lt;br/&gt;Track all paths]\n    MODE --&gt;|profile| PROFILE[\ud83d\udcca Profile Mode&lt;br/&gt;JAX profiler + mapping]\n\n    FAST --&gt; RUN[Run Simulation]\n    LINE --&gt; INST[Instrument Counters] --&gt; RUN\n    BRANCH --&gt; INST\n    PROFILE --&gt; JAXPROF[Enable JAX Profiler] --&gt; RUN\n\n    RUN --&gt; COLLECT{Coverage Mode?}\n\n    COLLECT --&gt;|disabled| DONE([Done])\n    COLLECT --&gt;|line/branch| MERGE[Merge Counters] --&gt; REPORT[Generate Report]\n    COLLECT --&gt;|profile| PARSE[Parse Trace] --&gt; MAP[Map to Source] --&gt; REPORT\n\n    REPORT --&gt; DONE\n\n    classDef fast fill:#90EE90,stroke:#333,color:darkgreen\n    classDef inst fill:#FFD700,stroke:#333,color:black\n    classDef prof fill:#87CEEB,stroke:#333,color:darkblue\n\n    class FAST fast\n    class LINE,BRANCH,INST inst\n    class PROFILE,JAXPROF,PARSE,MAP prof</code></pre> <p>Approach A: Counter-Based (Recommended for Line Coverage)</p> <pre><code>class LineCoverageTracker:\n    \"\"\"Track line execution via counters.\"\"\"\n\n    def __init__(self, source_map: JAXSourceMap):\n        self.source_map = source_map\n        # Counter per source line: (file_id, line) -&gt; count\n        self.line_counts: Dict[Tuple[int, int], int] = defaultdict(int)\n\n    def instrument(self, jax_fn: Callable) -&gt; Callable:\n        \"\"\"Wrap JAX function with coverage counters.\"\"\"\n\n        def instrumented(*args, **kwargs):\n            # Pre-execution: Mark lines as about to execute\n            # This uses JAX's callback mechanism\n            result = jax_fn(*args, **kwargs)\n\n            # Post-execution: Increment counters\n            for var in self._executed_vars:\n                if var in self.source_map.variable_spans:\n                    span = self.source_map.variable_spans[var]\n                    self.line_counts[(span.file_id, span.start_line)] += 1\n\n            return result\n\n        return instrumented\n</code></pre> <p>Approach B: JAX Profiler-Based (For Detailed Analysis)</p> <pre><code>class ProfileCoverageTracker:\n    \"\"\"Track coverage via JAX profiler traces.\"\"\"\n\n    def __init__(self, source_map: JAXSourceMap):\n        self.source_map = source_map\n\n    def run_with_profiling(self, jax_fn: Callable, *args) -&gt; Tuple[Any, CoverageData]:\n        \"\"\"Run function with JAX profiler and extract coverage.\"\"\"\n\n        with jax.profiler.trace(\"/tmp/coverage_trace\"):\n            result = jax_fn(*args)\n\n        # Parse the profiler trace\n        trace_data = self._parse_trace(\"/tmp/coverage_trace\")\n\n        # Map HLO operations back to source lines\n        coverage = self._map_trace_to_source(trace_data)\n\n        return result, coverage\n\n    def _map_trace_to_source(self, trace: TraceData) -&gt; CoverageData:\n        \"\"\"Map profiler trace entries to source lines.\"\"\"\n        coverage = CoverageData()\n\n        for op in trace.operations:\n            # JAX preserves some metadata in HLO op names\n            if span := self._find_span_for_op(op):\n                coverage.mark_executed(span, op.execution_count)\n\n        return coverage\n</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#55-layer-5-cobertura-output","title":"5.5 Layer 5: Cobertura Output","text":"<p>Cobertura XML Structure:</p> <pre><code>&lt;?xml version=\"1.0\" ?&gt;\n&lt;!DOCTYPE coverage SYSTEM \"http://cobertura.sourceforge.net/xml/coverage-04.dtd\"&gt;\n&lt;coverage line-rate=\"0.85\" branch-rate=\"0.72\"\n          lines-covered=\"850\" lines-valid=\"1000\"\n          branches-covered=\"36\" branches-valid=\"50\"\n          version=\"1.0\" timestamp=\"1703876400\"&gt;\n    &lt;sources&gt;\n        &lt;source&gt;/path/to/vendor/VACASK/devices&lt;/source&gt;\n    &lt;/sources&gt;\n    &lt;packages&gt;\n        &lt;package name=\"psp103\" line-rate=\"0.90\" branch-rate=\"0.80\"&gt;\n            &lt;classes&gt;\n                &lt;class name=\"psp103va\" filename=\"psp103.va\"\n                       line-rate=\"0.90\" branch-rate=\"0.80\"&gt;\n                    &lt;methods/&gt;\n                    &lt;lines&gt;\n                        &lt;line number=\"100\" hits=\"1000\"/&gt;\n                        &lt;line number=\"101\" hits=\"1000\"/&gt;\n                        &lt;line number=\"102\" hits=\"0\"/&gt;  &lt;!-- Not covered --&gt;\n                        &lt;line number=\"150\" hits=\"500\" branch=\"true\"\n                              condition-coverage=\"50% (1/2)\"&gt;\n                            &lt;conditions&gt;\n                                &lt;condition number=\"0\" type=\"jump\" coverage=\"50%\"/&gt;\n                            &lt;/conditions&gt;\n                        &lt;/line&gt;\n                    &lt;/lines&gt;\n                &lt;/class&gt;\n            &lt;/classes&gt;\n        &lt;/package&gt;\n    &lt;/packages&gt;\n&lt;/coverage&gt;\n</code></pre> <p>Python Generator:</p> <pre><code>class CoberturaGenerator:\n    \"\"\"Generate Cobertura XML from coverage data.\"\"\"\n\n    def generate(self, coverage: CoverageData, output_path: Path) -&gt; None:\n        root = ET.Element(\"coverage\")\n        root.set(\"line-rate\", str(coverage.line_rate))\n        root.set(\"branch-rate\", str(coverage.branch_rate))\n        root.set(\"lines-covered\", str(coverage.lines_covered))\n        root.set(\"lines-valid\", str(coverage.lines_valid))\n        root.set(\"branches-covered\", str(coverage.branches_covered))\n        root.set(\"branches-valid\", str(coverage.branches_valid))\n        root.set(\"version\", \"1.0\")\n        root.set(\"timestamp\", str(int(time.time())))\n\n        # Add sources\n        sources = ET.SubElement(root, \"sources\")\n        for source_dir in coverage.source_dirs:\n            ET.SubElement(sources, \"source\").text = str(source_dir)\n\n        # Add packages (group by model)\n        packages = ET.SubElement(root, \"packages\")\n        for model_name, model_coverage in coverage.by_model.items():\n            self._add_package(packages, model_name, model_coverage)\n\n        # Write XML\n        tree = ET.ElementTree(root)\n        tree.write(output_path, encoding=\"utf-8\", xml_declaration=True)\n</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#6-data-flow","title":"6. Data Flow","text":""},{"location":"design/verilog-a-source-coverage-tracking/#61-compilation-flow-source-map-generation","title":"6.1 Compilation Flow (Source Map Generation)","text":"<pre><code>sequenceDiagram\n    participant VA as Verilog-A File\n    participant OC as OpenVAF Compiler\n    participant PY as openvaf-py\n    participant JAX as openvaf-jax\n    participant CACHE as Source Map Cache\n\n    VA-&gt;&gt;OC: Parse psp103.va\n    OC-&gt;&gt;OC: Generate AST with spans\n    OC-&gt;&gt;OC: Lower to HIR (preserve spans)\n    OC-&gt;&gt;OC: Generate MIR (instruction spans)\n    OC-&gt;&gt;PY: Export CompiledModule + SpanMap\n    PY-&gt;&gt;PY: Build Python InstructionInfo list\n    PY-&gt;&gt;JAX: Pass module + instruction metadata\n    JAX-&gt;&gt;JAX: Translate to JAX functions\n    JAX-&gt;&gt;JAX: Build JAXSourceMap\n    JAX-&gt;&gt;CACHE: Cache source map (by model hash)\n    JAX--&gt;&gt;PY: Return (jax_fn, source_map)</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#62-runtime-flow-coverage-collection","title":"6.2 Runtime Flow (Coverage Collection)","text":"<pre><code>sequenceDiagram\n    participant SIM as Simulator\n    participant COV as Coverage Tracker\n    participant JAX as JAX Runtime\n    participant MAP as Source Map\n    participant AGG as Aggregator\n\n    SIM-&gt;&gt;COV: Enable coverage mode\n    COV-&gt;&gt;MAP: Load source map\n    COV-&gt;&gt;JAX: Instrument functions\n\n    loop Each Timestep\n        SIM-&gt;&gt;JAX: Run simulation step\n        JAX-&gt;&gt;JAX: Execute instrumented code\n        JAX-&gt;&gt;COV: Report executed operations\n        COV-&gt;&gt;COV: Update line counters\n    end\n\n    SIM-&gt;&gt;COV: End simulation\n    COV-&gt;&gt;AGG: Submit run coverage\n    AGG-&gt;&gt;AGG: Merge with previous runs\n    AGG--&gt;&gt;SIM: Return merged coverage</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#7-implementation-phases","title":"7. Implementation Phases","text":""},{"location":"design/verilog-a-source-coverage-tracking/#phase-1-foundation-4-6-weeks","title":"Phase 1: Foundation (4-6 weeks)","text":"<pre><code>gantt\n    title Phase 1: Foundation\n    dateFormat  YYYY-MM-DD\n    section OpenVAF\n    Add span export API           :p1a, 2025-01-06, 2w\n    Update melange FFI            :p1b, after p1a, 1w\n    section openvaf-py\n    Add SpanInfo bindings         :p1c, after p1b, 1w\n    Expose instruction metadata   :p1d, after p1c, 1w\n    section Testing\n    Unit tests for span export    :p1e, after p1d, 1w</code></pre> <p>Deliverables: - OpenVAF exports source spans through new API - openvaf-py exposes <code>SourceSpan</code> and <code>InstructionInfo</code> classes - Basic tests verifying span preservation</p>"},{"location":"design/verilog-a-source-coverage-tracking/#phase-2-source-mapping-3-4-weeks","title":"Phase 2: Source Mapping (3-4 weeks)","text":"<pre><code>gantt\n    title Phase 2: Source Mapping\n    dateFormat  YYYY-MM-DD\n    section openvaf-jax\n    JAXSourceMap implementation   :p2a, 2025-02-17, 2w\n    Translator integration        :p2b, after p2a, 1w\n    Source map caching           :p2c, after p2b, 1w</code></pre> <p>Deliverables: - <code>JAXSourceMap</code> class mapping JAX expressions to VA lines - Automatic source map generation during translation - Caching layer to avoid regeneration</p>"},{"location":"design/verilog-a-source-coverage-tracking/#phase-3-runtime-tracking-4-5-weeks","title":"Phase 3: Runtime Tracking (4-5 weeks)","text":"<pre><code>gantt\n    title Phase 3: Runtime Tracking\n    dateFormat  YYYY-MM-DD\n    section Counter-Based\n    Line counter implementation   :p3a, 2025-03-17, 2w\n    Branch counter implementation :p3b, after p3a, 1w\n    section Profiler-Based\n    JAX profiler integration      :p3c, after p3b, 2w\n    Trace-to-source mapping      :p3d, after p3c, 1w</code></pre> <p>Deliverables: - Counter-based line/branch coverage - JAX profiler integration for detailed analysis - Runtime overhead &lt; 20%</p>"},{"location":"design/verilog-a-source-coverage-tracking/#phase-4-reporting-ci-2-3-weeks","title":"Phase 4: Reporting &amp; CI (2-3 weeks)","text":"<pre><code>gantt\n    title Phase 4: Reporting &amp; CI\n    dateFormat  YYYY-MM-DD\n    section Reporting\n    Cobertura XML generator       :p4a, 2025-05-05, 1w\n    HTML report generator         :p4b, after p4a, 1w\n    section CI Integration\n    GitHub Actions workflow       :p4c, after p4b, 1w\n    Coverage badge generation     :p4d, after p4c, 3d</code></pre> <p>Deliverables: - Cobertura-compatible XML output - HTML coverage reports with source highlighting - GitHub Actions integration with coverage visualization</p>"},{"location":"design/verilog-a-source-coverage-tracking/#8-api-design","title":"8. API Design","text":""},{"location":"design/verilog-a-source-coverage-tracking/#81-user-facing-api","title":"8.1 User-Facing API","text":"<pre><code>from vajax.coverage import CoverageTracker, CoverageMode\n\n# Enable coverage during simulation\ntracker = CoverageTracker(mode=CoverageMode.LINE_AND_BRANCH)\n\nengine = CircuitEngine(\"circuit.sim\")\nengine.parse()\n\n# Run with coverage\nwith tracker.track(engine):\n    result = engine.run_transient(t_stop=1e-6, dt=1e-9)\n\n# Get coverage data\ncoverage = tracker.get_coverage()\n\n# Generate reports\ncoverage.to_cobertura(\"coverage.xml\")\ncoverage.to_html(\"coverage_report/\")\n\n# Print summary\nprint(f\"Line coverage: {coverage.line_rate:.1%}\")\nprint(f\"Branch coverage: {coverage.branch_rate:.1%}\")\n\n# Show uncovered lines\nfor file, lines in coverage.uncovered_lines.items():\n    print(f\"{file}: lines {lines}\")\n</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#82-cli-interface","title":"8.2 CLI Interface","text":"<pre><code># Run tests with coverage\nVAJAX_COVERAGE=1 uv run pytest tests/\n\n# Generate coverage report\nuv run python -m vajax.coverage report \\\n    --input coverage.json \\\n    --output coverage.xml \\\n    --format cobertura\n\n# Merge multiple coverage files\nuv run python -m vajax.coverage merge \\\n    coverage1.json coverage2.json \\\n    --output merged.json\n\n# Show coverage summary\nuv run python -m vajax.coverage summary coverage.json\n</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#83-ci-integration","title":"8.3 CI Integration","text":"<pre><code># .github/workflows/coverage.yml\nname: Coverage\n\non: [push, pull_request]\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run tests with coverage\n        run: |\n          VAJAX_COVERAGE=1 uv run pytest tests/ \\\n            --cov-report=xml:coverage.xml\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v4\n        with:\n          files: coverage.xml\n          flags: verilog-a\n\n      - name: Coverage comment on PR\n        uses: py-cov-action/python-coverage-comment-action@v3\n        with:\n          COVERAGE_DATA_BRANCH: coverage-data\n</code></pre>"},{"location":"design/verilog-a-source-coverage-tracking/#9-trade-offs-alternatives","title":"9. Trade-offs &amp; Alternatives","text":""},{"location":"design/verilog-a-source-coverage-tracking/#91-source-mapping-approach","title":"9.1 Source Mapping Approach","text":"Approach Pros Cons Recommendation Compile-time spans Accurate, no runtime cost Requires OpenVAF changes \u2705 Recommended Debug info (DWARF) Standard format Complex integration \u274c Over-engineered Heuristic mapping No compiler changes Inaccurate for complex code \u274c Unreliable <p>Decision: Compile-time span export. It's the most accurate and aligns with how coverage tools work for other languages.</p>"},{"location":"design/verilog-a-source-coverage-tracking/#92-runtime-tracking-approach","title":"9.2 Runtime Tracking Approach","text":"Approach Overhead Accuracy Use Case Counter instrumentation 5-15% Line-level CI, regular testing JAX profiler 20-50% Op-level Detailed analysis Sampling 1-5% Statistical Production monitoring <p>Decision: Support both counter and profiler modes. Counter for CI (low overhead), profiler for debugging (detailed analysis).</p>"},{"location":"design/verilog-a-source-coverage-tracking/#93-output-format","title":"9.3 Output Format","text":"Format CI Support Human Readable Ecosystem Cobertura XML \u2705 Excellent \u274c Poor GitHub, GitLab, Codecov LCOV \u2705 Good \u274c Poor gcov ecosystem JSON \u26a0\ufe0f Custom \u2705 Good Internal tools HTML N/A \u2705 Excellent Manual review <p>Decision: Primary: Cobertura XML (CI integration). Secondary: HTML for human review. Internal: JSON for merging/caching.</p>"},{"location":"design/verilog-a-source-coverage-tracking/#10-risks-mitigations","title":"10. Risks &amp; Mitigations","text":"Risk Impact Probability Mitigation OpenVAF changes rejected upstream High Medium Fork or maintain patch set JAX JIT obscures mappings Medium High Use stable variable names, preserve metadata Performance overhead too high High Low Make coverage optional, optimize counters Cobertura format limitations Low Medium Extend with custom attributes"},{"location":"design/verilog-a-source-coverage-tracking/#11-success-metrics","title":"11. Success Metrics","text":"Metric Target Measurement Source line attribution accuracy &gt; 95% Manual audit of 100 random lines Runtime overhead (counter mode) &lt; 15% Benchmark comparison CI integration GitHub + GitLab Working coverage visualization Model coverage All VACASK models All .va files have coverage"},{"location":"design/verilog-a-source-coverage-tracking/#12-appendices","title":"12. Appendices","text":""},{"location":"design/verilog-a-source-coverage-tracking/#a-openvaf-source-span-infrastructure-investigation-notes","title":"A. OpenVAF Source Span Infrastructure (Investigation Notes)","text":"<p>This section documents the existing source span infrastructure in OpenVAF based on codebase investigation (December 2025).</p>"},{"location":"design/verilog-a-source-coverage-tracking/#a1-current-architecture","title":"A.1 Current Architecture","text":"<p>OpenVAF already tracks source locations through the compilation pipeline:</p> <pre><code>Verilog-A \u2192 Parser \u2192 AST (with Spans) \u2192 HIR \u2192 MIR (with SourceLocs) \u2192 LLVM \u2192 .osdi\n                      \u2193                  \u2193           \u2193\n                   TextRange          ExprId      SourceLoc(i32)\n                   FileSpan       BodySourceMap   (opaque HIR ref)\n</code></pre> <p>Key Types:</p> <ol> <li><code>SourceLoc</code> (<code>openvaf/mir/src/lib.rs:222</code>)</li> <li>Opaque 32-bit integer attached to each MIR instruction</li> <li>Default value (<code>!0</code> = -1) means \"no source location\"</li> <li> <p>Stored in <code>Function.srclocs: TiVec&lt;Inst, SourceLoc&gt;</code></p> </li> <li> <p><code>BodySourceMap</code> (<code>openvaf/hir_def/src/body.rs:32-43</code>)</p> </li> <li>Maps HIR expressions back to AST pointers</li> <li><code>expr_map_back: ArenaMap&lt;Expr, Option&lt;AstPtr&lt;ast::Expr&gt;&gt;&gt;</code> - reverse mapping</li> <li> <p><code>stmt_map_back: ArenaMap&lt;Stmt, Option&lt;AstPtr&lt;ast::Stmt&gt;&gt;&gt;</code> - statement mapping</p> </li> <li> <p><code>FileSpan</code> (<code>openvaf/preprocessor/src/sourcemap.rs</code>)</p> </li> <li>Contains <code>FileId</code> + <code>TextRange</code> for actual source location</li> <li> <p>Handles macro expansions via <code>CtxSpan</code></p> </li> <li> <p><code>SourceMap</code> (preprocessor level)</p> </li> <li>Tracks file table and macro expansion contexts</li> <li><code>lookup_expansion()</code> resolves spans through macro stack</li> </ol>"},{"location":"design/verilog-a-source-coverage-tracking/#a2-how-sourceloc-connects-to-source","title":"A.2 How SourceLoc Connects to Source","text":"<p>The mapping chain is:</p> <pre><code># MIR instruction has SourceLoc(i32)\ninst_srcloc: SourceLoc = function.srclocs[inst_id]\n\n# SourceLoc stores ExprId + 1 (see hir_lower)\n# SourceLoc(bits) where bits = u32::from(expr_id) + 1\nexpr_id: ExprId = ExprId::from(inst_srcloc.bits() - 1)\n\n# BodySourceMap maps ExprId \u2192 AstPtr\nast_ptr: Option&lt;AstPtr&lt;Expr&gt;&gt; = body_source_map.expr_map_back[expr_id]\n\n# AstPtr can be resolved to syntax node, which has TextRange\n# TextRange + FileId = FileSpan \u2192 actual line/column\n</code></pre> <p>Key insight from <code>hir_lower/src/lib.rs</code>: <pre><code>// SourceLoc is set as: SourceLoc::new(u32::from(expr) as i32 + 1)\n// This stores the HIR ExprId in the MIR instruction's source location\n</code></pre></p>"},{"location":"design/verilog-a-source-coverage-tracking/#a3-what-verilogae-currently-exposes","title":"A.3 What verilogae Currently Exposes","text":"<p>Looking at <code>verilogae/verilogae_py/src/model.rs</code> and <code>verilogae_ffi/src/ffi/generated.rs</code>:</p> <p>Currently Exposed: - <code>verilogae_real_params()</code> - parameter names - <code>verilogae_real_param_descriptions()</code> - param descriptions - <code>verilogae_nodes()</code> - port names - <code>verilogae_functions()</code> - function names - <code>verilogae_opvars()</code> - operating point variables - <code>verilogae_module_name()</code> - module name</p> <p>NOT Currently Exposed: - Source spans for parameters - Source spans for instructions - The <code>BodySourceMap</code> or any span information - File table (FileId \u2192 path mapping)</p>"},{"location":"design/verilog-a-source-coverage-tracking/#a4-required-changes-for-source-coverage","title":"A.4 Required Changes for Source Coverage","text":"<p>Layer 1: OpenVAF Core Changes</p> <ol> <li>Export BodySourceMap - Currently internal to HIR lowering</li> <li>Add query: <code>fn instruction_source_map(db, module) -&gt; InstructionSourceMap</code></li> <li> <p>Returns mapping: <code>instruction_id \u2192 (file_id, line, col)</code></p> </li> <li> <p>Export File Table - Map FileId to file path</p> </li> <li> <p>Add query: <code>fn file_table(db, root_file) -&gt; Vec&lt;(FileId, PathBuf)&gt;</code></p> </li> <li> <p>New API in <code>verilogae/verilogae/src/api.rs</code>:    <pre><code>expose_ptrs! {\n    const verilogae_source_spans: SourceSpanEntry = \"source.spans\";\n    const verilogae_source_files: *const c_char = \"source.files\";\n}\nexpose_consts! {\n    verilogae_source_span_cnt: usize = \"source.spans.cnt\";\n    verilogae_source_file_cnt: usize = \"source.files.cnt\";\n}\n</code></pre></p> </li> </ol> <p>Layer 2: openvaf-py Changes</p> <ol> <li> <p>Add <code>SourceSpan</code> type in new <code>spans.py</code>:    <pre><code>@dataclass\nclass SourceSpan:\n    file_id: int\n    start_line: int\n    start_col: int\n    end_line: int\n    end_col: int\n</code></pre></p> </li> <li> <p>Extend <code>VaeModel</code> to include:</p> </li> <li><code>source_files: List[str]</code> - file table</li> <li><code>source_spans: Dict[int, SourceSpan]</code> - instruction \u2192 span mapping</li> </ol> <p>Layer 3: verilogae Backend Changes</p> <ol> <li>In <code>back.rs</code> - Export source spans as global arrays</li> <li>Similar pattern to how <code>export_param_info()</code> exports parameter metadata</li> <li> <p>Add <code>export_source_map()</code> function</p> </li> <li> <p>In <code>compiler_db.rs</code> - Collect source spans during compilation</p> </li> <li>Query the <code>BodySourceMap</code> for each instruction</li> <li>Resolve to line/column via preprocessor <code>SourceMap</code></li> </ol>"},{"location":"design/verilog-a-source-coverage-tracking/#a5-simplified-implementation-path","title":"A.5 Simplified Implementation Path","text":"<p>Given the complexity, a phased approach:</p> <p>Phase 1A (Minimal Viable): - Export parameter source locations only (not all instructions) - Parameters have clear source in the AST - Sufficient for \"what parameters are used\" coverage</p> <p>Phase 1B (Full Instruction Coverage): - Export all MIR instruction source locations - Requires walking <code>function.srclocs</code> during code generation - More complex but enables line-level coverage</p>"},{"location":"design/verilog-a-source-coverage-tracking/#a6-key-files-to-modify","title":"A.6 Key Files to Modify","text":"File Purpose Changes <code>openvaf/osdi/src/compilation.rs</code> OSDI compilation Add span collection during MIR\u2192LLVM <code>openvaf/osdi/src/metadata.rs</code> (new) Source span export structures <code>verilogae/verilogae/src/back.rs</code> Code generation Export source maps as globals <code>verilogae/verilogae/src/api.rs</code> C API Add span access functions <code>verilogae/verilogae_ffi/src/ffi.rs</code> FFI types Add SourceSpan structures <code>verilogae/verilogae_py/src/model.rs</code> Python bindings Expose spans to Python"},{"location":"design/verilog-a-source-coverage-tracking/#b-glossary","title":"B. Glossary","text":"Term Definition Span Source location (file, line, column range) HIR High-level Intermediate Representation (OpenVAF) MIR Mid-level Intermediate Representation (OpenVAF) HLO High-Level Operations (XLA) Cobertura XML coverage format, originally for Java SourceLoc Opaque i32 in MIR storing HIR ExprId reference BodySourceMap HIR mapping from ExprId/StmtId back to AST pointers FileSpan File ID + text range for source locations CtxSpan Context-aware span handling macro expansions"},{"location":"design/verilog-a-source-coverage-tracking/#c-references","title":"C. References","text":"<ol> <li>OpenVAF Compiler</li> <li>JAX Profiler Documentation</li> <li>Cobertura DTD</li> <li>GitHub Coverage Visualization</li> </ol>"},{"location":"design/verilog-a-source-coverage-tracking/#c-file-structure","title":"C. File Structure","text":"<pre><code>vajax/\n\u251c\u2500\u2500 coverage/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 tracker.py          # CoverageTracker, CoverageMode\n\u2502   \u251c\u2500\u2500 source_map.py       # JAXSourceMap\n\u2502   \u251c\u2500\u2500 counters.py         # Counter-based tracking\n\u2502   \u251c\u2500\u2500 profiler.py         # JAX profiler integration\n\u2502   \u251c\u2500\u2500 aggregator.py       # Multi-run merging\n\u2502   \u251c\u2500\u2500 cobertura.py        # XML generation\n\u2502   \u2514\u2500\u2500 html_report.py      # HTML generation\n\nopenvaf-py/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 lib.rs              # Add span export FFI\n\u2514\u2500\u2500 python/\n    \u2514\u2500\u2500 openvaf_py/\n        \u251c\u2500\u2500 spans.py        # SourceSpan, InstructionInfo\n        \u2514\u2500\u2500 module.py       # Extended CompiledModule\n\nopenvaf-jax/\n\u2514\u2500\u2500 openvaf_jax/\n    \u251c\u2500\u2500 translator.py       # Add source map generation\n    \u2514\u2500\u2500 source_map.py       # JAXSourceMap implementation\n</code></pre>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/","title":"Plan: Generic Runtime Collapse Pattern from OpenVAF (Approach 2)","text":"<p>Status: Saved for later implementation Date: 2025-12-23 Context: After node count was fixed (47 nodes), DC operating point still differs. This plan addresses the PSP103-specific hack with a generic solution.</p>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#problem-summary","title":"Problem Summary","text":"<ul> <li>VAJAX currently has PSP103-specific collapse logic hardcoded in runner.py</li> <li>This is fragile and won't work for other models</li> <li>OpenVAF's init function already computes collapse decisions at runtime</li> <li>Need to expose this capability through openvaf-py</li> </ul>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#current-state","title":"Current State","text":"<ul> <li>Node count now matches VACASK (47) with PSP103-specific hack</li> <li>DC operating point still differs (0.5085V vs 0.661V)</li> <li>PSP103-specific code in <code>_get_psp103_collapse_pairs()</code> needs to be replaced</li> </ul>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#how-collapse-works-in-openvaf","title":"How Collapse Works in OpenVAF","text":""},{"location":"plans/plan-generic-runtime-collapse-openvaf/#static-information-already-exposed","title":"Static Information (already exposed)","text":"<p><code>compiled.node_collapse.pairs()</code> returns potential collapse pairs: - Each pair has a <code>CollapsePair</code> index - Currently exposed as <code>collapsible_pairs: Vec&lt;(u32, u32)&gt;</code></p>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#runtime-information-needs-exposure","title":"Runtime Information (needs exposure)","text":"<p>There are TWO sources of collapse:</p> <ol> <li>CollapseHint callbacks (from <code>V(N1,N2) &lt;+ 0</code> statements):</li> <li>Called at runtime when the collapse code path is executed</li> <li>In VA: <code>if (R &gt; 0) I&lt;+G*V else V&lt;+0</code> \u2192 CollapseHint called in else branch</li> <li> <p>The callback signals \"this pair should collapse\"</p> </li> <li> <p>CollapseImplicitEquation outputs (from implicit equations):</p> </li> <li>Boolean values in <code>init.intern.outputs</code></li> <li>Less common than CollapseHint</li> </ol>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#data-flow-for-psp103s-collapsabler","title":"Data Flow for PSP103's CollapsableR","text":"<pre><code>VA Code: `CollapsableR macro\n    \u2193\nif (R &gt; 0) I(N1,N2) &lt;+ G * V(N1,N2)\nelse V(N1,N2) &lt;+ 0   \u2192 CollapseHint(N1, N2) callback\n    \u2193\nDuring init: CollapseHint callbacks track which pairs collapse\n    \u2193\ncollapse_pattern: [bool; num_collapsible_pairs]\n</code></pre>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#key-insight","title":"Key Insight","text":"<ul> <li>VACASK's <code>setup_instance()</code> clears collapse pattern, then callbacks write <code>true</code></li> <li>openvaf-py can do the same: hook CollapseHint callbacks during init interpretation</li> </ul>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#implementation-plan","title":"Implementation Plan","text":""},{"location":"plans/plan-generic-runtime-collapse-openvaf/#step-1-modify-openvaf-pysrclibrs","title":"Step 1: Modify openvaf-py/src/lib.rs","text":"<p>1a. Add callback tracking info to VaModule struct</p> <pre><code>// In VaModule struct, add:\ncollapse_callback_indices: Vec&lt;(usize, u32, u32)&gt;,  // (callback_idx, hi_node, lo_node_or_max)\n</code></pre> <p>1b. Store collapse callback indices during compilation (lines ~960-968)</p> <p>After extracting <code>collapsible_pairs</code>, also map which callbacks correspond to which pairs:</p> <pre><code>// Build mapping from callback index to collapse pair\n// compiled.init.intern.callbacks contains CallBackKind entries\nlet mut collapse_callback_indices: Vec&lt;(usize, u32, u32)&gt; = Vec::new();\nfor (cb_idx, kind) in compiled.init.intern.callbacks.iter().enumerate() {\n    if let CallBackKind::CollapseHint(hi, lo) = *kind {\n        let hi_idx: u32 = /* convert Node to index */;\n        let lo_idx: u32 = lo.map(|n| /* convert */).unwrap_or(u32::MAX);\n        collapse_callback_indices.push((cb_idx, hi_idx, lo_idx));\n    }\n}\n</code></pre> <p>1c. Add <code>get_collapse_pattern()</code> method with callback hooks</p> <pre><code>/// Query which collapsible pairs should actually collapse based on parameters\n/// Returns: Vec&lt;bool&gt; where true = this pair collapses\nfn get_collapse_pattern(&amp;self, params: std::collections::HashMap&lt;String, f64&gt;) -&gt; PyResult&lt;Vec&lt;bool&gt;&gt; {\n    // Track which pairs collapse via callback invocation\n    let collapse_pattern = std::cell::RefCell::new(vec![false; self.num_collapsible]);\n    let callback_mapping = &amp;self.collapse_callback_indices;\n    let all_pairs = &amp;self.collapsible_pairs;\n\n    // Collapse callback - marks pair as collapsed when invoked\n    let collapse_callback = |state: &amp;mut InterpreterState, args: &amp;[Value], rets: &amp;[Value], data: *mut c_void| {\n        // Get callback index from data pointer\n        let cb_idx = data as usize;\n\n        // Find the pair this callback corresponds to\n        for (idx, hi, lo) in callback_mapping {\n            if *idx == cb_idx {\n                // Find pair index in collapsible_pairs\n                for (pair_idx, &amp;(p_hi, p_lo)) in all_pairs.iter().enumerate() {\n                    if p_hi == *hi &amp;&amp; p_lo == *lo {\n                        collapse_pattern.borrow_mut()[pair_idx] = true;\n                    }\n                }\n            }\n        }\n    };\n\n    // Build callbacks array with collapse_callback for CollapseHint, stub for others\n    let callbacks = /* build callbacks with collapse_callback hooked */;\n\n    // Run init function\n    let mut init_args = /* build from params */;\n    let mut init_interp = Interpreter::new(&amp;self.init_func, &amp;callbacks, &amp;init_args);\n    init_interp.run();\n\n    Ok(collapse_pattern.into_inner())\n}\n</code></pre>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#step-2-modify-vajaxbenchmarksrunnerpy","title":"Step 2: Modify vajax/benchmarks/runner.py","text":"<p>2a. Update <code>_get_model_collapse_pairs()</code></p> <pre><code>def _get_model_collapse_pairs(self, model_type: str, device_params: Dict[str, float]) -&gt; List[Tuple[int, int]]:\n    \"\"\"Get collapse pairs based on runtime parameter evaluation.\"\"\"\n    compiled = self._compiled_models.get(model_type)\n    if not compiled:\n        return []\n\n    module = compiled.get('module')\n    if module is None:\n        return []\n\n    all_pairs = module.collapsible_pairs\n\n    # Query runtime collapse pattern\n    try:\n        collapse_pattern = module.get_collapse_pattern(device_params)\n        return [pair for pair, should_collapse in zip(all_pairs, collapse_pattern) if should_collapse]\n    except Exception:\n        # Fallback: no collapse if query fails\n        return []\n</code></pre> <p>2b. Remove PSP103-specific code</p> <p>Delete <code>_get_psp103_collapse_pairs()</code> method entirely.</p>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#step-3-update-tests","title":"Step 3: Update Tests","text":"<ul> <li>Remove any PSP103-specific test expectations</li> <li>Verify generic collapse works for all benchmark models</li> </ul>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#files-to-modify","title":"Files to Modify","text":"<ol> <li><code>openvaf-py/src/lib.rs</code> (~60 lines)</li> <li>Add <code>collapse_callback_indices: Vec&lt;(usize, u32, u32)&gt;</code> to VaModule struct</li> <li>Build callback \u2192 pair mapping during compilation</li> <li> <p>Add <code>get_collapse_pattern()</code> method with callback hooks</p> </li> <li> <p><code>vajax/benchmarks/runner.py</code> (~30 lines)</p> </li> <li>Update <code>_get_model_collapse_pairs()</code> to use generic query</li> <li> <p>Remove <code>_get_psp103_collapse_pairs()</code> (~50 lines deleted)</p> </li> <li> <p><code>tests/test_vacask_benchmarks.py</code></p> </li> <li>Remove PSP103-specific test expectations</li> </ol>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#verification","title":"Verification","text":"<ol> <li>Ring benchmark: node count matches VACASK (47)</li> <li>Ring benchmark: DC operating point matches VACASK (~0.661V)</li> <li>All VACASK benchmark tests pass</li> <li>Other models (resistor, capacitor, diode) still work correctly</li> </ol>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#riskcomplexity-assessment","title":"Risk/Complexity Assessment","text":"<p>Low risk: - Adding new field to VaModule struct - Adding new Python method to runner.py</p> <p>Medium risk: - Callback hooking in Rust requires careful lifetime management - The RefCell pattern for capturing collapse state in callback closures - Node index conversion from HIR Node to our node indices</p> <p>Mitigation: - Can test callback hooking in isolation first - The existing <code>run_init_eval</code> code already handles callback setup - Start with PSP103/Ring test case to validate before generalizing</p>"},{"location":"plans/plan-generic-runtime-collapse-openvaf/#alternative-approach-simpler-but-less-general","title":"Alternative Approach (Simpler but Less General)","text":"<p>If callback hooking proves complex, could instead: 1. Parse <code>collapsible_pairs</code> node names to get node indices 2. Pass these to Python and let Python match against <code>collapse_callback_indices</code> 3. Run init with a Python callback that tracks invocations</p> <p>This moves complexity to Python but may be easier to debug.</p>"}]}