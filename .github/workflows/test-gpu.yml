name: GPU Tests

on:
  # Manual trigger with options
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Test type to run'
        required: true
        default: 'quick'
        type: choice
        options:
          - quick
          - full
          - benchmark

  # Also run on PRs that modify GPU-related code
  pull_request:
    branches: [main]
    paths:
      - 'jax_spice/analysis/**'
      - 'jax_spice/devices/**'
      - 'jax_spice/benchmarks/**'
      - 'tests/test_vectorized*.py'
      - '.github/workflows/test-gpu.yml'

env:
  CARGO_TERM_COLOR: always
  GCP_PROJECT: jax-spice-cuda-test
  GCP_ZONE: us-central1-f
  GCP_VM_NAME: jax-spice-cuda

jobs:
  gpu-tests:
    runs-on: ubuntu-latest
    # Only run on internal PRs where secrets are available
    if: github.event_name == 'workflow_dispatch' || github.event.pull_request.head.repo.full_name == github.repository

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

      - name: Set up gcloud CLI
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT }}

      - name: Start GPU VM if stopped
        run: |
          # Check VM status
          VM_STATUS=$(gcloud compute instances describe ${{ env.GCP_VM_NAME }} \
            --zone=${{ env.GCP_ZONE }} \
            --format='value(status)' 2>/dev/null || echo "NOT_FOUND")

          if [ "$VM_STATUS" = "TERMINATED" ]; then
            echo "Starting VM..."
            gcloud compute instances start ${{ env.GCP_VM_NAME }} --zone=${{ env.GCP_ZONE }}
            # Wait for VM to be ready
            sleep 30
          elif [ "$VM_STATUS" = "RUNNING" ]; then
            echo "VM is already running"
          else
            echo "VM status: $VM_STATUS"
            exit 1
          fi

          # Wait for SSH to be available
          for i in {1..30}; do
            if gcloud compute ssh ${{ env.GCP_VM_NAME }} --zone=${{ env.GCP_ZONE }} --command="echo 'SSH ready'" 2>/dev/null; then
              echo "SSH is ready"
              break
            fi
            echo "Waiting for SSH... ($i/30)"
            sleep 10
          done

      - name: Sync code to GPU VM
        run: |
          # Create a tarball of the current code
          tar czf /tmp/jax-spice.tar.gz \
            --exclude='.git' \
            --exclude='__pycache__' \
            --exclude='*.pyc' \
            --exclude='.venv' \
            --exclude='target' \
            --exclude='*.so' \
            .

          # Copy to VM
          gcloud compute scp /tmp/jax-spice.tar.gz \
            ${{ env.GCP_VM_NAME }}:/tmp/jax-spice.tar.gz \
            --zone=${{ env.GCP_ZONE }}

          # Extract and setup on VM
          gcloud compute ssh ${{ env.GCP_VM_NAME }} --zone=${{ env.GCP_ZONE }} --command="
            cd ~
            rm -rf jax-spice-ci
            mkdir -p jax-spice-ci
            cd jax-spice-ci
            tar xzf /tmp/jax-spice.tar.gz
            rm /tmp/jax-spice.tar.gz
          "

      - name: Setup Python environment on GPU VM
        run: |
          gcloud compute ssh ${{ env.GCP_VM_NAME }} --zone=${{ env.GCP_ZONE }} --command="
            cd ~/jax-spice-ci

            # Create fresh venv if needed
            if [ ! -d .venv ]; then
              python3.10 -m venv .venv
            fi

            source .venv/bin/activate

            # Install dependencies
            pip install --upgrade pip
            pip install -e '.[test]' 2>/dev/null || pip install -e .
            pip install pytest jax jaxlib

            # Verify JAX can see GPU
            python -c 'import jax; print(f\"JAX devices: {jax.devices()}\"); assert any(\"cuda\" in str(d).lower() or \"gpu\" in str(d).lower() for d in jax.devices()), \"No GPU found!\"'
          "

      - name: Run GPU tests
        id: gpu_tests
        run: |
          TEST_TYPE="${{ github.event.inputs.test_type || 'quick' }}"

          if [ "$TEST_TYPE" = "quick" ]; then
            TEST_CMD="pytest tests/test_vectorized_mna.py -v --tb=short"
          elif [ "$TEST_TYPE" = "full" ]; then
            TEST_CMD="pytest tests/ -v --tb=short -x"
          elif [ "$TEST_TYPE" = "benchmark" ]; then
            TEST_CMD="python -c '
          import jax
          jax.config.update(\"jax_enable_x64\", True)
          from jax_spice.benchmarks.c6288 import C6288Benchmark
          bench = C6288Benchmark(verbose=True)
          bench.parse()
          bench.flatten(\"c6288_test\")
          bench.build_system(\"c6288_test\")
          print(f\"System has {len(bench.system.devices)} devices\")
          print(f\"Matrix size: {bench.system.num_nodes - 1}\")
          print(f\"JAX backend: {jax.default_backend()}\")
          '"
          fi

          gcloud compute ssh ${{ env.GCP_VM_NAME }} --zone=${{ env.GCP_ZONE }} --command="
            cd ~/jax-spice-ci
            source .venv/bin/activate
            export JAX_ENABLE_X64=1

            echo '=== GPU Info ==='
            nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv

            echo ''
            echo '=== Running tests ==='
            $TEST_CMD
          "

      - name: Stop GPU VM (on success or manual trigger)
        if: always() && (github.event_name == 'workflow_dispatch' || success())
        run: |
          # Only stop if this was a manual trigger or tests passed
          # Keep running on PR failures so devs can investigate
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Stopping VM after manual run..."
            gcloud compute instances stop ${{ env.GCP_VM_NAME }} --zone=${{ env.GCP_ZONE }} || true
          elif [ "${{ steps.gpu_tests.outcome }}" = "success" ]; then
            echo "Tests passed, stopping VM..."
            gcloud compute instances stop ${{ env.GCP_VM_NAME }} --zone=${{ env.GCP_ZONE }} || true
          else
            echo "Tests failed on PR, keeping VM running for investigation"
          fi
