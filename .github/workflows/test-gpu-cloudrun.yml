name: GPU Tests (Cloud Run)

on:
  workflow_dispatch:
  push:
    branches:
      - main
  pull_request:

env:
  GCP_PROJECT: jax-spice-cuda-test
  GCP_REGION: us-central1
  JOB_NAME: jax-spice-gpu-tests
  AR_REMOTE_REPO: ghcr-remote

jobs:
  gpu-tests:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
      packages: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          install_components: 'beta'

      # NOTE: Artifact Registry and sccache bucket are created via scripts/setup_gcp_gpu_ci.sh
      # Run that script once when setting up a new GCP project

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set image names (lowercase for ghcr.io)
        run: |
          REPO_LC=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
          GHCR_IMAGE="ghcr.io/${REPO_LC}/gpu-base"
          echo "GHCR_IMAGE=${GHCR_IMAGE}" >> "$GITHUB_ENV"
          echo "GHCR_PATH=${REPO_LC}/gpu-base" >> "$GITHUB_ENV"

      - name: Check if base image needs rebuild
        id: check-rebuild
        run: |
          # Check if base image exists with current deps hash
          DEPS_HASH=$(cat pyproject.toml uv.lock scripts/run-gpu-tests.sh Dockerfile.gpu-base | sha256sum | cut -c1-12)
          echo "deps_hash=${DEPS_HASH}" >> "$GITHUB_OUTPUT"

          # Check if image exists using manifest inspect (fast - only fetches metadata)
          if docker manifest inspect "${{ env.GHCR_IMAGE }}:${DEPS_HASH}" > /dev/null 2>&1; then
            echo "Base image exists for deps hash ${DEPS_HASH}"
            echo "needs_rebuild=false" >> "$GITHUB_OUTPUT"
          else
            echo "Base image needs rebuild (deps hash: ${DEPS_HASH})"
            echo "needs_rebuild=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Free up disk space for Docker build
        if: steps.check-rebuild.outputs.needs_rebuild == 'true'
        run: |
          echo "::group::Disk space before cleanup"
          df -h
          echo "::endgroup::"

          # Remove large packages to free ~15GB+ of space
          # Based on https://github.com/kou/arrow/blob/main/ci/scripts/util_free_space.sh
          sudo rm -rf /usr/local/lib/android || :
          sudo rm -rf /usr/local/share/powershell || :
          sudo rm -rf /opt/hostedtoolcache/CodeQL || :
          sudo rm -rf /opt/hostedtoolcache/go || :
          sudo rm -rf /opt/hostedtoolcache/PyPy || :
          sudo rm -rf /usr/share/dotnet || :
          sudo rm -rf /usr/share/swift || :

          echo "::group::Disk space after cleanup"
          df -h
          echo "::endgroup::"

      - name: Set up Docker Buildx
        if: steps.check-rebuild.outputs.needs_rebuild == 'true'
        uses: docker/setup-buildx-action@v3

      - name: Build and push base image (if needed)
        if: steps.check-rebuild.outputs.needs_rebuild == 'true'
        uses: docker/build-push-action@v6
        with:
          context: .
          file: Dockerfile.gpu-base
          push: true
          tags: |
            ${{ env.GHCR_IMAGE }}:${{ steps.check-rebuild.outputs.deps_hash }}
            ${{ env.GHCR_IMAGE }}:latest
          provenance: false
          cache-from: |
            type=registry,ref=${{ env.GHCR_IMAGE }}:latest
            type=gha
          cache-to: |
            type=gha

      - name: Set image tag for Cloud Run
        run: |
          AR_IMAGE="${{ env.GCP_REGION }}-docker.pkg.dev/${{ env.GCP_PROJECT }}/${{ env.AR_REMOTE_REPO }}/${{ env.GHCR_PATH }}:${{ steps.check-rebuild.outputs.deps_hash }}"
          echo "IMAGE_TAG=${AR_IMAGE}" >> "$GITHUB_ENV"
          echo "Cloud Run will use: ${AR_IMAGE}"

      - name: Create or update Cloud Run Job
        run: |
          job_desc=" \
              --region=${{ env.GCP_REGION }} \
              --image=${{ env.IMAGE_TAG }} \
              --execution-environment=gen2 \
              --gpu=1 \
              --gpu-type=nvidia-l4 \
              --no-gpu-zonal-redundancy \
              --cpu=4 \
              --memory=16Gi \
              --max-retries=2 \
              --task-timeout=45m \
              --set-env-vars=GITHUB_REPOSITORY=${{ github.repository }} \
              --set-env-vars=GITHUB_SHA=${{ github.sha }} \
              --set-env-vars=RUN_GPU_BENCHMARKS=1 \
          "

          # Check if job exists
          if gcloud run jobs describe ${{ env.JOB_NAME }} --region=${{ env.GCP_REGION }} 2>/dev/null; then
            echo "Updating existing job..."
            gcloud run jobs update ${{ env.JOB_NAME }} $job_desc
          else
            echo "Creating new job..."
            gcloud run jobs create ${{ env.JOB_NAME }} $job_desc
          fi

      - name: Execute Cloud Run Job
        run: |
          echo "Starting GPU test job for commit ${{ github.sha }}..."

          # Execute and capture execution name
          exec_id=$(gcloud run jobs execute ${{ env.JOB_NAME }} \
            --region=${{ env.GCP_REGION }} \
            --async \
            --format="value(metadata.name)")

          echo "Execution started: $exec_id"
          echo "exec_id=$exec_id" >> "$GITHUB_ENV"
          echo
          echo "Waiting for run:"

          # Get execution status
          status="Unknown"
          until [[ "$status" != "Unknown" ]]; do
            status=$(gcloud run jobs executions describe $exec_id \
              --region=${{ env.GCP_REGION }} \
              --format="value(status.conditions[0].status)")
            stdbuf -oL echo -n .
            sleep 5
          done

          echo

          # Capture logs to file for parsing
          gcloud beta run jobs executions logs read $exec_id \
            --region=${{ env.GCP_REGION }} | tee /tmp/job_logs.txt

          status=$(gcloud run jobs executions describe $exec_id \
            --region=${{ env.GCP_REGION }} \
            --format="value(status.conditions[0].status)")
          echo
          echo "Status: $status"

          if [ "$status" != "True" ]; then
            exit 1
          fi

      - name: Extract benchmark comparison to summary
        if: always()
        run: |
          # Extract the benchmark comparison from logs
          if [ -f /tmp/job_logs.txt ]; then
            {
              echo "## JAX-SPICE vs VACASK Benchmark Comparison (GPU)"
              echo ""
              echo "### Environment"
              echo "- **Platform**: GPU (Cloud Run with NVIDIA L4)"
              echo "- **Mode**: lax.scan (JIT-compiled)"
              echo "- **Steps**: 200"
              echo ""

              # Extract per-step timing table
              echo "### Per-Step Timing"
              echo ""
              echo "| Benchmark | Steps | JAX-SPICE (ms/step) | VACASK (ms/step) | Ratio |"
              echo "|-----------|-------|---------------------|------------------|-------|"

              # Parse the per-step summary table from the log (strip Cloud Run timestamp prefix)
              sed 's/^[0-9-]* [0-9:]* //' /tmp/job_logs.txt | \
                grep -A 10 "Summary (per-step timing)" | \
                grep "^|" | tail -n +3 || true

              echo ""
              echo "### Total Wall Time"
              echo ""
              echo "| Benchmark | Steps | JAX-SPICE (ms) | VACASK (ms) | Ratio |"
              echo "|-----------|-------|----------------|-------------|-------|"

              # Parse the total time summary table from the log
              sed 's/^[0-9-]* [0-9:]* //' /tmp/job_logs.txt | \
                grep -A 10 "Summary (total wall time)" | \
                grep "^|" | tail -n +3 || true

              echo ""
              echo "### Interpretation"
              echo ""
              echo "- **Ratio < 1.0**: JAX-SPICE is faster"
              echo "- **Ratio > 1.0**: JAX-SPICE is slower"
              echo "- **N/A**: VACASK comparison not available"
              # Profiling traces section will be added after we generate signed URLs
            } >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Generate Perfetto links for traces
        if: always()
        run: |
          # Generate signed URLs for traces and add clickable Perfetto links to summary
          TRACE_PATH="${{ github.sha }}"
          GCS_BUCKET="jax-spice-cuda-test-traces"

          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "### Profiling Traces" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"

          # List trace files in GCS (use .trace.json.gz - Perfetto native format, not .xplane.pb)
          TRACE_FILES=$(gsutil ls "gs://${GCS_BUCKET}/${TRACE_PATH}/**/*.trace.json.gz" 2>/dev/null || echo "")
          export TRACE_FILES

          if [ -z "$TRACE_FILES" ]; then
            echo "No profiling traces found." >> "$GITHUB_STEP_SUMMARY"
          else
            echo "Click to open in Perfetto UI (links valid for 7 days):" >> "$GITHUB_STEP_SUMMARY"
            echo "" >> "$GITHUB_STEP_SUMMARY"

            # Use Python to generate signed URLs from the SA JSON key
            pip install --quiet google-cloud-storage

            # Write Python script to temp file to avoid YAML heredoc issues
            cat > /tmp/gen_signed_urls.py << 'EOF'
          import os, re, urllib.parse
          from datetime import timedelta
          from google.cloud import storage

          bucket_name = "jax-spice-cuda-test-traces"
          summary_file = os.environ["GITHUB_STEP_SUMMARY"]
          trace_files = [f.strip() for f in os.environ.get("TRACE_FILES", "").split("\n") if f.strip()]

          client = storage.Client()
          bucket = client.bucket(bucket_name)

          with open(summary_file, "a") as summary:
              for gcs_path in trace_files:
                  blob_name = gcs_path.replace(f"gs://{bucket_name}/", "")
                  blob = bucket.blob(blob_name)
                  match = re.search(r'benchmark_[^/]+', blob_name)
                  benchmark = match.group(0) if match else "trace"
                  try:
                      signed_url = blob.generate_signed_url(version="v4", expiration=timedelta(days=7), method="GET")
                      encoded_url = urllib.parse.quote(signed_url, safe='')
                      perfetto_url = f"https://ui.perfetto.dev/#!/?url={encoded_url}"
                      summary.write(f"- [{benchmark}]({perfetto_url})\n")
                  except Exception as e:
                      summary.write(f"- {benchmark}: (failed: {str(e)[:100]})\n")
          EOF

            python3 /tmp/gen_signed_urls.py

            echo "" >> "$GITHUB_STEP_SUMMARY"
            echo "Or download via CLI: \`uv run scripts/view_traces.py\`" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Fetch traces from GCS for artifact upload
        if: always()
        run: |
          # Cloud Run uploads traces to GCS during job execution.
          # We fetch them here to re-upload as a GitHub artifact for easier access.
          TRACE_PATH="${{ github.sha }}"
          GCS_BUCKET="jax-spice-cuda-test-traces"

          echo "Fetching traces from gs://${GCS_BUCKET}/${TRACE_PATH}/"
          mkdir -p /tmp/profiling-traces

          gsutil -m cp -r "gs://${GCS_BUCKET}/${TRACE_PATH}/*" /tmp/profiling-traces/ 2>/dev/null || {
            echo "No traces found (profiling may have been skipped or failed)"
            exit 0
          }

          echo "Fetched traces:"
          ls -la /tmp/profiling-traces/ || true

      - name: Upload profiling traces as GitHub artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: profiling-traces-${{ github.sha }}
          path: /tmp/profiling-traces/
          if-no-files-found: ignore
          retention-days: 30
