name: Benchmark Comparison

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always
  CARGO_INCREMENTAL: 0
  # XLA compilation cache - keyed by OS and architecture to avoid mismatches
  # This significantly speeds up JAX compilation (4-10x on complex models)
  JAX_COMPILATION_CACHE_DIR: /tmp/jax-xla-cache

jobs:
  benchmark-comparison:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout with submodules
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            cmake ninja-build \
            flex bison libfl-dev \
            libsuitesparse-dev \
            ccache \
            bc

      - name: Install LLVM 18
        run: |
          wget https://apt.llvm.org/llvm.sh
          chmod +x llvm.sh
          sudo ./llvm.sh 18
          # Install additional LLVM tools needed by OpenVAF
          sudo apt-get install -y lld-18
          # Add LLVM tools to PATH and set environment
          echo "/usr/lib/llvm-18/bin" >> "$GITHUB_PATH"
          echo "LLVM_SYS_181_PREFIX=/usr/lib/llvm-18" >> "$GITHUB_ENV"

      - name: Set up Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache ccache
        uses: actions/cache@v4
        with:
          path: ~/.ccache
          key: ccache-${{ runner.os }}-${{ github.sha }}
          restore-keys: |
            ccache-${{ runner.os }}-

      - name: Configure ccache
        run: |
          ccache --set-config=max_size=500M
          ccache --set-config=compression=true
          ccache -z  # Zero stats

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: |
            openvaf_jax/openvaf_py
            vendor/OpenVAF

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Set up Python
        run: uv python install 3.11

      # Cache XLA compiled artifacts to speed up JAX compilation
      # Key includes OS, arch, and JAX version to avoid binary incompatibilities
      - name: Cache XLA compilation artifacts
        uses: actions/cache@v4
        with:
          path: /tmp/jax-xla-cache
          key: xla-cache-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            xla-cache-${{ runner.os }}-${{ runner.arch }}-

      - name: Build openvaf-py
        working-directory: openvaf_jax/openvaf_py
        run: |
          uv sync
          uv run maturin develop --release

      - name: Build openvaf-r (standalone compiler for VACASK)
        working-directory: vendor/OpenVAF
        run: |
          # Build openvaf-r binary for OSDI compilation
          # Use --no-default-features --features llvm18 to build with LLVM 18 (default is LLVM 21)
          cargo build --release -p openvaf-driver --bin openvaf-r --no-default-features --features llvm18
          echo "OPENVAF_DIR=${{ github.workspace }}/vendor/OpenVAF/target/release" >> "$GITHUB_ENV"

      - name: Install jax-spice
        run: uv sync --extra dev

      - name: Run JAX-SPICE tests
        env:
          JAX_PLATFORMS: cpu
        run: uv run pytest tests/test_vacask_suite.py tests/test_vacask_jax.py -v --tb=short

      # Build VACASK simulator
      - name: Cache Boost 1.88
        uses: actions/cache@v4
        id: cache-boost
        with:
          path: /tmp/boost_1_88_0
          key: boost-1.88.0-${{ runner.os }}

      - name: Download and build Boost 1.88
        if: steps.cache-boost.outputs.cache-hit != 'true'
        run: |
          cd /tmp
          wget -q https://archives.boost.io/release/1.88.0/source/boost_1_88_0.tar.gz
          tar -xzf boost_1_88_0.tar.gz
          cd boost_1_88_0
          ./bootstrap.sh --with-libraries=filesystem,process,system
          ./b2 -j"$(nproc)" link=static

      - name: Download toml++ 3.4.0
        run: |
          cd /tmp
          wget -q https://github.com/marzer/tomlplusplus/archive/refs/tags/v3.4.0.tar.gz
          tar -xzf v3.4.0.tar.gz

      - name: Cache VACASK build
        uses: actions/cache@v4
        with:
          path: vendor/VACASK/build
          # Include OpenVAF sources since openvaf-r changes affect OSDI compilation
          key: vacask-build-${{ runner.os }}-${{ hashFiles('vendor/VACASK/CMakeLists.txt', 'vendor/VACASK/lib/**', 'vendor/VACASK/simulator/**', 'vendor/VACASK/devices/**', 'vendor/OpenVAF/Cargo.lock') }}

      - name: Build VACASK
        run: |
          cd vendor/VACASK
          mkdir -p build && cd build
          cmake .. \
            -G Ninja \
            -DCMAKE_BUILD_TYPE=Release \
            -DCMAKE_C_COMPILER_LAUNCHER=ccache \
            -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \
            -DBoost_NO_SYSTEM_PATHS=TRUE \
            -DBoost_INCLUDE_DIR=/tmp/boost_1_88_0 \
            -DCMAKE_PREFIX_PATH="/tmp/boost_1_88_0/stage/lib/cmake" \
            -DTOMLPP_DIR=/tmp/tomlplusplus-3.4.0 \
            -DOPENVAF_DIR="${OPENVAF_DIR}"
          # Build simulator and OSDI device files (parallel)
          ninja -j"$(nproc)" vacask
          # Try to build device OSDI files (may fail on some platforms)
          ninja -j"$(nproc)" build_and_stage_devices || {
            echo "Warning: OSDI device compilation failed"
            echo "=== OpenVAF crash logs ==="
            cat /tmp/openvaf-crash-*.log 2>/dev/null || echo "No crash logs found"
          }
          # Show ccache stats
          echo "=== ccache stats ==="
          ccache -s

      # Run automated VACASK result comparison tests
      # These tests compare simulation waveforms between JAX-SPICE and VACASK
      # Tests marked with xfail are expected to fail and won't break CI
      - name: Run VACASK result comparison tests
        timeout-minutes: 15
        env:
          JAX_PLATFORMS: cpu
          JAX_ENABLE_X64: "1"
          VACASK_BIN: ${{ github.workspace }}/vendor/VACASK/build/simulator/vacask
          # Limit steps in CI to avoid timeout (full 1M steps takes too long)
          JAX_SPICE_MAX_STEPS: "10000"
          # Enable JAX compilation tracing to debug CI slowdowns
          JAX_LOG_COMPILES: "1"
          JAX_EXPLAIN_CACHE_MISSES: "1"
        run: |
          echo "Running automated VACASK result comparison tests..."
          echo "Note: Limiting to 10k steps per benchmark for CI (full run uses up to 1M)"
          # Run pytest with the VACASK comparison tests
          # Tests marked xfail won't cause failure, but unexpected failures will
          # Using --tb=long for full tracebacks, --log-cli-level=INFO for timing
          uv run pytest tests/test_vacask_benchmarks.py -v \
            -k "TestVACASKResultComparison" \
            --tb=long --log-cli-level=INFO 2>&1 | tee /tmp/vacask-result-tests.log

      # Summarize XLA compilation times for CI debugging
      - name: Summarize XLA compilation times
        if: always()
        run: |
          echo "=== XLA Compilation Summary ==="
          echo "Top 20 slowest XLA compilations:"
          grep "Finished XLA compilation" /tmp/vacask-result-tests.log 2>/dev/null | \
            sed 's/.*of jit(\([^)]*\)) in \([0-9.]*\) sec.*/\2 \1/' | \
            sort -rn | head -20 || echo "No XLA compilation data found"
          echo ""
          echo "Total compilations: $(grep -c "Finished XLA compilation" /tmp/vacask-result-tests.log 2>/dev/null || echo 0)"
          echo "Cache hits: $(grep -c "Persistent compilation cache hit" /tmp/vacask-result-tests.log 2>/dev/null || echo 0)"
          echo "Cache misses: $(grep -c "PERSISTENT COMPILATION CACHE MISS" /tmp/vacask-result-tests.log 2>/dev/null || echo 0)"

      # Report XLA compilation cache status
      # Cache is keyed by OS-arch-pyproject hash for binary compatibility
      - name: Report XLA cache status
        env:
          JAX_PLATFORMS: cpu
          JAX_ENABLE_X64: "1"
        run: |
          echo "=== XLA Compilation Cache Status ==="
          echo "Cache directory: ${JAX_COMPILATION_CACHE_DIR}"
          echo "Cache key: xla-cache-${{ runner.os }}-${{ runner.arch }}-<pyproject-hash>"

          if [ -d "${JAX_COMPILATION_CACHE_DIR}" ]; then
            CACHE_SIZE=$(du -sh "${JAX_COMPILATION_CACHE_DIR}" 2>/dev/null | cut -f1 || echo "empty")
            CACHE_FILES=$(find "${JAX_COMPILATION_CACHE_DIR}" -type f 2>/dev/null | wc -l || echo 0)
            echo "Cache size: ${CACHE_SIZE}"
            echo "Cached artifacts: ${CACHE_FILES}"
            echo "CACHE_SIZE=${CACHE_SIZE}" >> /tmp/cache-metrics.env
            echo "CACHE_FILES=${CACHE_FILES}" >> /tmp/cache-metrics.env

            # List largest cached artifacts
            echo ""
            echo "Largest cached artifacts:"
            find "${JAX_COMPILATION_CACHE_DIR}" -type f -exec du -h {} \; 2>/dev/null | sort -rh | head -5 || true
          else
            echo "Cache directory not found (first run or cache miss)"
            echo "CACHE_SIZE=0" >> /tmp/cache-metrics.env
            echo "CACHE_FILES=0" >> /tmp/cache-metrics.env
          fi

      # Run benchmark performance comparison
      # NOTE: VACASK benchmarks require OSDI device files compiled by openvaf-r
      # This currently crashes on Linux/LLVM18, so VACASK results may not be available
      - name: Run benchmark performance comparison
        env:
          JAX_PLATFORMS: cpu
          JAX_ENABLE_X64: "1"
        timeout-minutes: 30
        run: |
          echo "Running JAX-SPICE vs VACASK comparison..."
          # Benchmarks are auto-discovered from jax_spice.benchmarks.registry
          # Includes: rc, graetz, mul, ring, c6288, tb_dp (if available)
          uv run python scripts/compare_vacask.py \
            --max-steps 200 \
            --use-scan \
            --use-sparse 2>&1 | tee /tmp/benchmark-comparison.log || true

      # Generate comparison summary for GitHub step output
      - name: Generate comparison summary
        run: |
          {
            echo "## Benchmark Comparison: JAX-SPICE vs VACASK"
            echo ""
            echo "### Environment"
            echo "- **Platform**: CPU (GitHub Actions runner)"
            echo "- **JAX Backend**: cpu"
            echo "- **Mode**: lax.scan (JIT-compiled)"
            echo "- **Steps**: 200"
            echo ""

            # Report VACASK result comparison tests
            echo "### Result Accuracy Tests"
            echo ""
            if [ -f "/tmp/vacask-result-tests.log" ]; then
              echo "| Benchmark | Status | Details |"
              echo "|-----------|--------|---------|"

              # Extract test results for all benchmarks found in the log
              grep -oP 'test_transient_matches_vacask\[\K[^\]]+' /tmp/vacask-result-tests.log | sort -u | while read -r bench; do
                if grep -q "test_transient_matches_vacask\[${bench}\].*PASSED" /tmp/vacask-result-tests.log; then
                  echo "| ${bench} | ✅ PASSED | Waveform matches VACASK |"
                elif grep -q "test_transient_matches_vacask\[${bench}\].*XFAIL" /tmp/vacask-result-tests.log; then
                  reason=$(grep "test_transient_matches_vacask\[${bench}\]" /tmp/vacask-result-tests.log | head -1 | sed 's/.*reason=//' || echo "Expected failure")
                  echo "| ${bench} | ⚠️ XFAIL | ${reason} |"
                elif grep -q "test_transient_matches_vacask\[${bench}\].*SKIPPED" /tmp/vacask-result-tests.log; then
                  echo "| ${bench} | ⏭️ SKIPPED | VACASK binary not available |"
                elif grep -q "test_transient_matches_vacask\[${bench}\].*FAILED" /tmp/vacask-result-tests.log; then
                  echo "| ${bench} | ❌ FAILED | Unexpected failure |"
                fi
              done

              echo ""
              echo "_Tests marked XFAIL are known limitations being worked on._"
              echo ""
            else
              echo "**Warning**: Result comparison tests log not found"
              echo ""
            fi

            # Extract and display the comparison output
            if [ -f "/tmp/benchmark-comparison.log" ]; then
              # Check if VACASK was available and working
              if grep -q "VACASK binary: NOT FOUND" /tmp/benchmark-comparison.log; then
                echo "### ⚠️ VACASK Binary Not Found"
                echo ""
                echo "VACASK simulator binary was not built. Check the Build VACASK step."
                echo ""
              elif grep -q "\.osdi' not found" /tmp/benchmark-comparison.log; then
                echo "### ⚠️ VACASK OSDI Files Missing"
                echo ""
                echo "VACASK binary exists but OSDI device files are missing."
                echo "openvaf-r OSDI compilation fails on Linux/LLVM18 (known upstream issue)."
                echo "JAX-SPICE benchmarks ran successfully - showing JAX-SPICE only results."
                echo ""
                echo "For full comparison results, run locally on macOS."
                echo ""
              fi

              echo "### Per-Step Timing"
              echo ""
              echo "| Benchmark | Steps | JAX-SPICE (ms/step) | VACASK (ms/step) | Ratio |"
              echo "|-----------|-------|---------------------|------------------|-------|"

              # Parse the per-step summary table from the log
              grep -A 10 "Summary (per-step timing)" /tmp/benchmark-comparison.log | \
                grep "^|" | tail -n +3 | while read -r line; do
                echo "$line"
              done

              echo ""
              echo "### Total Wall Time"
              echo ""
              echo "| Benchmark | Steps | JAX-SPICE (ms) | VACASK (ms) | Ratio |"
              echo "|-----------|-------|----------------|-------------|-------|"

              # Parse the total time summary table from the log
              grep -A 10 "Summary (total wall time)" /tmp/benchmark-comparison.log | \
                grep "^|" | tail -n +3 | while read -r line; do
                echo "$line"
              done

              echo ""
              echo "### Interpretation"
              echo ""
              echo "- **Ratio < 1.0**: JAX-SPICE is faster"
              echo "- **Ratio > 1.0**: JAX-SPICE is slower (overhead-dominated for small circuits)"
              echo "- **N/A**: VACASK comparison not available"
            else
              echo "**Error**: Benchmark comparison log not found"
            fi

            # XLA Cache status
            if [ -f "/tmp/cache-metrics.env" ]; then
              source /tmp/cache-metrics.env
              echo ""
              echo "### XLA Compilation Cache"
              echo ""
              echo "| Metric | Value |"
              echo "|--------|-------|"
              echo "| Cache size | ${CACHE_SIZE:-N/A} |"
              echo "| Cached artifacts | ${CACHE_FILES:-N/A} |"
              echo "| Cache key | \`xla-cache-${{ runner.os }}-${{ runner.arch }}-...\` |"
              echo ""
              echo "_Cache is persisted between runs for faster compilation._"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload benchmark logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-logs
          path: |
            /tmp/benchmark-comparison.log
            /tmp/vacask-result-tests.log
